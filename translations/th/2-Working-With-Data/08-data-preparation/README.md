<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "90a815d332aea41a222f4c6372e7186e",
  "translation_date": "2025-09-04T18:46:11+00:00",
  "source_file": "2-Working-With-Data/08-data-preparation/README.md",
  "language_code": "th"
}
-->
# การทำงานกับข้อมูล: การเตรียมข้อมูล

|![ Sketchnote โดย [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/08-DataPreparation.png)|
|:---:|
|การเตรียมข้อมูล - _Sketchnote โดย [@nitya](https://twitter.com/nitya)_ |

## [แบบทดสอบก่อนเรียน](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/14)

ขึ้นอยู่กับแหล่งที่มาของข้อมูล ข้อมูลดิบอาจมีความไม่สอดคล้องกันที่ทำให้เกิดความท้าทายในการวิเคราะห์และการสร้างแบบจำลอง กล่าวอีกนัยหนึ่ง ข้อมูลนี้สามารถจัดประเภทเป็น "ข้อมูลสกปรก" และจำเป็นต้องทำความสะอาด บทเรียนนี้มุ่งเน้นไปที่เทคนิคในการทำความสะอาดและแปลงข้อมูลเพื่อจัดการกับปัญหาข้อมูลที่หายไป ไม่ถูกต้อง หรือไม่สมบูรณ์ หัวข้อที่ครอบคลุมในบทเรียนนี้จะใช้ Python และไลบรารี Pandas และจะ [แสดงในโน้ตบุ๊ก](notebook.ipynb) ในไดเรกทอรีนี้

## ความสำคัญของการทำความสะอาดข้อมูล

- **ความง่ายในการใช้งานและการนำกลับมาใช้ใหม่**: เมื่อข้อมูลถูกจัดระเบียบและปรับให้เป็นมาตรฐานอย่างเหมาะสม จะง่ายต่อการค้นหา ใช้งาน และแบ่งปันกับผู้อื่น

- **ความสอดคล้องกัน**: วิทยาศาสตร์ข้อมูลมักต้องทำงานกับชุดข้อมูลมากกว่าหนึ่งชุด ซึ่งชุดข้อมูลจากแหล่งต่าง ๆ จำเป็นต้องรวมเข้าด้วยกัน การทำให้ชุดข้อมูลแต่ละชุดมีมาตรฐานร่วมกันจะช่วยให้ข้อมูลยังคงมีประโยชน์เมื่อรวมกันเป็นชุดข้อมูลเดียว

- **ความแม่นยำของแบบจำลอง**: ข้อมูลที่ได้รับการทำความสะอาดช่วยเพิ่มความแม่นยำของแบบจำลองที่อ้างอิงข้อมูลนั้น

## เป้าหมายและกลยุทธ์ทั่วไปในการทำความสะอาดข้อมูล

- **การสำรวจชุดข้อมูล**: การสำรวจข้อมูล ซึ่งจะครอบคลุมใน [บทเรียนถัดไป](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/4-Data-Science-Lifecycle/15-analyzing) สามารถช่วยให้คุณค้นพบข้อมูลที่ต้องทำความสะอาด การสังเกตค่าภายในชุดข้อมูลด้วยสายตาสามารถตั้งความคาดหวังเกี่ยวกับลักษณะของข้อมูลที่เหลือ หรือให้แนวคิดเกี่ยวกับปัญหาที่สามารถแก้ไขได้ การสำรวจอาจรวมถึงการตั้งคำถามพื้นฐาน การสร้างภาพ และการสุ่มตัวอย่าง

- **การจัดรูปแบบ**: ขึ้นอยู่กับแหล่งที่มา ข้อมูลอาจมีความไม่สอดคล้องกันในวิธีการนำเสนอ ซึ่งอาจทำให้เกิดปัญหาในการค้นหาและแสดงค่า โดยที่ค่าเหล่านั้นปรากฏในชุดข้อมูลแต่ไม่ได้แสดงผลอย่างเหมาะสมในภาพหรือผลลัพธ์ของการตั้งคำถาม ปัญหาการจัดรูปแบบทั่วไปเกี่ยวข้องกับการแก้ไขช่องว่าง วันที่ และประเภทข้อมูล การแก้ไขปัญหาการจัดรูปแบบมักขึ้นอยู่กับผู้ที่ใช้ข้อมูล ตัวอย่างเช่น มาตรฐานเกี่ยวกับวิธีการนำเสนอวันที่และตัวเลขอาจแตกต่างกันไปตามประเทศ

- **การซ้ำซ้อน**: ข้อมูลที่มีการเกิดซ้ำมากกว่าหนึ่งครั้งอาจทำให้ผลลัพธ์ไม่ถูกต้องและมักจะต้องถูกลบออก สิ่งนี้อาจเกิดขึ้นบ่อยเมื่อรวมชุดข้อมูลสองชุดหรือมากกว่านั้นเข้าด้วยกัน อย่างไรก็ตาม มีกรณีที่การซ้ำซ้อนในชุดข้อมูลที่รวมกันมีส่วนที่สามารถให้ข้อมูลเพิ่มเติมและอาจจำเป็นต้องเก็บรักษาไว้

- **ข้อมูลที่หายไป**: ข้อมูลที่หายไปอาจทำให้เกิดความไม่ถูกต้อง รวมถึงผลลัพธ์ที่อ่อนแอหรือมีอคติ บางครั้งสามารถแก้ไขได้โดยการ "โหลดใหม่" ข้อมูล เติมค่าที่หายไปด้วยการคำนวณและโค้ด เช่น Python หรือเพียงแค่ลบค่าที่หายไปและข้อมูลที่เกี่ยวข้อง เหตุผลที่ข้อมูลอาจหายไปมีมากมาย และการดำเนินการที่ทำเพื่อแก้ไขค่าที่หายไปเหล่านี้อาจขึ้นอยู่กับวิธีและเหตุผลที่ข้อมูลหายไปในตอนแรก

## การสำรวจข้อมูลใน DataFrame
> **เป้าหมายการเรียนรู้:** เมื่อจบส่วนย่อยนี้ คุณควรจะสามารถค้นหาข้อมูลทั่วไปเกี่ยวกับข้อมูลที่จัดเก็บใน pandas DataFrames ได้อย่างสะดวก

เมื่อคุณโหลดข้อมูลเข้าสู่ pandas ข้อมูลนั้นมักจะอยู่ในรูปแบบ DataFrame (ดู [บทเรียนก่อนหน้า](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/2-Working-With-Data/07-python#dataframe) เพื่อดูภาพรวมโดยละเอียด) อย่างไรก็ตาม หากชุดข้อมูลใน DataFrame ของคุณมี 60,000 แถวและ 400 คอลัมน์ คุณจะเริ่มต้นทำความเข้าใจข้อมูลที่คุณกำลังทำงานด้วยได้อย่างไร? โชคดีที่ [pandas](https://pandas.pydata.org/) มีเครื่องมือที่สะดวกในการดูข้อมูลโดยรวมเกี่ยวกับ DataFrame รวมถึงแถวแรกและแถวสุดท้าย

เพื่อสำรวจฟังก์ชันนี้ เราจะนำเข้าไลบรารี Python scikit-learn และใช้ชุดข้อมูลที่มีชื่อเสียง: **ชุดข้อมูล Iris**

```python
import pandas as pd
from sklearn.datasets import load_iris

iris = load_iris()
iris_df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])
```
|                                        |sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|
|----------------------------------------|-----------------|----------------|-----------------|----------------|
|0                                       |5.1              |3.5             |1.4              |0.2             |
|1                                       |4.9              |3.0             |1.4              |0.2             |
|2                                       |4.7              |3.2             |1.3              |0.2             |
|3                                       |4.6              |3.1             |1.5              |0.2             |
|4                                       |5.0              |3.6             |1.4              |0.2             |

- **DataFrame.info**: เริ่มต้นด้วยการใช้เมธอด `info()` เพื่อพิมพ์สรุปเนื้อหาที่มีอยู่ใน `DataFrame` ลองดูชุดข้อมูลนี้เพื่อดูว่าเรามีอะไรบ้าง:
```python
iris_df.info()
```
```
RangeIndex: 150 entries, 0 to 149
Data columns (total 4 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   sepal length (cm)  150 non-null    float64
 1   sepal width (cm)   150 non-null    float64
 2   petal length (cm)  150 non-null    float64
 3   petal width (cm)   150 non-null    float64
dtypes: float64(4)
memory usage: 4.8 KB
```
จากข้อมูลนี้ เราทราบว่าชุดข้อมูล *Iris* มี 150 รายการในสี่คอลัมน์โดยไม่มีรายการที่เป็น null ข้อมูลทั้งหมดถูกจัดเก็บเป็นตัวเลขทศนิยมแบบ 64 บิต

- **DataFrame.head()**: ถัดไป เพื่อดูเนื้อหาจริงของ `DataFrame` เราใช้เมธอด `head()` ลองดูแถวแรก ๆ ของ `iris_df`:
```python
iris_df.head()
```
```
   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
0                5.1               3.5                1.4               0.2
1                4.9               3.0                1.4               0.2
2                4.7               3.2                1.3               0.2
3                4.6               3.1                1.5               0.2
4                5.0               3.6                1.4               0.2
```
- **DataFrame.tail()**: ในทางกลับกัน เพื่อดูแถวสุดท้ายของ `DataFrame` เราใช้เมธอด `tail()`:
```python
iris_df.tail()
```
```
     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
145                6.7               3.0                5.2               2.3
146                6.3               2.5                5.0               1.9
147                6.5               3.0                5.2               2.0
148                6.2               3.4                5.4               2.3
149                5.9               3.0                5.1               1.8
```
> **ข้อสรุป:** เพียงแค่ดูข้อมูลเมตาเกี่ยวกับข้อมูลใน DataFrame หรือค่าต่าง ๆ ในแถวแรกและแถวสุดท้าย คุณสามารถเข้าใจขนาด รูปร่าง และเนื้อหาของข้อมูลที่คุณกำลังจัดการได้ทันที

## การจัดการข้อมูลที่หายไป
> **เป้าหมายการเรียนรู้:** เมื่อจบส่วนย่อยนี้ คุณควรทราบวิธีแทนที่หรือลบค่าที่เป็น null ออกจาก DataFrames

ส่วนใหญ่แล้ว ชุดข้อมูลที่คุณต้องการใช้ (หรือจำเป็นต้องใช้) มีค่าที่หายไป การจัดการข้อมูลที่หายไปมีการแลกเปลี่ยนที่ละเอียดอ่อนซึ่งอาจส่งผลต่อการวิเคราะห์ขั้นสุดท้ายและผลลัพธ์ในโลกจริง

Pandas จัดการค่าที่หายไปในสองวิธี วิธีแรกที่คุณเคยเห็นในส่วนก่อนหน้า: `NaN` หรือ Not a Number นี่เป็นค่าพิเศษที่เป็นส่วนหนึ่งของข้อกำหนด IEEE floating-point และใช้เพื่อระบุค่าที่หายไปในตัวเลขทศนิยมเท่านั้น

สำหรับค่าที่หายไปนอกเหนือจากตัวเลขทศนิยม Pandas ใช้ Python `None` object แม้ว่ามันอาจดูสับสนที่คุณจะพบค่าที่แตกต่างกันสองประเภทที่บอกสิ่งเดียวกัน แต่มีเหตุผลทางโปรแกรมที่ดีสำหรับการออกแบบนี้ และในทางปฏิบัติ การเลือกเส้นทางนี้ช่วยให้ Pandas มอบการประนีประนอมที่ดีสำหรับกรณีส่วนใหญ่ อย่างไรก็ตาม ทั้ง `None` และ `NaN` มีข้อจำกัดที่คุณต้องระวังเกี่ยวกับวิธีการใช้งาน

ดูข้อมูลเพิ่มเติมเกี่ยวกับ `NaN` และ `None` จาก [โน้ตบุ๊ก](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/4-Data-Science-Lifecycle/15-analyzing/notebook.ipynb)!

- **การตรวจจับค่าที่เป็น null**: ใน `pandas` เมธอด `isnull()` และ `notnull()` เป็นเมธอดหลักของคุณในการตรวจจับข้อมูลที่เป็น null ทั้งสองเมธอดจะคืนค่ามาสก์ Boolean บนข้อมูลของคุณ เราจะใช้ `numpy` สำหรับค่าที่เป็น `NaN`:
```python
import numpy as np

example1 = pd.Series([0, np.nan, '', None])
example1.isnull()
```
```
0    False
1     True
2    False
3     True
dtype: bool
```
ดูผลลัพธ์อย่างใกล้ชิด มีอะไรที่ทำให้คุณประหลาดใจหรือไม่? แม้ว่า `0` จะเป็น null ทางคณิตศาสตร์ แต่ก็ยังเป็นจำนวนเต็มที่สมบูรณ์และ Pandas ถือว่าเป็นเช่นนั้น `''` มีความละเอียดอ่อนเล็กน้อย แม้ว่าเราใช้มันในส่วนที่ 1 เพื่อแสดงถึงค่าข้อความว่างเปล่า แต่ก็ยังเป็น object ข้อความและไม่ใช่การแสดงค่าที่เป็น null ตามที่ Pandas กำหนด

ตอนนี้ ลองพลิกกลับและใช้เมธอดเหล่านี้ในลักษณะที่คล้ายกับที่คุณจะใช้ในทางปฏิบัติ คุณสามารถใช้มาสก์ Boolean โดยตรงเป็นดัชนี ``Series`` หรือ ``DataFrame`` ซึ่งมีประโยชน์เมื่อพยายามทำงานกับค่าที่หายไป (หรือค่าที่มีอยู่) ที่แยกออกมา

> **ข้อสรุป**: เมธอด `isnull()` และ `notnull()` ให้ผลลัพธ์ที่คล้ายกันเมื่อคุณใช้ใน `DataFrame`s: พวกมันแสดงผลลัพธ์และดัชนีของผลลัพธ์เหล่านั้น ซึ่งจะช่วยคุณอย่างมากเมื่อคุณจัดการกับข้อมูลของคุณ

- **การลบค่าที่เป็น null**: นอกเหนือจากการระบุค่าที่หายไป Pandas มีวิธีที่สะดวกในการลบค่าที่เป็น null ออกจาก `Series` และ `DataFrame`s (โดยเฉพาะในชุดข้อมูลขนาดใหญ่ มักจะแนะนำให้ลบค่าที่หายไป [NA] ออกจากการวิเคราะห์ของคุณมากกว่าที่จะจัดการกับมันในวิธีอื่น ๆ) เพื่อดูสิ่งนี้ในทางปฏิบัติ ลองกลับไปที่ `example1`:
```python
example1 = example1.dropna()
example1
```
```
0    0
2     
dtype: object
```
สังเกตว่าสิ่งนี้ควรดูเหมือนผลลัพธ์ของคุณจาก `example3[example3.notnull()]` ความแตกต่างที่นี่คือ แทนที่จะเพียงแค่จัดทำดัชนีบนค่าที่มาสก์ไว้ `dropna` ได้ลบค่าที่หายไปเหล่านั้นออกจาก `Series` `example1`

เนื่องจาก `DataFrame`s มีสองมิติ จึงมีตัวเลือกเพิ่มเติมสำหรับการลบข้อมูล

```python
example2 = pd.DataFrame([[1,      np.nan, 7], 
                         [2,      5,      8], 
                         [np.nan, 6,      9]])
example2
```
|      | 0 | 1 | 2 |
|------|---|---|---|
|0     |1.0|NaN|7  |
|1     |2.0|5.0|8  |
|2     |NaN|6.0|9  |

(คุณสังเกตไหมว่า Pandas เปลี่ยนสองคอลัมน์เป็นตัวเลขทศนิยมเพื่อรองรับ `NaN`s?)

คุณไม่สามารถลบค่าหนึ่งค่าออกจาก `DataFrame` ได้ ดังนั้นคุณต้องลบทั้งแถวหรือคอลัมน์ ขึ้นอยู่กับสิ่งที่คุณกำลังทำ คุณอาจต้องการทำอย่างใดอย่างหนึ่ง และ Pandas ให้ตัวเลือกสำหรับทั้งสองอย่าง เนื่องจากในวิทยาศาสตร์ข้อมูล คอลัมน์มักแสดงตัวแปรและแถวแสดงการสังเกต คุณมีแนวโน้มที่จะลบแถวของข้อมูลมากกว่า การตั้งค่าดีฟอลต์สำหรับ `dropna()` คือการลบแถวทั้งหมดที่มีค่าที่เป็น null:

```python
example2.dropna()
```
```
	0	1	2
1	2.0	5.0	8
```
หากจำเป็น คุณสามารถลบค่าที่เป็น NA ออกจากคอลัมน์ได้ ใช้ `axis=1` เพื่อทำเช่นนั้น:
```python
example2.dropna(axis='columns')
```
```
	2
0	7
1	8
2	9
```
สังเกตว่าสิ่งนี้สามารถลบข้อมูลจำนวนมากที่คุณอาจต้องการเก็บไว้ โดยเฉพาะในชุดข้อมูลขนาดเล็ก หากคุณต้องการลบแถวหรือคอลัมน์ที่มีค่าที่เป็น null หลายค่าหรือแม้แต่ทั้งหมด คุณสามารถระบุการตั้งค่าเหล่านั้นใน `dropna` ด้วยพารามิเตอร์ `how` และ `thresh`

โดยดีฟอลต์ `how='any'` (หากคุณต้องการตรวจสอบด้วยตัวเองหรือดูว่ามีพารามิเตอร์อื่น ๆ ในเมธอดนี้หรือไม่ ให้รัน `example4.dropna?` ในเซลล์โค้ด) คุณสามารถระบุ `how='all'` เพื่อให้ลบเฉพาะแถวหรือคอลัมน์ที่มีค่าที่เป็น null ทั้งหมด ลองขยาย `DataFrame` ตัวอย่างของเราเพื่อดูสิ่งนี้ในทางปฏิบัติ

```python
example2[3] = np.nan
example2
```
|      |0  |1  |2  |3  |
|------|---|---|---|---|
|0     |1.0|NaN|7  |NaN|
|1     |2.0|5.0|8  |NaN|
|2     |NaN|6.0|9  |NaN|

พารามิเตอร์ `thresh` ให้คุณควบคุมได้ละเอียดขึ้น: คุณตั้งค่าจำนวน *ค่าที่ไม่เป็น null* ที่แถวหรือคอลัมน์ต้องมีเพื่อให้เก็บไว้:
```python
example2.dropna(axis='rows', thresh=3)
```
```
	0	1	2	3
1	2.0	5.0	8	NaN
```
ที่นี่ แถวแรกและแถวสุดท้ายถูกลบออก เพราะมีเพียงสองค่าที่ไม่เป็น null

- **การเติมค่าที่เป็น null**: ขึ้นอยู่กับชุดข้อมูลของคุณ บางครั้งอาจสมเหตุสมผลกว่าที่จะเติมค่าที่เป็น null ด้วยค่าที่ถูกต้องแทนที่จะลบออก คุณสามารถใช้ `isnull` เพื่อทำสิ่งนี้ในที่เดียว แต่สิ่งนี้อาจยุ่งยาก โดยเฉพาะถ้าคุณมีค่าที่ต้องเติมจำนวนมาก เนื่องจากนี่เป็นงานที่พบได้บ่อยในวิทยาศาสตร์ข้อมูล Pandas มี `fillna` ซึ่งคืนสำเนาของ `Series` หรือ `DataFrame` พร้อมค่าที่หายไปแทนที่ด้วยค่าที่คุณเลือก ลองสร้าง `Series` ตัวอย่างอีกตัวเพื่อดูว่าสิ่งนี้ทำงานอย่างไรในทางปฏิบัติ
```python
example3 = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))
example3
```
```
a    1.0
b    NaN
c    2.0
d    NaN
e    3.0
dtype: float64
```
คุณสามารถเติมค่าที่เป็น null ทั้งหมดด้วยค่าหนึ่ง เช่น `0`:
```python
example3.fillna(0)
```
```
a    1.0
b    0.0
c    2.0
d    0.0
e    3.0
dtype: float64
```
คุณสามารถ **เติมค่าล่วงหน้า** (forward-fill) ค่าที่เป็น null ซึ่งหมายถึงการใช้ค่าที่ถูกต้องล่าสุดเพื่อเติมค่าที่เป็น null:
```python
example3.fillna(method='ffill')
```
```
a    1.0
b    1.0
c    2.0
d    2.0
e    3.0
dtype: float64
```
คุณยังสามารถ **เติมค่าถอยหลัง** (back-fill) เพื่อใช้ค่าที่ถูกต้องถัดไปเติมค่าที่เป็น null:
```python
example3.fillna(method='bfill')
```
```
a    1.0
b    2.0
c    2.0
d    3.0
e    3.0
dtype: float64
```
ตามที่คุณคาดเดา สิ่งนี้ทำงานเหมือนกันกับ `DataFrame`s แต่คุณยังสามารถระบุ `axis` ที่จะเติมค่าที่เป็น null ได้ โดยใช้ `example2` ที่เคยใช้ก่อนหน้านี้อีกครั้ง:
```python
example2.fillna(method='ffill', axis=1)
```
```
	0	1	2	3
0	1.0	1.0	7.0	7.0
1	2.0	5.0	8.0	8.0
2	NaN	6.0	9.0	9.0
```
สังเกตว่าเมื่อไม่มีค่าก่อนหน้าสำหรับการเติมค่าล่วงหน้า ค่าที่เป็น null จะยังคงอยู่
> **ข้อสำคัญ:** มีหลายวิธีในการจัดการกับค่าที่หายไปในชุดข้อมูลของคุณ กลยุทธ์เฉพาะที่คุณเลือกใช้ (การลบ, การแทนที่, หรือแม้กระทั่งวิธีการแทนที่) ควรขึ้นอยู่กับลักษณะเฉพาะของข้อมูลนั้น คุณจะพัฒนาความเข้าใจในการจัดการกับค่าที่หายไปได้ดีขึ้นเมื่อคุณมีประสบการณ์ในการทำงานและวิเคราะห์ชุดข้อมูลมากขึ้น

## การลบข้อมูลที่ซ้ำกัน

> **เป้าหมายการเรียนรู้:** เมื่อจบส่วนนี้ คุณควรมีความมั่นใจในการระบุและลบค่าที่ซ้ำกันออกจาก DataFrames

นอกจากข้อมูลที่หายไปแล้ว คุณมักจะพบข้อมูลที่ซ้ำกันในชุดข้อมูลจริง โชคดีที่ `pandas` มีวิธีที่ง่ายในการตรวจจับและลบรายการที่ซ้ำกัน

- **การระบุข้อมูลซ้ำ: `duplicated`**: คุณสามารถตรวจสอบค่าที่ซ้ำกันได้ง่าย ๆ โดยใช้เมธอด `duplicated` ใน pandas ซึ่งจะคืนค่าหน้ากาก Boolean ที่ระบุว่ารายการใน `DataFrame` เป็นข้อมูลซ้ำของรายการก่อนหน้าหรือไม่ ลองสร้างตัวอย่าง `DataFrame` เพื่อดูการทำงานนี้
```python
example4 = pd.DataFrame({'letters': ['A','B'] * 2 + ['B'],
                         'numbers': [1, 2, 1, 3, 3]})
example4
```
|      |letters|numbers|
|------|-------|-------|
|0     |A      |1      |
|1     |B      |2      |
|2     |A      |1      |
|3     |B      |3      |
|4     |B      |3      |

```python
example4.duplicated()
```
```
0    False
1    False
2     True
3    False
4     True
dtype: bool
```
- **การลบข้อมูลซ้ำ: `drop_duplicates`:** คืนสำเนาของข้อมูลที่ค่าทั้งหมดใน `duplicated` เป็น `False`:
```python
example4.drop_duplicates()
```
```
	letters	numbers
0	A	1
1	B	2
3	B	3
```
ทั้ง `duplicated` และ `drop_duplicates` จะพิจารณาทุกคอลัมน์เป็นค่าเริ่มต้น แต่คุณสามารถระบุให้ตรวจสอบเฉพาะคอลัมน์บางส่วนใน `DataFrame` ของคุณได้:
```python
example4.drop_duplicates(['letters'])
```
```
letters	numbers
0	A	1
1	B	2
```

> **ข้อสำคัญ:** การลบข้อมูลที่ซ้ำกันเป็นส่วนสำคัญของเกือบทุกโครงการด้านวิทยาศาสตร์ข้อมูล ข้อมูลที่ซ้ำกันสามารถเปลี่ยนผลลัพธ์ของการวิเคราะห์และทำให้ผลลัพธ์ของคุณไม่ถูกต้อง!


## 🚀 ความท้าทาย

เนื้อหาทั้งหมดที่กล่าวถึงมีให้ใน [Jupyter Notebook](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/2-Working-With-Data/08-data-preparation/notebook.ipynb) นอกจากนี้ยังมีแบบฝึกหัดหลังแต่ละส่วน ลองทำดู!

## [แบบทดสอบหลังการบรรยาย](https://ff-quizzes.netlify.app/en/ds/)



## ทบทวนและศึกษาด้วยตนเอง

มีหลายวิธีในการค้นหาและเตรียมข้อมูลของคุณสำหรับการวิเคราะห์และการสร้างแบบจำลอง การทำความสะอาดข้อมูลเป็นขั้นตอนสำคัญที่ต้องลงมือทำ ลองทำความท้าทายเหล่านี้จาก Kaggle เพื่อสำรวจเทคนิคที่บทเรียนนี้ไม่ได้กล่าวถึง

- [Data Cleaning Challenge: Parsing Dates](https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/)

- [Data Cleaning Challenge: Scale and Normalize Data](https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data)


## งานที่ได้รับมอบหมาย

[Evaluating Data from a Form](assignment.md)

---

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามให้การแปลมีความถูกต้อง แต่โปรดทราบว่าการแปลโดยอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่ถูกต้อง เอกสารต้นฉบับในภาษาดั้งเดิมควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้บริการแปลภาษามืออาชีพ เราไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความผิดที่เกิดจากการใช้การแปลนี้