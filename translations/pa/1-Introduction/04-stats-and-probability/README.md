<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8bbb3fa0d4ad61384a3b4b5f7560226f",
  "translation_date": "2025-09-04T17:31:32+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "pa"
}
-->
# ਸਟੈਟਿਸਟਿਕਸ ਅਤੇ ਪ੍ਰੋਬੈਬਿਲਿਟੀ ਦਾ ਸੰਖੇਪ ਪਰੀਚਯ

|![ [(@sketchthedocs)] ਦੁਆਰਾ ਬਣਾਈ ਗਈ ਸਕੈਚਨੋਟ](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| ਸਟੈਟਿਸਟਿਕਸ ਅਤੇ ਪ੍ਰੋਬੈਬਿਲਿਟੀ - _[@nitya](https://twitter.com/nitya) ਦੁਆਰਾ ਸਕੈਚਨੋਟ_ |

ਸਟੈਟਿਸਟਿਕਸ ਅਤੇ ਪ੍ਰੋਬੈਬਿਲਿਟੀ ਥਿਊਰੀ ਗਣਿਤ ਦੇ ਦੋ ਬਹੁਤ ਹੀ ਜੁੜੇ ਹੋਏ ਖੇਤਰ ਹਨ ਜੋ ਡਾਟਾ ਸਾਇੰਸ ਲਈ ਬਹੁਤ ਮਹੱਤਵਪੂਰਨ ਹਨ। ਡਾਟਾ ਨਾਲ ਬਿਨਾਂ ਗਣਿਤ ਦੀ ਗਹਿਰਾਈ ਵਾਲੀ ਜਾਣਕਾਰੀ ਦੇ ਕੰਮ ਕਰਨਾ ਸੰਭਵ ਹੈ, ਪਰ ਕੁਝ ਮੁੱਢਲੀ ਧਾਰਨਾਵਾਂ ਜਾਣਨਾ ਫਿਰ ਵੀ ਵਧੀਆ ਹੈ। ਇੱਥੇ ਅਸੀਂ ਇੱਕ ਛੋਟਾ ਪਰੀਚਯ ਪੇਸ਼ ਕਰਾਂਗੇ ਜੋ ਤੁਹਾਨੂੰ ਸ਼ੁਰੂਆਤ ਕਰਨ ਵਿੱਚ ਮਦਦ ਕਰੇਗਾ।

[![ਇੰਟਰੋ ਵੀਡੀਓ](../../../../translated_images/video-prob-and-stats.e4282e5efa2f2543400843ed98b1057065c9600cebfc8a728e8931b5702b2ae4.pa.png)](https://youtu.be/Z5Zy85g4Yjw)

## [ਪ੍ਰੀ-ਲੈਕਚਰ ਕਵਿਜ਼](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/6)

## ਪ੍ਰੋਬੈਬਿਲਿਟੀ ਅਤੇ ਰੈਂਡਮ ਵੈਰੀਏਬਲਜ਼

**ਪ੍ਰੋਬੈਬਿਲਿਟੀ** 0 ਅਤੇ 1 ਦੇ ਵਿਚਕਾਰ ਇੱਕ ਗਿਣਤੀ ਹੈ ਜੋ ਦੱਸਦੀ ਹੈ ਕਿ ਕੋਈ **ਘਟਨਾ** ਕਿੰਨੀ ਸੰਭਾਵਨਾ ਵਾਲੀ ਹੈ। ਇਹ ਸਾਰੇ ਸੰਭਾਵਨਾਵਾਂ ਦੇ ਸਮਾਨ ਹੋਣ ਦੀ ਸ਼ਰਤ 'ਤੇ, ਸਕਾਰਾਤਮਕ ਨਤੀਜਿਆਂ ਦੀ ਗਿਣਤੀ ਨੂੰ ਕੁੱਲ ਨਤੀਜਿਆਂ ਦੀ ਗਿਣਤੀ ਨਾਲ ਵੰਡ ਕੇ ਪਰਿਭਾਸ਼ਿਤ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਉਦਾਹਰਣ ਲਈ, ਜਦੋਂ ਅਸੀਂ ਪਾਸਾ ਸੁੱਟਦੇ ਹਾਂ, ਤਾਂ ਇੱਕ ਜੋੜੇ ਨੰਬਰ ਦੇ ਆਉਣ ਦੀ ਸੰਭਾਵਨਾ 3/6 = 0.5 ਹੈ।

ਜਦੋਂ ਅਸੀਂ ਘਟਨਾਵਾਂ ਬਾਰੇ ਗੱਲ ਕਰਦੇ ਹਾਂ, ਤਾਂ ਅਸੀਂ **ਰੈਂਡਮ ਵੈਰੀਏਬਲਜ਼** ਦੀ ਵਰਤੋਂ ਕਰਦੇ ਹਾਂ। ਉਦਾਹਰਣ ਲਈ, ਪਾਸਾ ਸੁੱਟਣ 'ਤੇ ਪ੍ਰਾਪਤ ਨੰਬਰ ਨੂੰ ਦਰਸਾਉਣ ਵਾਲਾ ਰੈਂਡਮ ਵੈਰੀਏਬਲ 1 ਤੋਂ 6 ਤੱਕ ਦੇ ਮੁੱਲ ਲੈਂਦਾ ਹੈ। 1 ਤੋਂ 6 ਤੱਕ ਦੇ ਨੰਬਰਾਂ ਦਾ ਸੈਟ **ਸੈਂਪਲ ਸਪੇਸ** ਕਿਹਾ ਜਾਂਦਾ ਹੈ। ਅਸੀਂ ਰੈਂਡਮ ਵੈਰੀਏਬਲ ਦੇ ਕਿਸੇ ਵਿਸ਼ੇਸ਼ ਮੁੱਲ ਨੂੰ ਲੈਣ ਦੀ ਸੰਭਾਵਨਾ ਬਾਰੇ ਗੱਲ ਕਰ ਸਕਦੇ ਹਾਂ, ਉਦਾਹਰਣ ਲਈ P(X=3)=1/6।

ਪਿਛਲੇ ਉਦਾਹਰਣ ਵਿੱਚ ਰੈਂਡਮ ਵੈਰੀਏਬਲ ਨੂੰ **ਡਿਸਕ੍ਰੀਟ** ਕਿਹਾ ਜਾਂਦਾ ਹੈ, ਕਿਉਂਕਿ ਇਸਦਾ ਸੈਂਪਲ ਸਪੇਸ ਗਿਣਤੀਯੋਗ ਹੈ, ਅਰਥਾਤ ਅਲੱਗ ਅਲੱਗ ਮੁੱਲ ਹਨ ਜੋ ਗਿਣੇ ਜਾ ਸਕਦੇ ਹਨ। ਕੁਝ ਮਾਮਲਿਆਂ ਵਿੱਚ ਸੈਂਪਲ ਸਪੇਸ ਅਸਲ ਨੰਬਰਾਂ ਦੀ ਰੇਂਜ ਜਾਂ ਅਸਲ ਨੰਬਰਾਂ ਦਾ ਪੂਰਾ ਸੈਟ ਹੁੰਦਾ ਹੈ। ਇਸ ਤਰ੍ਹਾਂ ਦੇ ਵੈਰੀਏਬਲਜ਼ ਨੂੰ **ਕੰਟਿਨਿਊਅਸ** ਕਿਹਾ ਜਾਂਦਾ ਹੈ। ਇੱਕ ਵਧੀਆ ਉਦਾਹਰਣ ਬੱਸ ਦੇ ਆਉਣ ਦਾ ਸਮਾਂ ਹੈ।

## ਪ੍ਰੋਬੈਬਿਲਿਟੀ ਡਿਸਟ੍ਰੀਬਿਊਸ਼ਨ

ਡਿਸਕ੍ਰੀਟ ਰੈਂਡਮ ਵੈਰੀਏਬਲਜ਼ ਦੇ ਮਾਮਲੇ ਵਿੱਚ, ਹਰ ਘਟਨਾ ਦੀ ਸੰਭਾਵਨਾ ਨੂੰ P(X) ਫੰਕਸ਼ਨ ਦੁਆਰਾ ਵਰਣਨ ਕਰਨਾ ਆਸਾਨ ਹੈ। ਸੈਂਪਲ ਸਪੇਸ *S* ਦੇ ਹਰ ਮੁੱਲ *s* ਲਈ ਇਹ 0 ਤੋਂ 1 ਤੱਕ ਦੀ ਗਿਣਤੀ ਦੇਵੇਗਾ, ਇਸ ਤਰ੍ਹਾਂ ਕਿ P(X=s) ਦੇ ਸਾਰੇ ਮੁੱਲਾਂ ਦਾ ਜੋੜ 1 ਹੋਵੇਗਾ।

ਸਭ ਤੋਂ ਪ੍ਰਸਿੱਧ ਡਿਸਕ੍ਰੀਟ ਡਿਸਟ੍ਰੀਬਿਊਸ਼ਨ **ਯੂਨੀਫਾਰਮ ਡਿਸਟ੍ਰੀਬਿਊਸ਼ਨ** ਹੈ, ਜਿਸ ਵਿੱਚ N ਤੱਤਾਂ ਦਾ ਸੈਂਪਲ ਸਪੇਸ ਹੁੰਦਾ ਹੈ, ਅਤੇ ਹਰ ਇੱਕ ਲਈ 1/N ਦੀ ਸਮਾਨ ਸੰਭਾਵਨਾ ਹੁੰਦੀ ਹੈ।

ਕੰਟਿਨਿਊਅਸ ਵੈਰੀਏਬਲ ਦੇ ਪ੍ਰੋਬੈਬਿਲਿਟੀ ਡਿਸਟ੍ਰੀਬਿਊਸ਼ਨ ਨੂੰ ਵਰਣਨ ਕਰਨਾ ਥੋੜਾ ਮੁਸ਼ਕਲ ਹੈ, ਜਿਸਦੇ ਮੁੱਲ ਕੁਝ ਇੰਟਰਵਲ [a,b] ਤੋਂ ਲਏ ਜਾਂਦੇ ਹਨ ਜਾਂ ਅਸਲ ਨੰਬਰਾਂ ਦੇ ਪੂਰੇ ਸੈਟ ℝ ਤੋਂ। ਬੱਸ ਦੇ ਆਉਣ ਦੇ ਸਮੇਂ ਦੇ ਮਾਮਲੇ ਨੂੰ ਵਿਚਾਰੋ। ਅਸਲ ਵਿੱਚ, ਹਰ ਵਿਸ਼ੇਸ਼ ਆਉਣ ਦੇ ਸਮੇਂ *t* ਲਈ, ਬੱਸ ਦੇ ਉਸ ਸਮੇਂ 'ਤੇ ਆਉਣ ਦੀ ਸੰਭਾਵਨਾ 0 ਹੈ!

> ਹੁਣ ਤੁਹਾਨੂੰ ਪਤਾ ਹੈ ਕਿ 0 ਸੰਭਾਵਨਾ ਵਾਲੀਆਂ ਘਟਨਾਵਾਂ ਹੁੰਦੀਆਂ ਹਨ, ਅਤੇ ਬਹੁਤ ਵਾਰ ਹੁੰਦੀਆਂ ਹਨ! ਘੱਟੋ-ਘੱਟ ਹਰ ਵਾਰ ਜਦੋਂ ਬੱਸ ਆਉਂਦੀ ਹੈ!

ਅਸੀਂ ਸਿਰਫ਼ ਕਿਸੇ ਵੈਰੀਏਬਲ ਦੇ ਮੁੱਲਾਂ ਦੇ ਦਿੱਤੇ ਇੰਟਰਵਲ ਵਿੱਚ ਪੈਣ ਦੀ ਸੰਭਾਵਨਾ ਬਾਰੇ ਗੱਲ ਕਰ ਸਕਦੇ ਹਾਂ, ਜਿਵੇਂ P(t<sub>1</sub>≤X<t<sub>2</sub>)। ਇਸ ਮਾਮਲੇ ਵਿੱਚ, ਪ੍ਰੋਬੈਬਿਲਿਟੀ ਡਿਸਟ੍ਰੀਬਿਊਸ਼ਨ ਨੂੰ **ਪ੍ਰੋਬੈਬਿਲਿਟੀ ਡੈਂਸਿਟੀ ਫੰਕਸ਼ਨ** p(x) ਦੁਆਰਾ ਵਰਣਨ ਕੀਤਾ ਜਾਂਦਾ ਹੈ, ਜਿਸਦਾ ਫਾਰਮੂਲਾ ਹੈ:

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../translated_images/probability-density.a8aad29f17a14afb519b407c7b6edeb9f3f9aa5f69c9e6d9445f604e5f8a2bf7.pa.png)

ਯੂਨੀਫਾਰਮ ਡਿਸਟ੍ਰੀਬਿਊਸ਼ਨ ਦਾ ਕੰਟਿਨਿਊਅਸ ਰੂਪ **ਕੰਟਿਨਿਊਅਸ ਯੂਨੀਫਾਰਮ** ਕਿਹਾ ਜਾਂਦਾ ਹੈ, ਜੋ ਇੱਕ ਸੀਮਿਤ ਇੰਟਰਵਲ 'ਤੇ ਪਰਿਭਾਸ਼ਿਤ ਹੁੰਦਾ ਹੈ। ਸੰਭਾਵਨਾ ਕਿ ਮੁੱਲ X ਲੰਬਾਈ l ਦੇ ਇੰਟਰਵਲ ਵਿੱਚ ਪੈਂਦਾ ਹੈ, l ਦੇ ਅਨੁਪਾਤ ਵਿੱਚ ਹੁੰਦੀ ਹੈ, ਅਤੇ 1 ਤੱਕ ਵਧਦੀ ਹੈ।

ਇੱਕ ਹੋਰ ਮਹੱਤਵਪੂਰਨ ਡਿਸਟ੍ਰੀਬਿਊਸ਼ਨ **ਨਾਰਮਲ ਡਿਸਟ੍ਰੀਬਿਊਸ਼ਨ** ਹੈ, ਜਿਸ ਬਾਰੇ ਅਸੀਂ ਹੇਠਾਂ ਵਧੇਰੇ ਵਿਸਤਾਰ ਵਿੱਚ ਗੱਲ ਕਰਾਂਗੇ।

## ਮੀਨ, ਵੈਰੀਅੰਸ ਅਤੇ ਸਟੈਂਡਰਡ ਡਿਵਿਏਸ਼ਨ

ਮੰਨੋ ਕਿ ਅਸੀਂ ਰੈਂਡਮ ਵੈਰੀਏਬਲ X ਦੇ n ਸੈਂਪਲਾਂ ਦੀ ਲੜੀ ਖਿੱਚਦੇ ਹਾਂ: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>। ਅਸੀਂ ਲੜੀ ਦੇ **ਮੀਨ** (ਜਾਂ **ਅੰਕਗਣਿਤ ਔਸਤ**) ਮੁੱਲ ਨੂੰ ਰਵਾਇਤੀ ਤਰੀਕੇ ਨਾਲ ਪਰਿਭਾਸ਼ਿਤ ਕਰ ਸਕਦੇ ਹਾਂ (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n। ਜਿਵੇਂ ਅਸੀਂ ਸੈਂਪਲ ਦਾ ਆਕਾਰ ਵਧਾਉਂਦੇ ਹਾਂ (ਅਰਥਾਤ n→∞ ਦੀ ਸੀਮਾ ਲੈਂਦੇ ਹਾਂ), ਅਸੀਂ ਡਿਸਟ੍ਰੀਬਿਊਸ਼ਨ ਦਾ ਮੀਨ (ਜਿਸਨੂੰ **ਐਕਸਪੈਕਟੇਸ਼ਨ** ਵੀ ਕਿਹਾ ਜਾਂਦਾ ਹੈ) ਪ੍ਰਾਪਤ ਕਰਾਂਗੇ। ਅਸੀਂ ਐਕਸਪੈਕਟੇਸ਼ਨ ਨੂੰ **E**(x) ਨਾਲ ਦਰਸਾਵਾਂਗੇ।

> ਇਹ ਦਿਖਾਇਆ ਜਾ ਸਕਦਾ ਹੈ ਕਿ ਕਿਸੇ ਵੀ ਡਿਸਕ੍ਰੀਟ ਡਿਸਟ੍ਰੀਬਿਊਸ਼ਨ ਲਈ, ਜਿਸਦੇ ਮੁੱਲ {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} ਅਤੇ ਸੰਬੰਧਿਤ ਸੰਭਾਵਨਾਵਾਂ p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub> ਹਨ, ਐਕਸਪੈਕਟੇਸ਼ਨ E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub> ਦੇ ਬਰਾਬਰ ਹੋਵੇਗਾ।

ਮੁੱਲਾਂ ਕਿੰਨੇ ਫੈਲੇ ਹੋਏ ਹਨ, ਇਹ ਪਛਾਣਣ ਲਈ ਅਸੀਂ ਵੈਰੀਅੰਸ σ<sup>2</sup> = ∑(x<sub>i</sub> - μ)<sup>2</sup>/n ਦੀ ਗਣਨਾ ਕਰ ਸਕਦੇ ਹਾਂ, ਜਿੱਥੇ μ ਲੜੀ ਦਾ ਮੀਨ ਹੈ। ਮੁੱਲ σ ਨੂੰ **ਸਟੈਂਡਰਡ ਡਿਵਿਏਸ਼ਨ** ਕਿਹਾ ਜਾਂਦਾ ਹੈ, ਅਤੇ σ<sup>2</sup> ਨੂੰ **ਵੈਰੀਅੰਸ** ਕਿਹਾ ਜਾਂਦਾ ਹੈ।

## ਮੋਡ, ਮੀਡਿਅਨ ਅਤੇ ਕਵਾਰਟਾਈਲਜ਼

ਕਈ ਵਾਰ, ਮੀਨ ਡਾਟਾ ਲਈ "ਟਿਪਿਕਲ" ਮੁੱਲ ਨੂੰ ਢੰਗ ਨਾਲ ਦਰਸਾਉਣ ਵਿੱਚ ਅਸਮਰਥ ਹੁੰਦਾ ਹੈ। ਉਦਾਹਰਣ ਲਈ, ਜਦੋਂ ਕੁਝ ਅਤਿ ਮੁੱਲ ਹੁੰਦੇ ਹਨ ਜੋ ਪੂਰੀ ਤਰ੍ਹਾਂ ਰੇਂਜ ਤੋਂ ਬਾਹਰ ਹੁੰਦੇ ਹਨ, ਉਹ ਮੀਨ ਨੂੰ ਪ੍ਰਭਾਵਿਤ ਕਰ ਸਕਦੇ ਹਨ। ਇੱਕ ਹੋਰ ਵਧੀਆ ਸੰਕੇਤ **ਮੀਡਿਅਨ** ਹੈ, ਇੱਕ ਮੁੱਲ ਜਿਸਦੇ ਹੇਠਾਂ ਡਾਟਾ ਪੌਇੰਟਾਂ ਦਾ ਅੱਧਾ ਹਿੱਸਾ ਹੁੰਦਾ ਹੈ, ਅਤੇ ਉੱਪਰ - ਦੂਜਾ ਅੱਧਾ।

ਡਾਟਾ ਦੇ ਡਿਸਟ੍ਰੀਬਿਊਸ਼ਨ ਨੂੰ ਸਮਝਣ ਵਿੱਚ ਸਹਾਇਕ ਹੋਣ ਲਈ, **ਕਵਾਰਟਾਈਲਜ਼** ਬਾਰੇ ਗੱਲ ਕਰਨਾ ਲਾਭਦਾਇਕ ਹੈ:

* ਪਹਿਲਾ ਕਵਾਰਟਾਈਲ, ਜਾਂ Q1, ਇੱਕ ਮੁੱਲ ਹੈ, ਜਿਸਦੇ ਹੇਠਾਂ 25% ਡਾਟਾ ਪੈਂਦਾ ਹੈ
* ਤੀਜਾ ਕਵਾਰਟਾਈਲ, ਜਾਂ Q3, ਇੱਕ ਮੁੱਲ ਹੈ, ਜਿਸਦੇ ਹੇਠਾਂ 75% ਡਾਟਾ ਪੈਂਦਾ ਹੈ

ਗ੍ਰਾਫਿਕਲ ਤੌਰ 'ਤੇ ਅਸੀਂ ਮੀਡਿਅਨ ਅਤੇ ਕਵਾਰਟਾਈਲਜ਼ ਦੇ ਸੰਬੰਧ ਨੂੰ **ਬਾਕਸ ਪਲਾਟ** ਵਿੱਚ ਦਰਸਾ ਸਕਦੇ ਹਾਂ:

<img src="images/boxplot_explanation.png" width="50%"/>

ਇੱਥੇ ਅਸੀਂ **ਇੰਟਰ-ਕਵਾਰਟਾਈਲ ਰੇਂਜ** IQR=Q3-Q1 ਦੀ ਗਣਨਾ ਕਰਦੇ ਹਾਂ, ਅਤੇ **ਆਊਟਲਾਇਰਜ਼** - ਮੁੱਲ ਜੋ ਸੀਮਾਵਾਂ [Q1-1.5*IQR,Q3+1.5*IQR] ਤੋਂ ਬਾਹਰ ਪੈਂਦੇ ਹਨ।

ਜਦੋਂ ਡਿਸਟ੍ਰੀਬਿਊਸ਼ਨ ਵਿੱਚ ਕੁਝ ਸੰਭਾਵਤ ਮੁੱਲਾਂ ਦੀ ਗਿਣਤੀ ਘੱਟ ਹੁੰਦੀ ਹੈ, ਇੱਕ ਵਧੀਆ "ਟਿਪਿਕਲ" ਮੁੱਲ ਉਹ ਹੁੰਦਾ ਹੈ ਜੋ ਸਭ ਤੋਂ ਵੱਧ ਵਾਰ ਆਉਂਦਾ ਹੈ, ਜਿਸਨੂੰ **ਮੋਡ** ਕਿਹਾ ਜਾਂਦਾ ਹੈ। ਇਹ ਅਕਸਰ ਸ਼੍ਰੇਣੀਬੱਧ ਡਾਟਾ, ਜਿਵੇਂ ਰੰਗਾਂ ਲਈ ਲਾਗੂ ਹੁੰਦਾ ਹੈ। ਇੱਕ ਸਥਿਤੀ ਨੂੰ ਵਿਚਾਰੋ ਜਦੋਂ ਸਾਡੇ ਕੋਲ ਦੋ ਸਮੂਹ ਹਨ - ਕੁਝ ਜੋ ਲਾਲ ਨੂੰ ਪਸੰਦ ਕਰਦੇ ਹਨ, ਅਤੇ ਹੋਰ ਜੋ ਨੀਲੇ ਨੂੰ ਪਸੰਦ ਕਰਦੇ ਹਨ। ਜੇਕਰ ਅਸੀਂ ਰੰਗਾਂ ਨੂੰ ਨੰਬਰਾਂ ਦੁਆਰਾ ਕੋਡ ਕਰਦੇ ਹਾਂ, ਤਾਂ ਪਸੰਦੀਦਾ ਰੰਗ ਲਈ ਮੀਨ ਮੁੱਲ ਕਿਤੇ ਸੰਤਰੀ-ਹਰੇ ਸਪੈਕਟ੍ਰਮ ਵਿੱਚ ਹੋਵੇਗਾ, ਜੋ ਕਿਸੇ ਵੀ ਸਮੂਹ ਦੀ ਅਸਲ ਪਸੰਦ ਨੂੰ ਦਰਸਾਉਂਦਾ ਨਹੀਂ। ਹਾਲਾਂਕਿ, ਮੋਡ ਜਾਂ ਤਾਂ ਇੱਕ ਰੰਗ ਹੋਵੇਗਾ, ਜਾਂ ਦੋਵੇਂ ਰੰਗ, ਜੇਕਰ ਉਨ੍ਹਾਂ ਲਈ ਵੋਟ ਕਰਨ ਵਾਲੇ ਲੋਕਾਂ ਦੀ ਗਿਣਤੀ ਬਰਾਬਰ ਹੋਵੇ (ਇਸ ਮਾਮਲੇ ਵਿੱਚ ਅਸੀਂ ਸੈਂਪਲ ਨੂੰ **ਮਲਟੀਮੋਡਲ** ਕਹਿੰਦੇ ਹਾਂ)।
> **ਭਰੋਸੇਮੰਦ ਅੰਤਰਾਲ** ਉਹ ਅੰਦਾਜ਼ਾ ਹੈ ਜੋ ਸਾਡੇ ਨਮੂਨੇ ਦੇ ਆਧਾਰ 'ਤੇ ਜਨਸੰਖਿਆ ਦੇ ਸੱਚੇ ਔਸਤ ਨੂੰ ਦਰਸਾਉਂਦਾ ਹੈ, ਜੋ ਇੱਕ ਨਿਰਧਾਰਤ ਸੰਭਾਵਨਾ (ਜਾਂ **ਭਰੋਸੇ ਦੇ ਪੱਧਰ**) 'ਤੇ ਸਹੀ ਹੁੰਦਾ ਹੈ।
ਮੰਨ ਲਓ ਕਿ ਸਾਡੇ ਕੋਲ ਸੈਂਪਲ X<sub>1</sub>, ..., X<sub>n</sub> ਸਾਡੇ ਵੰਡਣ ਤੋਂ ਹੈ। ਹਰ ਵਾਰ ਜਦੋਂ ਅਸੀਂ ਸੈਂਪਲ ਖਿੱਚਦੇ ਹਾਂ, ਸਾਨੂੰ ਵੱਖ-ਵੱਖ ਔਸਤ ਮੁੱਲ μ ਮਿਲੇਗਾ। ਇਸ ਤਰ੍ਹਾਂ μ ਨੂੰ ਇੱਕ ਰੈਂਡਮ ਵੈਰੀਏਬਲ ਮੰਨਿਆ ਜਾ ਸਕਦਾ ਹੈ। ਇੱਕ **ਭਰੋਸੇਮੰਦ ਅੰਤਰਾਲ** ਭਰੋਸੇ p ਦੇ ਨਾਲ ਇੱਕ ਜੋੜੇ ਮੁੱਲਾਂ (L<sub>p</sub>,R<sub>p</sub>) ਦੇ ਰੂਪ ਵਿੱਚ ਹੁੰਦਾ ਹੈ, ਇਸ ਤਰ੍ਹਾਂ **P**(L<sub>p</sub>≤μ≤R<sub>p</sub>) = p, ਅਰਥਾਤ ਮਾਪੇ ਗਏ ਔਸਤ ਮੁੱਲ ਦੇ ਅੰਤਰਾਲ ਵਿੱਚ ਆਉਣ ਦੀ ਸੰਭਾਵਨਾ p ਦੇ ਬਰਾਬਰ ਹੁੰਦੀ ਹੈ।

ਇਹ ਸਾਡੇ ਛੋਟੇ ਜਾਣ-ਪਛਾਣ ਤੋਂ ਪਰੇ ਜਾਂਦਾ ਹੈ ਕਿ ਇਹ ਭਰੋਸੇਮੰਦ ਅੰਤਰਾਲ ਕਿਵੇਂ ਗਿਣੇ ਜਾਂਦੇ ਹਨ। ਕੁਝ ਹੋਰ ਵੇਰਵੇ [ਵਿਕੀਪੀਡੀਆ](https://en.wikipedia.org/wiki/Confidence_interval) 'ਤੇ ਮਿਲ ਸਕਦੇ ਹਨ। ਸੰਖੇਪ ਵਿੱਚ, ਅਸੀਂ ਅਸਲੀ ਜਨਸੰਖਿਆ ਦੇ ਔਸਤ ਦੇ ਸਬੰਧ ਵਿੱਚ ਗਿਣੇ ਗਏ ਸੈਂਪਲ ਔਸਤ ਦੇ ਵੰਡਣ ਨੂੰ ਪਰਿਭਾਸ਼ਿਤ ਕਰਦੇ ਹਾਂ, ਜਿਸਨੂੰ **ਸਟੂਡੈਂਟ ਵੰਡਣ** ਕਿਹਾ ਜਾਂਦਾ ਹੈ।

> **ਦਿਲਚਸਪ ਤੱਥ**: ਸਟੂਡੈਂਟ ਵੰਡਣ ਦਾ ਨਾਮ ਗਣਿਤਜੀ ਵਿਲੀਅਮ ਸੀਲੀ ਗੋਸੇਟ ਦੇ ਨਾਮ 'ਤੇ ਰੱਖਿਆ ਗਿਆ ਹੈ, ਜਿਸਨੇ ਆਪਣਾ ਪੇਪਰ "ਸਟੂਡੈਂਟ" ਨਾਂ ਦੇ ਤਹਿਤ ਪ੍ਰਕਾਸ਼ਿਤ ਕੀਤਾ। ਉਹ ਗਿਨੀਜ਼ ਬਰੂਅਰੀ ਵਿੱਚ ਕੰਮ ਕਰਦਾ ਸੀ, ਅਤੇ, ਇੱਕ ਵਰਜਨ ਦੇ ਅਨੁਸਾਰ, ਉਸਦੇ ਨੌਕਰੀਦਾਤਾ ਨਹੀਂ ਚਾਹੁੰਦੇ ਸਨ ਕਿ ਆਮ ਜਨਤਾ ਨੂੰ ਪਤਾ ਲੱਗੇ ਕਿ ਉਹ ਕੱਚੇ ਸਮੱਗਰੀ ਦੀ ਗੁਣਵੱਤਾ ਨਿਰਧਾਰਤ ਕਰਨ ਲਈ ਸਾਂਖਿਆਕੀ ਟੈਸਟਾਂ ਦੀ ਵਰਤੋਂ ਕਰ ਰਹੇ ਹਨ।

ਜੇਕਰ ਅਸੀਂ ਭਰੋਸੇ p ਦੇ ਨਾਲ ਆਪਣੀ ਜਨਸੰਖਿਆ ਦੇ ਔਸਤ μ ਦਾ ਅੰਦਾਜ਼ਾ ਲਗਾਉਣਾ ਚਾਹੁੰਦੇ ਹਾਂ, ਤਾਂ ਸਾਨੂੰ ਸਟੂਡੈਂਟ ਵੰਡਣ A ਦੇ *(1-p)/2-ਵੇਂ ਪ੍ਰਤੀਸ਼ਤਕ* ਨੂੰ ਲੈਣਾ ਪਵੇਗਾ, ਜੋ ਜਾਂ ਤਾਂ ਟੇਬਲਾਂ ਤੋਂ ਲਿਆ ਜਾ ਸਕਦਾ ਹੈ, ਜਾਂ ਸਾਂਖਿਆਕੀ ਸੌਫਟਵੇਅਰ (ਜਿਵੇਂ ਕਿ Python, R, ਆਦਿ) ਦੇ ਕੁਝ ਬਿਲਟ-ਇਨ ਫੰਕਸ਼ਨਾਂ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਗਿਣਿਆ ਜਾ ਸਕਦਾ ਹੈ। ਫਿਰ μ ਲਈ ਅੰਤਰਾਲ X±A*D/√n ਦੇ ਰੂਪ ਵਿੱਚ ਦਿੱਤਾ ਜਾਵੇਗਾ, ਜਿੱਥੇ X ਸੈਂਪਲ ਦਾ ਪ੍ਰਾਪਤ ਔਸਤ ਹੈ, D ਮਿਆਰੀ ਵਿਸਥਾਪਨ ਹੈ।

> **ਨੋਟ**: ਅਸੀਂ [ਡਿਗਰੀਜ਼ ਆਫ ਫ੍ਰੀਡਮ](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)) ਦੇ ਇੱਕ ਮਹੱਤਵਪੂਰਨ ਧਾਰਨਾ ਦੀ ਚਰਚਾ ਵੀ ਛੱਡ ਰਹੇ ਹਾਂ, ਜੋ ਸਟੂਡੈਂਟ ਵੰਡਣ ਦੇ ਸਬੰਧ ਵਿੱਚ ਮਹੱਤਵਪੂਰਨ ਹੈ। ਇਸ ਧਾਰਨਾ ਨੂੰ ਗਹਿਰਾਈ ਨਾਲ ਸਮਝਣ ਲਈ ਸਾਂਖਿਆਕੀ 'ਤੇ ਹੋਰ ਪੂਰੇ ਕਿਤਾਬਾਂ ਨੂੰ ਪੜ੍ਹ ਸਕਦੇ ਹੋ।

ਵਜ਼ਨ ਅਤੇ ਉਚਾਈਆਂ ਲਈ ਭਰੋਸੇਮੰਦ ਅੰਤਰਾਲ ਦੀ ਗਿਣਤੀ ਦਾ ਇੱਕ ਉਦਾਹਰਨ [ਸੰਲਗਨ ਨੋਟਬੁੱਕ](notebook.ipynb) ਵਿੱਚ ਦਿੱਤਾ ਗਿਆ ਹੈ।

| p | ਵਜ਼ਨ ਔਸਤ |
|-----|-----------|
| 0.85 | 201.73±0.94 |
| 0.90 | 201.73±1.08 |
| 0.95 | 201.73±1.28 |

ਧਿਆਨ ਦਿਓ ਕਿ ਜਿੰਨਾ ਵਧੇਰੇ ਭਰੋਸੇ ਦੀ ਸੰਭਾਵਨਾ ਹੁੰਦੀ ਹੈ, ਉਨਾ ਵਧੇਰੇ ਭਰੋਸੇਮੰਦ ਅੰਤਰਾਲ ਚੌੜਾ ਹੁੰਦਾ ਹੈ।

## ਧਾਰਨਾ ਟੈਸਟਿੰਗ

ਸਾਡੇ ਬੇਸਬਾਲ ਖਿਡਾਰੀਆਂ ਦੇ ਡਾਟਾਸੈਟ ਵਿੱਚ ਵੱਖ-ਵੱਖ ਖਿਡਾਰੀ ਭੂਮਿਕਾਵਾਂ ਹਨ, ਜੋ ਹੇਠਾਂ ਸੰਖੇਪ ਵਿੱਚ ਦਿੱਤੀਆਂ ਜਾ ਸਕਦੀਆਂ ਹਨ (ਇਸ ਟੇਬਲ ਨੂੰ ਕਿਵੇਂ ਗਿਣਿਆ ਜਾ ਸਕਦਾ ਹੈ, ਇਹ ਦੇਖਣ ਲਈ [ਸੰਲਗਨ ਨੋਟਬੁੱਕ](notebook.ipynb) 'ਤੇ ਜਾਓ):

| ਭੂਮਿਕਾ | ਉਚਾਈ | ਵਜ਼ਨ | ਗਿਣਤੀ |
|------|--------|--------|-------|
| ਕੈਚਰ | 72.723684 | 204.328947 | 76 |
| ਡਿਜ਼ਾਈਨਟਿਡ_ਹਿਟਰ | 74.222222 | 220.888889 | 18 |
| ਫਰਸਟ_ਬੇਸਮੈਨ | 74.000000 | 213.109091 | 55 |
| ਆਊਟਫੀਲਡਰ | 73.010309 | 199.113402 | 194 |
| ਰੀਲੀਫ_ਪਿਚਰ | 74.374603 | 203.517460 | 315 |
| ਸੈਕੰਡ_ਬੇਸਮੈਨ | 71.362069 | 184.344828 | 58 |
| ਸ਼ਾਰਟਸਟਾਪ | 71.903846 | 182.923077 | 52 |
| ਸਟਾਰਟਿੰਗ_ਪਿਚਰ | 74.719457 | 205.163636 | 221 |
| ਥਰਡ_ਬੇਸਮੈਨ | 73.044444 | 200.955556 | 45 |

ਅਸੀਂ ਦੇਖ ਸਕਦੇ ਹਾਂ ਕਿ ਫਰਸਟ ਬੇਸਮੈਨ ਦੀ ਔਸਤ ਉਚਾਈ ਸੈਕੰਡ ਬੇਸਮੈਨ ਦੀ ਔਸਤ ਉਚਾਈ ਤੋਂ ਵਧੇਰੇ ਹੈ। ਇਸ ਤਰ੍ਹਾਂ, ਅਸੀਂ ਇਹ ਨਿਸ਼ਚਿਤ ਕਰਨ ਲਈ ਪ੍ਰੇਰਿਤ ਹੋ ਸਕਦੇ ਹਾਂ ਕਿ **ਫਰਸਟ ਬੇਸਮੈਨ ਸੈਕੰਡ ਬੇਸਮੈਨ ਤੋਂ ਉੱਚੇ ਹਨ**।

> ਇਸ ਬਿਆਨ ਨੂੰ **ਧਾਰਨਾ** ਕਿਹਾ ਜਾਂਦਾ ਹੈ, ਕਿਉਂਕਿ ਸਾਨੂੰ ਪਤਾ ਨਹੀਂ ਕਿ ਇਹ ਤੱਥ ਅਸਲ ਵਿੱਚ ਸੱਚ ਹੈ ਜਾਂ ਨਹੀਂ।

ਹਾਲਾਂਕਿ, ਇਹ ਸਪਸ਼ਟ ਨਹੀਂ ਹੁੰਦਾ ਕਿ ਅਸੀਂ ਇਹ ਨਿਸ਼ਚਿਤ ਕਰ ਸਕਦੇ ਹਾਂ। ਉਪਰੋਕਤ ਚਰਚਾ ਤੋਂ ਅਸੀਂ ਜਾਣਦੇ ਹਾਂ ਕਿ ਹਰ ਔਸਤ ਨਾਲ ਇੱਕ ਸੰਬੰਧਿਤ ਭਰੋਸੇਮੰਦ ਅੰਤਰਾਲ ਹੁੰਦਾ ਹੈ, ਅਤੇ ਇਸ ਤਰ੍ਹਾਂ ਇਹ ਫਰਕ ਸਿਰਫ ਸਾਂਖਿਆਕੀ ਗਲਤੀ ਹੋ ਸਕਦੀ ਹੈ। ਸਾਨੂੰ ਆਪਣੀ ਧਾਰਨਾ ਦੀ ਜਾਂਚ ਕਰਨ ਲਈ ਕੁਝ ਹੋਰ ਅਧਿਕਾਰਤ ਤਰੀਕੇ ਦੀ ਲੋੜ ਹੈ।

ਆਓ ਫਰਸਟ ਅਤੇ ਸੈਕੰਡ ਬੇਸਮੈਨ ਦੀਆਂ ਉਚਾਈਆਂ ਲਈ ਭਰੋਸੇਮੰਦ ਅੰਤਰਾਲ ਨੂੰ ਵੱਖ-ਵੱਖ ਗਿਣੀਏ:

| ਭਰੋਸਾ | ਫਰਸਟ ਬੇਸਮੈਨ | ਸੈਕੰਡ ਬੇਸਮੈਨ |
|------------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

ਅਸੀਂ ਦੇਖ ਸਕਦੇ ਹਾਂ ਕਿ ਕਿਸੇ ਵੀ ਭਰੋਸੇ ਦੇ ਅੰਤਰਾਲ ਵਿੱਚ ਇਹ ਅੰਤਰਾਲ ਇੱਕ-ਦੂਜੇ ਨਾਲ ਓਵਰਲੈਪ ਨਹੀਂ ਕਰਦੇ। ਇਹ ਸਾਡੀ ਧਾਰਨਾ ਨੂੰ ਸਾਬਤ ਕਰਦਾ ਹੈ ਕਿ ਫਰਸਟ ਬੇਸਮੈਨ ਸੈਕੰਡ ਬੇਸਮੈਨ ਤੋਂ ਉੱਚੇ ਹਨ।

ਹੋਰ ਅਧਿਕਾਰਤ ਤੌਰ 'ਤੇ, ਸਾਡਾ ਸਮੱਸਿਆ ਇਹ ਹੈ ਕਿ **ਦੋ ਸੰਭਾਵਨਾ ਵੰਡਣ ਇੱਕੋ ਜਿਹੇ ਹਨ**, ਜਾਂ ਘੱਟੋ-ਘੱਟ ਇੱਕੋ ਜਿਹੇ ਪੈਰਾਮੀਟਰ ਹਨ। ਵੰਡਣ ਦੇ ਅਨੁਸਾਰ, ਸਾਨੂੰ ਇਸ ਲਈ ਵੱਖ-ਵੱਖ ਟੈਸਟਾਂ ਦੀ ਵਰਤੋਂ ਕਰਨ ਦੀ ਲੋੜ ਹੈ। ਜੇਕਰ ਸਾਨੂੰ ਪਤਾ ਹੈ ਕਿ ਸਾਡੇ ਵੰਡਣ ਸਧਾਰਨ ਹਨ, ਤਾਂ ਅਸੀਂ **[ਸਟੂਡੈਂਟ ਟੀ-ਟੈਸਟ](https://en.wikipedia.org/wiki/Student%27s_t-test)** ਲਾਗੂ ਕਰ ਸਕਦੇ ਹਾਂ।

ਸਟੂਡੈਂਟ ਟੀ-ਟੈਸਟ ਵਿੱਚ, ਅਸੀਂ **ਟੀ-ਮੁੱਲ** ਗਿਣਦੇ ਹਾਂ, ਜੋ ਔਸਤਾਂ ਦੇ ਫਰਕ ਨੂੰ ਦਰਸਾਉਂਦਾ ਹੈ, ਵਿਸਥਾਪਨ ਨੂੰ ਧਿਆਨ ਵਿੱਚ ਰੱਖਦੇ ਹੋਏ। ਇਹ ਸਾਬਤ ਕੀਤਾ ਗਿਆ ਹੈ ਕਿ ਟੀ-ਮੁੱਲ **ਸਟੂਡੈਂਟ ਵੰਡਣ** ਦੀ ਪਾਲਨਾ ਕਰਦਾ ਹੈ, ਜੋ ਸਾਨੂੰ ਦਿੱਤੇ ਗਏ ਭਰੋਸੇ ਦੇ ਪੱਧਰ **p** ਲਈ ਥ੍ਰੈਸ਼ਹੋਲਡ ਮੁੱਲ ਪ੍ਰਾਪਤ ਕਰਨ ਦੀ ਆਗਿਆ ਦਿੰਦਾ ਹੈ (ਇਹ ਗਿਣਿਆ ਜਾ ਸਕਦਾ ਹੈ, ਜਾਂ ਅੰਕ ਟੇਬਲਾਂ ਵਿੱਚ ਦੇਖਿਆ ਜਾ ਸਕਦਾ ਹੈ)। ਫਿਰ ਅਸੀਂ ਟੀ-ਮੁੱਲ ਨੂੰ ਇਸ ਥ੍ਰੈਸ਼ਹੋਲਡ ਨਾਲ ਤੁਲਨਾ ਕਰਦੇ ਹਾਂ ਤਾਂ ਜੋ ਧਾਰਨਾ ਨੂੰ ਮਨਜ਼ੂਰ ਜਾਂ ਰੱਦ ਕੀਤਾ ਜਾ ਸਕੇ।

Python ਵਿੱਚ, ਅਸੀਂ **SciPy** ਪੈਕੇਜ ਦੀ ਵਰਤੋਂ ਕਰ ਸਕਦੇ ਹਾਂ, ਜਿਸ ਵਿੱਚ `ttest_ind` ਫੰਕਸ਼ਨ ਸ਼ਾਮਲ ਹੈ (ਕਈ ਹੋਰ ਲਾਭਦਾਇਕ ਸਾਂਖਿਆਕੀ ਫੰਕਸ਼ਨਾਂ ਦੇ ਨਾਲ!). ਇਹ ਸਾਡੇ ਲਈ ਟੀ-ਮੁੱਲ ਗਿਣਦਾ ਹੈ, ਅਤੇ ਭਰੋਸੇ p-ਮੁੱਲ ਦੀ ਵਿਰੋਧੀ ਖੋਜ ਵੀ ਕਰਦਾ ਹੈ, ਤਾਂ ਜੋ ਅਸੀਂ ਸਿਰਫ ਭਰੋਸੇ ਨੂੰ ਦੇਖ ਕੇ ਨਤੀਜਾ ਕੱਢ ਸਕੀਏ।

ਉਦਾਹਰਨ ਲਈ, ਫਰਸਟ ਅਤੇ ਸੈਕੰਡ ਬੇਸਮੈਨ ਦੀਆਂ ਉਚਾਈਆਂ ਦੇ ਤੁਲਨਾਤਮਕ ਨਤੀਜੇ ਹੇਠਾਂ ਦਿੱਤੇ ਗਏ ਹਨ:
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
ਸਾਡੇ ਕੇਸ ਵਿੱਚ, p-ਮੁੱਲ ਬਹੁਤ ਘੱਟ ਹੈ, ਜਿਸਦਾ ਅਰਥ ਹੈ ਕਿ ਫਰਸਟ ਬੇਸਮੈਨ ਦੇ ਉੱਚੇ ਹੋਣ ਦੇ ਹੱਕ ਵਿੱਚ ਮਜ਼ਬੂਤ ਸਬੂਤ ਹਨ।

ਹੋਰ ਵੱਖ-ਵੱਖ ਕਿਸਮਾਂ ਦੀਆਂ ਧਾਰਨਾਵਾਂ ਵੀ ਹਨ ਜਿਨ੍ਹਾਂ ਨੂੰ ਅਸੀਂ ਜਾਂਚਣਾ ਚਾਹੁੰਦੇ ਹਾਂ, ਉਦਾਹਰਨ ਲਈ:
* ਸਾਬਤ ਕਰਨਾ ਕਿ ਦਿੱਤਾ ਗਿਆ ਸੈਂਪਲ ਕੁਝ ਵੰਡਣ ਦੀ ਪਾਲਨਾ ਕਰਦਾ ਹੈ। ਸਾਡੇ ਕੇਸ ਵਿੱਚ ਅਸੀਂ ਮੰਨਿਆ ਹੈ ਕਿ ਉਚਾਈਆਂ ਸਧਾਰਨ ਵੰਡਣ ਵਾਲੀਆਂ ਹਨ, ਪਰ ਇਸਨੂੰ ਸਾਂਖਿਆਕੀ ਤੌਰ 'ਤੇ ਸਾਬਤ ਕਰਨ ਦੀ ਲੋੜ ਹੈ।
* ਸਾਬਤ ਕਰਨਾ ਕਿ ਸੈਂਪਲ ਦਾ ਔਸਤ ਮੁੱਲ ਕੁਝ ਪੂਰਵ-ਨਿਰਧਾਰਤ ਮੁੱਲ ਦੇ ਬਰਾਬਰ ਹੈ
* ਕਈ ਸੈਂਪਲਾਂ ਦੇ ਔਸਤਾਂ ਦੀ ਤੁਲਨਾ ਕਰਨਾ (ਉਦਾਹਰਨ ਲਈ, ਵੱਖ-ਵੱਖ ਉਮਰ ਸਮੂਹਾਂ ਵਿੱਚ ਖੁਸ਼ੀ ਦੇ ਪੱਧਰ ਵਿੱਚ ਕੀ ਫਰਕ ਹੈ)

## ਵੱਡੇ ਨੰਬਰਾਂ ਦਾ ਕਾਨੂੰਨ ਅਤੇ ਕੇਂਦਰੀ ਸੀਮਾ ਸਿਧਾਂਤ

ਇੱਕ ਕਾਰਨ ਕਿ ਸਧਾਰਨ ਵੰਡਣ ਇੰਨਾ ਮਹੱਤਵਪੂਰਨ ਹੈ, ਇਸਨੂੰ **ਕੇਂਦਰੀ ਸੀਮਾ ਸਿਧਾਂਤ** ਕਿਹਾ ਜਾਂਦਾ ਹੈ। ਮੰਨ ਲਓ ਕਿ ਸਾਡੇ ਕੋਲ N ਮੁੱਲਾਂ X<sub>1</sub>, ..., X<sub>N</sub> ਦਾ ਇੱਕ ਵੱਡਾ ਸੈਂਪਲ ਹੈ, ਜੋ ਕਿਸੇ ਵੀ ਵੰਡਣ ਤੋਂ μ ਔਸਤ ਅਤੇ σ<sup>2</sup> ਵਿਸਥਾਪਨ ਦੇ ਨਾਲ ਖਿੱਚਿਆ ਗਿਆ ਹੈ। ਫਿਰ, N ਦੇ ਕਾਫ਼ੀ ਵੱਡੇ ਹੋਣ (ਅਰਥਾਤ, ਜਦੋਂ N→∞), Σ<sub>i</sub>X<sub>i</sub> ਦਾ ਔਸਤ ਸਧਾਰਨ ਵੰਡਣ ਵਾਲਾ ਹੋਵੇਗਾ, μ ਔਸਤ ਅਤੇ σ<sup>2</sup>/N ਵਿਸਥਾਪਨ ਦੇ ਨਾਲ।

> ਕੇਂਦਰੀ ਸੀਮਾ ਸਿਧਾਂਤ ਨੂੰ ਵੱਖ-ਵੱਖ ਤਰੀਕੇ ਨਾਲ ਸਮਝਿਆ ਜਾ ਸਕਦਾ ਹੈ ਕਿ ਚਾਹੇ ਕੋਈ ਵੀ ਵੰਡਣ ਹੋਵੇ, ਜਦੋਂ ਤੁਸੀਂ ਕਿਸੇ ਵੀ ਰੈਂਡਮ ਵੈਰੀਏਬਲ ਮੁੱਲਾਂ ਦੇ ਜੋੜ ਦਾ ਔਸਤ ਗਿਣਦੇ ਹੋ, ਤਾਂ ਤੁਸੀਂ ਸਧਾਰਨ ਵੰਡਣ ਪ੍ਰਾਪਤ ਕਰਦੇ ਹੋ।

ਕੇਂਦਰੀ ਸੀਮਾ ਸਿਧਾਂਤ ਤੋਂ ਇਹ ਵੀ ਨਿਕਲਦਾ ਹੈ ਕਿ, ਜਦੋਂ N→∞, ਸੈਂਪਲ ਔਸਤ μ ਦੇ ਬਰਾਬਰ ਹੋਣ ਦੀ ਸੰਭਾਵਨਾ 1 ਬਣ ਜਾਂਦੀ ਹੈ। ਇਸਨੂੰ **ਵੱਡੇ ਨੰਬਰਾਂ ਦਾ ਕਾਨੂੰਨ** ਕਿਹਾ ਜਾਂਦਾ ਹੈ।

## ਕੋਵੈਰੀਅੰਸ ਅਤੇ ਕੋਰਲੇਸ਼ਨ

ਡਾਟਾ ਸਾਇੰਸ ਦਾ ਇੱਕ ਕੰਮ ਡਾਟਾ ਦੇ ਸਬੰਧਾਂ ਨੂੰ ਖੋਜਣਾ ਹੈ। ਅਸੀਂ ਕਹਿੰਦੇ ਹਾਂ ਕਿ ਦੋ ਲੜੀਆਂ **ਸੰਬੰਧਿਤ** ਹਨ ਜਦੋਂ ਉਹ ਇੱਕੋ ਸਮੇਂ ਵਿੱਚ ਇੱਕੋ ਜਿਹੇ ਵਿਹਾਰ ਨੂੰ ਦਰਸਾਉਂਦੀਆਂ ਹਨ, ਅਰਥਾਤ ਉਹ ਇੱਕੋ ਸਮੇਂ ਉੱਪਰ ਜਾਂ ਹੇਠਾਂ ਜਾਂਦੀਆਂ ਹਨ, ਜਾਂ ਇੱਕ ਲੜੀ ਉੱਪਰ ਜਾਂਦੀ ਹੈ ਜਦੋਂ ਦੂਜੀ ਹੇਠਾਂ ਜਾਂਦੀ ਹੈ ਅਤੇ ਵਿਰੋਧੀ। ਦੂਜੇ ਸ਼ਬਦਾਂ ਵਿੱਚ, ਦੋ ਲੜੀਆਂ ਦੇ ਵਿਚਕਾਰ ਕੁਝ ਸਬੰਧ ਦਿਖਾਈ ਦਿੰਦਾ ਹੈ।

> ਸੰਬੰਧਤਾ ਲਾਜ਼ਮੀ ਨਹੀਂ ਦਿਖਾਉਂਦੀ ਕਿ ਦੋ ਲੜੀਆਂ ਦੇ ਵਿਚਕਾਰ ਕਾਰਨਾਤਮਕ ਸਬੰਧ ਹੈ; ਕਈ ਵਾਰ ਦੋਵੇਂ ਵੈਰੀਏਬਲ ਕਿਸੇ ਬਾਹਰੀ ਕਾਰਨ 'ਤੇ ਨਿਰਭਰ ਕਰ ਸਕਦੇ ਹਨ, ਜਾਂ ਇਹ ਸਿਰਫ਼ ਮੌਕੇ ਦੇ ਨਾਲ ਹੋ ਸਕਦਾ ਹੈ ਕਿ ਦੋ ਲੜੀਆਂ ਸੰਬੰਧਿਤ ਹਨ। ਹਾਲਾਂਕਿ, ਮਜ਼ਬੂਤ ਗਣਿਤਜੀ ਸੰਬੰਧਤਾ ਇਹ ਦਰਸਾਉਣ ਲਈ ਚੰਗਾ ਸੰਕੇਤ ਹੈ ਕਿ ਦੋ ਵੈਰੀਏਬਲ ਕਿਸੇ ਤਰੀਕੇ ਨਾਲ ਜੁੜੇ ਹੋਏ ਹਨ।

ਗਣਿਤਜੀ ਤੌਰ 'ਤੇ, ਮੁੱਖ ਧਾਰਨਾ ਜੋ ਦੋ ਰੈਂਡਮ ਵੈਰੀਏਬਲਾਂ ਦੇ ਵਿਚਕਾਰ ਸਬੰਧ ਦਿਖਾਉਂਦੀ ਹੈ, **ਕੋਵੈਰੀਅੰਸ** ਹੈ, ਜੋ ਇਸ ਤਰ੍ਹਾਂ ਗਿਣੀ ਜਾਂਦੀ ਹੈ: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]। ਅਸੀਂ ਦੋਵੇਂ ਵੈਰੀਏਬਲਾਂ ਦੇ ਔਸਤ ਮੁੱਲਾਂ ਤੋਂ ਵਿਸਥਾਪਨ ਗਿਣਦੇ ਹਾਂ, ਅਤੇ ਫਿਰ ਉਹਨਾਂ ਵਿਸਥਾਪਨਾਂ ਦਾ ਗੁਣਨ। ਜੇਕਰ ਦੋਵੇਂ ਵੈਰੀਏਬਲ ਇੱਕੋ ਸਮੇਂ ਵਿੱਚ ਵਿਸਥਾਪਨ ਕਰਦੇ ਹਨ, ਤਾਂ ਗੁਣਨ ਹਮੇਸ਼ਾਂ ਇੱਕ ਸਕਾਰਾਤਮਕ ਮੁੱਲ ਹੋਵੇਗਾ, ਜੋ ਸਕਾਰਾਤਮਕ ਕੋਵੈਰੀਅੰਸ ਵਿੱਚ ਸ਼ਾਮਲ ਹੋਵੇਗਾ। ਜੇਕਰ ਦੋਵੇਂ ਵੈਰੀਏਬਲ ਆਉਟ-ਆਫ-ਸਿੰਕ ਵਿਸਥਾਪਨ ਕਰਦੇ ਹਨ (ਅਰਥਾਤ ਇੱਕ ਔਸਤ ਤੋਂ ਹੇਠਾਂ ਜਾਂਦਾ ਹੈ ਜਦੋਂ ਦੂਜਾ ਔਸਤ ਤੋਂ ਉੱਪਰ ਜਾਂਦਾ ਹੈ), ਤਾਂ ਸਾਨੂੰ ਹਮੇਸ਼ਾਂ ਨਕਾਰਾਤਮਕ ਸੰਖੇਆਂ ਮਿਲਣਗੀਆਂ, ਜੋ ਨਕਾਰਾਤਮਕ ਕੋਵੈਰੀਅੰਸ ਵਿੱਚ ਸ਼ਾਮਲ ਹੋਣਗੀਆਂ। ਜੇਕਰ ਵਿਸਥਾਪਨ ਨਿਰਭਰ ਨਹੀਂ ਹੁੰਦੇ, ਤਾਂ ਉਹ ਲਗਭਗ ਜ਼ੀਰੋ ਵਿੱਚ ਸ਼ਾਮਲ ਹੋਣਗੇ।

ਕੋਵੈਰੀਅੰਸ ਦਾ ਅਬਸੋਲਿਊਟ ਮੁੱਲ ਸਾਨੂੰ ਇਹ ਨਹੀਂ ਦੱਸਦਾ ਕਿ ਸੰਬੰਧ ਕਿੰਨਾ ਵੱਡਾ ਹੈ, ਕਿਉਂਕਿ ਇਹ ਅਸਲ ਮੁੱਲਾਂ ਦੇ ਮਾਪ 'ਤੇ ਨਿਰਭਰ ਕਰਦਾ ਹੈ। ਇਸਨੂੰ ਸਧਾਰਨ ਕਰਨ ਲਈ, ਅਸੀਂ ਦੋਵੇਂ ਵੈਰੀਏਬਲਾਂ ਦੇ ਮਿਆਰੀ ਵਿਸਥਾਪਨ ਦੁਆਰਾ ਕੋਵੈਰੀਅੰਸ ਨੂੰ ਵੰਡ ਸਕਦੇ ਹਾਂ, ਤਾਂ ਜੋ **ਸੰਬੰਧਤਾ** ਪ੍ਰਾਪਤ ਕੀਤੀ ਜਾ ਸਕੇ। ਚੰਗੀ ਗੱਲ ਇਹ ਹੈ ਕਿ ਸੰਬੰਧਤਾ ਹਮੇਸ਼ਾਂ [-1,1] ਦੀ ਰੇਂਜ ਵਿੱਚ ਹੁੰਦੀ ਹੈ, ਜਿੱਥੇ 1 ਮੁੱਲਾਂ ਦੇ ਵਿਚਕਾਰ ਮਜ਼ਬੂਤ ਸਕਾਰਾਤਮਕ ਸੰਬੰਧਤਾ ਦਰਸਾਉਂਦਾ ਹੈ, -1 - ਮਜ਼ਬੂਤ ਨਕਾਰਾਤਮਕ ਸੰਬੰਧਤਾ, ਅਤੇ 0 - ਕੋਈ ਸੰਬੰਧਤਾ ਨਹੀਂ (ਵੈਰੀਏਬਲ ਸਵਤੰਤਰ ਹਨ)।

**ਉਦਾਹਰਨ**:

---

**ਅਸਵੀਕਤੀ**:  
ਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਜਦੋਂ ਕਿ ਅਸੀਂ ਸਹੀਤਾ ਲਈ ਯਤਨਸ਼ੀਲ ਹਾਂ, ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਦਿਓ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸੁਚਤਤਾਵਾਂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਮੂਲ ਦਸਤਾਵੇਜ਼ ਨੂੰ ਇਸਦੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਅਧਿਕਾਰਤ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੀ ਵਰਤੋਂ ਤੋਂ ਪੈਦਾ ਹੋਣ ਵਾਲੇ ਕਿਸੇ ਵੀ ਗਲਤਫਹਿਮੀ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।