<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "58860ce9a4b8a564003d2752f7c72851",
  "translation_date": "2025-10-03T16:53:07+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "hu"
}
-->
# Bevezet√©s az adatetik√°ba

|![ Sketchnote k√©sz√≠tette: [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Adattudom√°nyi etika - _Sketchnote k√©sz√≠tette: [@nitya](https://twitter.com/nitya)_ |

---

Mindannyian adatpolg√°rok vagyunk egy adatvez√©relt vil√°gban.

A piaci trendek azt mutatj√°k, hogy 2022-re minden harmadik nagy szervezet online [piactereken √©s t≈ëzsd√©ken](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/) kereszt√ºl fog adatokat v√°s√°rolni √©s eladni. **Alkalmaz√°sfejleszt≈ëk√©nt** k√∂nnyebb √©s olcs√≥bb lesz adatvez√©relt betekint√©seket √©s algoritmusvez√©relt automatiz√°l√°st integr√°lni a mindennapi felhaszn√°l√≥i √©lm√©nyekbe. Azonban ahogy az AI egyre elterjedtebb√© v√°lik, meg kell √©rten√ºnk az olyan algoritmusok [fegyveres√≠t√©s√©b≈ël](https://www.youtube.com/watch?v=TQHs8SA1qpk) sz√°rmaz√≥ potenci√°lis k√°rokat is, amelyek nagy l√©pt√©kben m≈±k√∂dnek.

A trendek azt sugallj√°k, hogy 2025-re t√∂bb mint [180 zettab√°jtnyi](https://www.statista.com/statistics/871513/worldwide-data-created/) adatot fogunk gener√°lni √©s fogyasztani. **Adattud√≥sokk√©nt** ez az inform√°ci√≥robban√°s p√©ld√°tlan hozz√°f√©r√©st biztos√≠t szem√©lyes √©s viselked√©si adatokhoz. Ez lehet≈ës√©get ad r√©szletes felhaszn√°l√≥i profilok l√©trehoz√°s√°ra √©s a d√∂nt√©shozatal finom befoly√°sol√°s√°ra‚Äîgyakran olyan m√≥don, amely egy [szabad v√°laszt√°s ill√∫zi√≥j√°t](https://www.datasciencecentral.com/the-pareto-set-and-the-paradox-of-choice/) kelti. B√°r ez felhaszn√°lhat√≥ arra, hogy a felhaszn√°l√≥kat prefer√°lt eredm√©nyek fel√© terelj√ºk, komoly k√©rd√©seket vet fel az adatv√©delemr≈ël, auton√≥mi√°r√≥l √©s az algoritmikus befoly√°s etikai hat√°rair√≥l.

Az adatetika mostanra _sz√ºks√©ges korl√°tokat_ jelent az adattudom√°ny √©s m√©rn√∂ki munka sz√°m√°ra, seg√≠tve a potenci√°lis k√°rok √©s nem sz√°nd√©kos k√∂vetkezm√©nyek minimaliz√°l√°s√°t az adatvez√©relt cselekv√©seinkb≈ël. A [Gartner AI Hype Cycle](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) azonos√≠tja a digit√°lis etika, a felel≈ës AI √©s az AI ir√°ny√≠t√°s relev√°ns trendjeit, mint kulcsfontoss√°g√∫ hajt√≥er≈ëket az AI _demokratiz√°l√°sa_ √©s _iparos√≠t√°sa_ k√∂r√ºli nagyobb megatrendekhez.

![Gartner AI Hype Cycle - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

Ebben a leck√©ben az adatetika leny≈±g√∂z≈ë ter√ºlet√©t fogjuk felfedezni‚Äîaz alapfogalmakt√≥l √©s kih√≠v√°sokt√≥l kezdve az esettanulm√°nyokon √©s alkalmazott AI fogalmakon √°t, mint az ir√°ny√≠t√°s‚Äîamelyek seg√≠tenek az etikai kult√∫ra kialak√≠t√°s√°ban az adatokat √©s AI-t haszn√°l√≥ csapatokban √©s szervezetekben.

## [El≈ëad√°s el≈ëtti kv√≠z](https://ff-quizzes.netlify.app/en/ds/quiz/2) üéØ

## Alapvet≈ë meghat√°roz√°sok

Kezdj√ºk az alapvet≈ë terminol√≥gia meg√©rt√©s√©vel.

Az "etika" sz√≥ a [g√∂r√∂g "ethikos"](https://en.wikipedia.org/wiki/Ethics) (√©s annak "ethos" gy√∂kere) sz√≥b√≥l sz√°rmazik, amely _jellemet vagy erk√∂lcsi term√©szetet_ jelent.

**Etika** azokr√≥l a k√∂z√∂s √©rt√©kekr≈ël √©s erk√∂lcsi elvekr≈ël sz√≥l, amelyek ir√°ny√≠tj√°k viselked√©s√ºnket a t√°rsadalomban. Az etika nem t√∂rv√©nyeken alapul, hanem sz√©les k√∂rben elfogadott norm√°kon arr√≥l, hogy mi a "helyes √©s helytelen". Az etikai megfontol√°sok azonban befoly√°solhatj√°k a v√°llalatir√°ny√≠t√°si kezdem√©nyez√©seket √©s a korm√°nyzati szab√°lyoz√°sokat, amelyek t√∂bb √∂szt√∂nz≈ët teremtenek a megfelel√©sre.

**Adatetika** egy [√∫j etikai √°g](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1), amely "tanulm√°nyozza √©s √©rt√©keli az _adatokkal, algoritmusokkal √©s kapcsol√≥d√≥ gyakorlatokkal_ kapcsolatos erk√∂lcsi probl√©m√°kat". Itt az **"adatok"** az adatok l√©trehoz√°s√°val, r√∂gz√≠t√©s√©vel, gondoz√°s√°val, feldolgoz√°s√°val, terjeszt√©s√©vel, megoszt√°s√°val √©s felhaszn√°l√°s√°val kapcsolatos cselekv√©sekre √∂sszpontos√≠tanak, az **"algoritmusok"** az AI-ra, √ºgyn√∂k√∂kre, g√©pi tanul√°sra √©s robotokra, m√≠g a **"gyakorlatok"** olyan t√©m√°kra, mint a felel≈ës innov√°ci√≥, programoz√°s, hackel√©s √©s etikai k√≥dexek.

**Alkalmazott etika** az [erk√∂lcsi megfontol√°sok gyakorlati alkalmaz√°sa](https://en.wikipedia.org/wiki/Applied_ethics). Ez az etikai k√©rd√©sek akt√≠v vizsg√°lat√°nak folyamata a _val√≥s cselekv√©sek, term√©kek √©s folyamatok_ kontextus√°ban, √©s korrekci√≥s int√©zked√©sek megt√©tele annak √©rdek√©ben, hogy ezek √∂sszhangban maradjanak a meghat√°rozott etikai √©rt√©keinkkel.

**Etikai kult√∫ra** az [_alkalmazott etika m≈±k√∂dtet√©se_](https://hbr.org/2019/05/how-to-design-an-ethical-organization), hogy biztos√≠tsuk, hogy etikai elveink √©s gyakorlataink k√∂vetkezetesen √©s sk√°l√°zhat√≥ m√≥don ker√ºljenek alkalmaz√°sra az eg√©sz szervezetben. A sikeres etikai kult√∫r√°k szervezet-szint≈± etikai elveket hat√°roznak meg, jelent≈ës √∂szt√∂nz≈ëket biztos√≠tanak a megfelel√©shez, √©s meger≈ës√≠tik az etikai norm√°kat az√°ltal, hogy √∂szt√∂nzik √©s feler≈ës√≠tik a k√≠v√°nt viselked√©seket a szervezet minden szintj√©n.

## Etikai fogalmak

Ebben a r√©szben olyan fogalmakat t√°rgyalunk, mint a **k√∂z√∂s √©rt√©kek** (elvek) √©s **etikai kih√≠v√°sok** (probl√©m√°k) az adatetik√°ban‚Äîvalamint **esettanulm√°nyokat** vizsg√°lunk, amelyek seg√≠tenek meg√©rteni ezeket a fogalmakat a val√≥s helyzetekben.

### 1. Etikai elvek

Minden adatetikai strat√©gia az _etikai elvek_ meghat√°roz√°s√°val kezd≈ëdik‚Äîazokkal a "k√∂z√∂s √©rt√©kekkel", amelyek le√≠rj√°k az elfogadhat√≥ viselked√©seket, √©s ir√°ny√≠tj√°k a megfelel√©si cselekv√©seket adat- √©s AI-projektjeinkben. Ezeket egy√©ni vagy csapatszinten is meghat√°rozhatjuk. Azonban a legt√∂bb nagy szervezet ezeket egy _etikus AI_ k√ºldet√©snyilatkozatban vagy keretrendszerben hat√°rozza meg, amelyet v√°llalati szinten defini√°lnak √©s k√∂vetkezetesen √©rv√©nyes√≠tenek minden csapatn√°l.

**P√©lda:** A Microsoft [Felel≈ës AI](https://www.microsoft.com/en-us/ai/responsible-ai) k√ºldet√©snyilatkozata √≠gy sz√≥l: _"Elk√∂telezettek vagyunk az AI fejl≈ëd√©se mellett, amelyet etikai elvek vez√©relnek, √©s az embereket helyezik el≈ët√©rbe"_‚Äî6 etikai elvet azonos√≠tva az al√°bbi keretrendszerben:

![Felel≈ës AI a Microsoftn√°l](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

N√©zz√ºk meg r√∂viden ezeket az elveket. A _transzparencia_ √©s _elsz√°moltathat√≥s√°g_ alapvet≈ë √©rt√©kek, amelyekre a t√∂bbi elv √©p√ºl‚Äîkezdj√ºk ezekkel:

* [**Elsz√°moltathat√≥s√°g**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) arra k√∂telezi a szakembereket, hogy _felel≈ëss√©get v√°llaljanak_ adat- √©s AI-m≈±veleteik√©rt, valamint az etikai elvek betart√°s√°√©rt.
* [**Transzparencia**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) biztos√≠tja, hogy az adat- √©s AI-cselekv√©sek _√©rthet≈ëek_ legyenek a felhaszn√°l√≥k sz√°m√°ra, megmagyar√°zva a d√∂nt√©sek m√∂g√∂tti mit √©s mi√©rt.
* [**M√©lt√°nyoss√°g**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) arra √∂sszpontos√≠t, hogy az AI _minden embert_ m√©lt√°nyosan kezeljen, foglalkozva az adatokban √©s rendszerekben l√©v≈ë szisztematikus vagy implicit szociotechnikai torz√≠t√°sokkal.
* [**Megb√≠zhat√≥s√°g √©s biztons√°g**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) biztos√≠tja, hogy az AI _k√∂vetkezetesen_ viselkedjen a meghat√°rozott √©rt√©kekkel, minimaliz√°lva a potenci√°lis k√°rokat vagy nem sz√°nd√©kos k√∂vetkezm√©nyeket.
* [**Adatv√©delem √©s biztons√°g**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) az adatok eredet√©nek meg√©rt√©s√©r≈ël sz√≥l, √©s _adatv√©delemhez kapcsol√≥d√≥ v√©delmet_ ny√∫jt a felhaszn√°l√≥knak.
* [**Befogad√°s**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) az AI-megold√°sok sz√°nd√©kos tervez√©s√©r≈ël sz√≥l, alkalmazkodva a _sz√©les k√∂r≈± emberi ig√©nyekhez_ √©s k√©pess√©gekhez.

> üö® Gondolkodj el azon, hogy mi lehetne az adatetikai k√ºldet√©snyilatkozatod. Fedezd fel m√°s szervezetek etikus AI keretrendszereit‚Äîp√©ld√°k: [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles), √©s [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Milyen k√∂z√∂s √©rt√©kekkel rendelkeznek? Hogyan kapcsol√≥dnak ezek az elvek az AI-term√©khez vagy ipar√°ghoz, amelyben m≈±k√∂dnek?

### 2. Etikai kih√≠v√°sok

Miut√°n meghat√°roztuk az etikai elveket, a k√∂vetkez≈ë l√©p√©s az adat- √©s AI-cselekv√©seink √©rt√©kel√©se, hogy megfelelnek-e ezeknek a k√∂z√∂s √©rt√©keknek. Gondolj a cselekv√©sekre k√©t kateg√≥ri√°ban: _adatgy≈±jt√©s_ √©s _algoritmus tervez√©s_.

Az adatgy≈±jt√©s sor√°n a cselekv√©sek val√≥sz√≠n≈±leg **szem√©lyes adatokkal** vagy szem√©lyesen azonos√≠that√≥ inform√°ci√≥kkal (PII) kapcsolatosak, amelyek azonos√≠that√≥ √©l≈ë szem√©lyekre vonatkoznak. Ez mag√°ban foglalja a [k√ºl√∂nf√©le nem szem√©lyes adatokat](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en), amelyek _egy√ºttesen_ azonos√≠tanak egy szem√©lyt. Az etikai kih√≠v√°sok kapcsol√≥dhatnak _adatv√©delemhez_, _adat tulajdonjoghoz_, √©s kapcsol√≥d√≥ t√©m√°khoz, mint _t√°j√©kozott beleegyez√©s_ √©s _szellemi tulajdonjogok_ a felhaszn√°l√≥k sz√°m√°ra.

Az algoritmus tervez√©s sor√°n a cselekv√©sek magukban foglalj√°k **adatk√©szletek** gy≈±jt√©s√©t √©s gondoz√°s√°t, majd ezek felhaszn√°l√°s√°t **adatmodellek** k√©pz√©s√©re √©s telep√≠t√©s√©re, amelyek val√≥s helyzetekben el≈ërejelz√©seket k√©sz√≠tenek vagy automatiz√°lt d√∂nt√©seket hoznak. Etikai kih√≠v√°sok mer√ºlhetnek fel _adatk√©szlet torz√≠t√°s_, _adatmin≈ës√©g_ probl√©m√°k, _m√©lt√°nytalans√°g_, √©s _f√©lrevezet√©s_ miatt az algoritmusokban‚Äîbele√©rtve n√©h√°ny szisztematikus jelleg≈± probl√©m√°t.

Mindk√©t esetben az etikai kih√≠v√°sok olyan ter√ºleteket emelnek ki, ahol cselekv√©seink konfliktusba ker√ºlhetnek k√∂z√∂s √©rt√©keinkkel. Ezek √©szlel√©s√©hez, enyh√≠t√©s√©hez, minimaliz√°l√°s√°hoz vagy megsz√ºntet√©s√©hez erk√∂lcsi "igen/nem" k√©rd√©seket kell feltenn√ºnk cselekv√©seinkkel kapcsolatban, majd sz√ºks√©g eset√©n korrekci√≥s int√©zked√©seket kell tenn√ºnk. N√©zz√ºnk meg n√©h√°ny etikai kih√≠v√°st √©s az √°ltaluk felvetett erk√∂lcsi k√©rd√©seket:

#### 2.1 Adattulajdonjog

Az adatgy≈±jt√©s gyakran szem√©lyes adatokat foglal mag√°ban, amelyek azonos√≠thatj√°k az adat alanyait. Az [adattulajdonjog](https://permission.io/blog/data-ownership) az adatok l√©trehoz√°s√°val, feldolgoz√°s√°val √©s terjeszt√©s√©vel kapcsolatos _ellen≈ërz√©sr≈ël_ √©s [_felhaszn√°l√≥i jogokr√≥l_](https://permission.io/blog/data-ownership) sz√≥l.

Az erk√∂lcsi k√©rd√©sek, amelyeket fel kell tenn√ºnk:
 * Ki birtokolja az adatokat? (felhaszn√°l√≥ vagy szervezet)
 * Milyen jogokkal rendelkeznek az adat alanyai? (pl. hozz√°f√©r√©s, t√∂rl√©s, hordozhat√≥s√°g)
 * Milyen jogokkal rendelkeznek a szervezetek? (pl. rosszindulat√∫ felhaszn√°l√≥i v√©lem√©nyek helyesb√≠t√©se)

#### 2.2 T√°j√©kozott beleegyez√©s

A [t√°j√©kozott beleegyez√©s](https://legaldictionary.net/informed-consent/) azt jelenti, hogy a felhaszn√°l√≥k beleegyeznek egy cselekv√©sbe (p√©ld√°ul adatgy≈±jt√©sbe) a relev√°ns t√©nyek teljes meg√©rt√©s√©vel, bele√©rtve a c√©lt, a potenci√°lis kock√°zatokat √©s az alternat√≠v√°kat.

Itt felmer√ºl≈ë k√©rd√©sek:
 * A felhaszn√°l√≥ (adat alany) enged√©lyt adott az adatok r√∂gz√≠t√©s√©re √©s felhaszn√°l√°s√°ra?
 * A felhaszn√°l√≥ meg√©rtette, hogy mi√©rt gy≈±jt√∂tt√©k az adatokat?
 * A felhaszn√°l√≥ meg√©rtette a r√©szv√©tel√©b≈ël sz√°rmaz√≥ potenci√°lis kock√°zatokat?

#### 2.3 Szellemi tulajdon

A [szellemi tulajdon](https://en.wikipedia.org/wiki/Intellectual_property) az emberi kezdem√©nyez√©sb≈ël sz√°rmaz√≥ immateri√°lis alkot√°sokra utal, amelyek _gazdas√°gi √©rt√©kkel_ b√≠rhatnak egy√©nek vagy v√°llalkoz√°sok sz√°m√°ra.

Itt felmer√ºl≈ë k√©rd√©sek:
 * A gy≈±jt√∂tt adatok gazdas√°gi √©rt√©kkel b√≠rnak-e egy felhaszn√°l√≥ vagy v√°llalkoz√°s sz√°m√°ra?
 * Van-e a **felhaszn√°l√≥nak** szellemi tulajdona itt?
 * Van-e a **szervezetnek** szellemi tulajdona itt?
 * Ha ezek a jogok l√©teznek, hogyan v√©dj√ºk ≈ëket?

#### 2.4 Adatv√©delem

Az [adatv√©delem](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) vagy inform√°ci√≥s mag√°n√©let a felhaszn√°l√≥i mag√°n√©let meg≈ërz√©s√©re √©s a felhaszn√°l√≥i identit√°s v√©delm√©re vonatkozik a szem√©lyesen azonos√≠that√≥ inform√°ci√≥k tekintet√©ben.

Itt felmer√ºl≈ë k√©rd√©sek:
 * A felhaszn√°l√≥k (szem√©lyes) adatai v√©dettek-e a hackel√©sekkel √©s sziv√°rg√°sokkal szemben?
 * A felhaszn√°l√≥k adatai csak jogosult felhaszn√°l√≥k √©s kontextusok sz√°m√°ra hozz√°f√©rhet≈ëk?
 * A felhaszn√°l√≥k anonimit√°sa megmarad-e, amikor az adatokat megosztj√°k vagy terjesztik?
 * Lehet-e egy felhaszn√°l√≥t azonos√≠tani anonimiz√°lt adatk√©szletekb≈ël?

#### 2.5 Az elfeledtet√©s joga

Az [elfeledtet√©s joga](https://en
* T√ºkr√∂zi az inform√°ci√≥ _pontosan_ a val√≥s√°got?

#### 2.8 Algoritmusok m√©lt√°nyoss√°ga

[Algoritmusok m√©lt√°nyoss√°ga](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) azt vizsg√°lja, hogy az algoritmus tervez√©se szisztematikusan diszkrimin√°lja-e az adatk√∂zl≈ëk bizonyos alcsoportjait, ami [potenci√°lis k√°rokat](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) okozhat az _eloszt√°sban_ (ahol er≈ëforr√°sokat tagadnak meg vagy tartanak vissza az adott csoportt√≥l) √©s a _szolg√°ltat√°s min≈ës√©g√©ben_ (ahol az AI nem olyan pontos bizonyos alcsoportok eset√©ben, mint m√°sokn√°l).

A k√∂vetkez≈ë k√©rd√©seket √©rdemes megvizsg√°lni:
* √ârt√©kelt√ºk-e a modell pontoss√°g√°t k√ºl√∂nb√∂z≈ë alcsoportok √©s felt√©telek eset√©ben?
* Vizsg√°ltuk-e a rendszert potenci√°lis k√°rok (pl. sztereotipiz√°l√°s) szempontj√°b√≥l?
* Tudjuk-e m√≥dos√≠tani az adatokat vagy √∫jratan√≠tani a modelleket az azonos√≠tott k√°rok enyh√≠t√©se √©rdek√©ben?

Fedezze fel az olyan forr√°sokat, mint az [AI m√©lt√°nyoss√°gi ellen≈ërz≈ëlist√°k](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA), hogy t√∂bbet megtudjon.

#### 2.9 F√©lrevezet√©s

[Adatok f√©lrevezet√©se](https://www.sciencedirect.com/topics/computer-science/misrepresentation) arr√≥l sz√≥l, hogy vajon ≈ëszint√©n k√∂z√∂lt adatokb√≥l sz√°rmaz√≥ betekint√©seket haszn√°lunk-e fel megt√©veszt≈ë m√≥don egy k√≠v√°nt narrat√≠va t√°mogat√°s√°ra.

A k√∂vetkez≈ë k√©rd√©seket √©rdemes megvizsg√°lni:
* Jelent√ºnk-e be hi√°nyos vagy pontatlan adatokat?
* √ögy vizualiz√°ljuk-e az adatokat, hogy f√©lrevezet≈ë k√∂vetkeztet√©seket vonjanak le bel≈ël√ºk?
* Haszn√°lunk-e szelekt√≠v statisztikai technik√°kat az eredm√©nyek manipul√°l√°s√°ra?
* Vannak-e alternat√≠v magyar√°zatok, amelyek m√°s k√∂vetkeztet√©st k√≠n√°lhatnak?

#### 2.10 Szabad v√°laszt√°s
A [szabad v√°laszt√°s ill√∫zi√≥ja](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) akkor fordul el≈ë, amikor a rendszer ‚Äûv√°laszt√°si architekt√∫r√°i‚Äù d√∂nt√©shoz√≥ algoritmusokat haszn√°lnak arra, hogy az embereket egy prefer√°lt eredm√©ny fel√© terelj√©k, mik√∂zben l√°tsz√≥lag lehet≈ës√©geket √©s kontrollt k√≠n√°lnak nekik. Ezek a [s√∂t√©t mint√°k](https://www.darkpatterns.org/) t√°rsadalmi √©s gazdas√°gi k√°rokat okozhatnak a felhaszn√°l√≥knak. Mivel a felhaszn√°l√≥i d√∂nt√©sek befoly√°solj√°k a viselked√©si profilokat, ezek a cselekv√©sek potenci√°lisan meghat√°rozhatj√°k a j√∂v≈ëbeli v√°laszt√°sokat, amelyek feler≈ës√≠thetik vagy kiterjeszthetik ezen k√°rok hat√°s√°t.

A k√∂vetkez≈ë k√©rd√©seket √©rdemes megvizsg√°lni:
* Meg√©rtette-e a felhaszn√°l√≥ annak a v√°laszt√°snak a k√∂vetkezm√©nyeit?
* Tudott-e a felhaszn√°l√≥ (alternat√≠v) v√°laszt√°si lehet≈ës√©gekr≈ël √©s azok el≈ënyeir≈ël √©s h√°tr√°nyair√≥l?
* Visszavonhatja-e a felhaszn√°l√≥ egy automatiz√°lt vagy befoly√°solt d√∂nt√©st k√©s≈ëbb?

### 3. Esettanulm√°nyok

Ahhoz, hogy ezeket az etikai kih√≠v√°sokat val√≥s k√∂rnyezetben meg√©rts√ºk, √©rdemes olyan esettanulm√°nyokat megvizsg√°lni, amelyek r√°vil√°g√≠tanak az egy√©nekre √©s a t√°rsadalomra gyakorolt potenci√°lis k√°rokra √©s k√∂vetkezm√©nyekre, amikor az ilyen etikai v√©ts√©geket figyelmen k√≠v√ºl hagyj√°k.

√çme n√©h√°ny p√©lda:

| Etikai kih√≠v√°s | Esettanulm√°ny | 
|--- |--- |
| **T√°j√©kozott beleegyez√©s** | 1972 - [Tuskegee szifilisz tanulm√°ny](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Az afrikai-amerikai f√©rfiak, akik r√©szt vettek a tanulm√°nyban, ingyenes orvosi ell√°t√°st √≠g√©rtek, _de megt√©vesztett√©k_ ≈ëket a kutat√≥k, akik nem t√°j√©koztatt√°k ≈ëket a diagn√≥zisukr√≥l vagy a kezel√©s el√©rhet≈ës√©g√©r≈ël. Sok alany meghalt, √©s partnereik vagy gyermekeik is √©rintettek voltak; a tanulm√°ny 40 √©vig tartott. | 
| **Adatv√©delem** | 2007 - A [Netflix adatd√≠j](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) kutat√≥knak _10M anonimiz√°lt film√©rt√©kel√©st_ biztos√≠tott 50K √ºgyf√©lt≈ël, hogy jav√≠ts√°k az aj√°nl√°si algoritmusokat. Azonban a kutat√≥k k√©pesek voltak az anonimiz√°lt adatokat szem√©lyazonos√≠t√≥ adatokkal √∂sszekapcsolni _k√ºls≈ë adatb√°zisokban_ (pl. IMDb kommentek), hat√©konyan ‚Äûdeanonimiz√°lva‚Äù n√©h√°ny Netflix el≈ëfizet≈ët.|
| **Gy≈±jt√©si torz√≠t√°s** | 2013 - Boston v√°rosa [kifejlesztette a Street Bump alkalmaz√°st](https://www.boston.gov/transportation/street-bump), amely lehet≈ëv√© tette a polg√°rok sz√°m√°ra, hogy k√°ty√∫kat jelentsenek, jobb √∫th√°l√≥zati adatokat biztos√≠tva a v√°rosnak a probl√©m√°k megtal√°l√°s√°hoz √©s jav√≠t√°s√°hoz. Azonban [az alacsonyabb j√∂vedelm≈± csoportoknak kevesebb hozz√°f√©r√©s√ºk volt aut√≥khoz √©s telefonokhoz](https://hbr.org/2013/04/the-hidden-biases-in-big-data), √≠gy az ≈ë √∫th√°l√≥zati probl√©m√°ik l√°thatatlanok maradtak az alkalmaz√°sban. A fejleszt≈ëk akad√©mikusokkal dolgoztak egy√ºtt az _egyenl≈ë hozz√°f√©r√©s √©s digit√°lis szakad√©k_ k√©rd√©seinek megold√°sa √©rdek√©ben. |
| **Algoritmusok m√©lt√°nyoss√°ga** | 2018 - Az MIT [Gender Shades tanulm√°ny](http://gendershades.org/overview.html) √©rt√©kelte a nemek oszt√°lyoz√°s√°ra szolg√°l√≥ AI term√©kek pontoss√°g√°t, felt√°rva a pontoss√°gi hi√°nyoss√°gokat a n≈ëk √©s sz√≠nes b≈ër≈±ek eset√©ben. Egy [2019-es Apple Card](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) √∫gy t≈±nt, hogy kevesebb hitelt k√≠n√°l a n≈ëknek, mint a f√©rfiaknak. Mindkett≈ë az algoritmikus torz√≠t√°s probl√©m√°it illusztr√°lta, amelyek t√°rsadalmi-gazdas√°gi k√°rokat okoztak.|
| **Adatok f√©lrevezet√©se** | 2020 - A [Georgia Eg√©szs√©g√ºgyi Miniszt√©rium COVID-19 grafikonokat tett k√∂zz√©](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening), amelyek f√©lrevezet≈ëen mutatt√°k a meger≈ës√≠tett esetek trendjeit, nem kronol√≥giai sorrendben az x-tengelyen. Ez a vizualiz√°ci√≥s tr√ºkk√∂k √°ltali f√©lrevezet√©st illusztr√°lja. |
| **Szabad v√°laszt√°s ill√∫zi√≥ja** | 2020 - Az ABCmouse tanul√°si alkalmaz√°s [10M doll√°rt fizetett az FTC panasz rendez√©s√©re](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/), ahol a sz√ºl≈ëk olyan el≈ëfizet√©sek√©rt fizettek, amelyeket nem tudtak lemondani. Ez a v√°laszt√°si architekt√∫r√°k s√∂t√©t mint√°it illusztr√°lja, ahol a felhaszn√°l√≥kat potenci√°lisan k√°ros d√∂nt√©sek fel√© terelt√©k. |
| **Adatv√©delem √©s felhaszn√°l√≥i jogok** | 2021 - A Facebook [adatv√©delmi incidens](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) 530M felhaszn√°l√≥ adatait tette ki, ami 5B doll√°ros egyezs√©get eredm√©nyezett az FTC-vel. Azonban megtagadta a felhaszn√°l√≥k √©rtes√≠t√©s√©t az incidensr≈ël, megs√©rtve a felhaszn√°l√≥i jogokat az adat√°tl√°that√≥s√°g √©s hozz√°f√©r√©s ter√©n. |

Szeretne tov√°bbi esettanulm√°nyokat felfedezni? N√©zze meg ezeket a forr√°sokat:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - etikai dilemm√°k k√ºl√∂nb√∂z≈ë ipar√°gakban.
* [Data Science Ethics kurzus](https://www.coursera.org/learn/data-science-ethics#syllabus) - m√©rf√∂ldk≈ënek sz√°m√≠t√≥ esettanulm√°nyok.
* [Hol mentek f√©lre a dolgok](https://deon.drivendata.org/examples/) - Deon ellen≈ërz≈ëlista p√©ld√°kkal.

> üö® Gondoljon azokra az esettanulm√°nyokra, amelyeket l√°tott ‚Äì tapasztalt-e, vagy √©rintett√©k-e hasonl√≥ etikai kih√≠v√°sok az √©let√©ben? Tud-e legal√°bb egy m√°sik esettanulm√°nyt, amely illusztr√°lja az ebben a szakaszban t√°rgyalt etikai kih√≠v√°sok egyik√©t?

## Alkalmazott etika

Besz√©lt√ºnk az etikai fogalmakr√≥l, kih√≠v√°sokr√≥l √©s esettanulm√°nyokr√≥l val√≥s k√∂rnyezetben. De hogyan kezdhetj√ºk el az etikai elvek √©s gyakorlatok _alkalmaz√°s√°t_ a projektjeinkben? √âs hogyan _val√≥s√≠thatjuk meg_ ezeket a gyakorlatokat a jobb ir√°ny√≠t√°s √©rdek√©ben? N√©zz√ºnk meg n√©h√°ny val√≥s megold√°st:

### 1. Szakmai k√≥dexek

A szakmai k√≥dexek egy lehet≈ës√©get k√≠n√°lnak a szervezetek sz√°m√°ra, hogy ‚Äû√∂szt√∂n√∂zz√©k‚Äù tagjaikat az etikai elveik √©s k√ºldet√©s√ºk t√°mogat√°s√°ra. A k√≥dexek _erk√∂lcsi ir√°nymutat√°sok_ a szakmai viselked√©shez, seg√≠tve az alkalmazottakat vagy tagokat olyan d√∂nt√©sek meghozatal√°ban, amelyek √∂sszhangban vannak a szervezet√ºk elveivel. Csak annyira hat√©konyak, amennyire a tagok √∂nk√©ntes megfelel√©se; azonban sok szervezet tov√°bbi jutalmakat √©s b√ºntet√©seket k√≠n√°l, hogy motiv√°lja a tagok megfelel√©s√©t.

P√©ld√°k:
* [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Etikai K√≥dex
* [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Magatart√°si K√≥dex (2013-ban k√©sz√ºlt)
* [ACM Etikai K√≥dex √©s Szakmai Magatart√°s](https://www.acm.org/code-of-ethics) (1993 √≥ta)

> üö® Tagja-e valamilyen szakmai m√©rn√∂ki vagy adatkutat√°si szervezetnek? N√©zze meg a weboldalukat, hogy meghat√°roznak-e szakmai etikai k√≥dexet. Mit mond ez az etikai elveikr≈ël? Hogyan ‚Äû√∂szt√∂nzik‚Äù a tagokat a k√≥dex k√∂vet√©s√©re?

### 2. Etikai ellen≈ërz≈ëlist√°k

M√≠g a szakmai k√≥dexek meghat√°rozz√°k a gyakorl√≥k √°ltal megk√∂vetelt _etikai viselked√©st_, [ismert korl√°tokkal](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) rendelkeznek a v√©grehajt√°sban, k√ºl√∂n√∂sen nagyszab√°s√∫ projektek eset√©ben. Ehelyett sok adatkutat√°si szak√©rt≈ë [ellen≈ërz≈ëlist√°kat javasol](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), amelyek **√∂sszekapcsolj√°k az elveket a gyakorlatokkal** determinisztikusabb √©s cselekv≈ëk√©pesebb m√≥don.

Az ellen≈ërz≈ëlist√°k a k√©rd√©seket ‚Äûigen/nem‚Äù feladatokk√° alak√≠tj√°k, amelyek operacionaliz√°lhat√≥k, lehet≈ëv√© t√©ve, hogy nyomon k√∂vess√©k ≈ëket a szok√°sos term√©kkiad√°si munkafolyamatok r√©szek√©nt.

P√©ld√°k:
* [Deon](https://deon.drivendata.org/) - √°ltal√°nos c√©l√∫ adatetikai ellen≈ërz≈ëlista, amelyet [ipar√°gi aj√°nl√°sokb√≥l](https://deon.drivendata.org/#checklist-citations) hoztak l√©tre, parancssori eszk√∂zzel a k√∂nny≈± integr√°ci√≥ √©rdek√©ben.
* [Adatv√©delmi audit ellen≈ërz≈ëlista](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - √°ltal√°nos ir√°nymutat√°st ny√∫jt az inform√°ci√≥kezel√©si gyakorlatokhoz jogi √©s t√°rsadalmi kitetts√©g szempontj√°b√≥l.
* [AI m√©lt√°nyoss√°gi ellen≈ërz≈ëlista](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - AI szakemberek √°ltal l√©trehozva, hogy t√°mogass√°k a m√©lt√°nyoss√°gi ellen≈ërz√©sek bevezet√©s√©t √©s integr√°ci√≥j√°t az AI fejleszt√©si ciklusokba.
* [22 k√©rd√©s az adatok √©s AI etik√°j√°r√≥l](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - nyitottabb keretrendszer, amelyet az etikai k√©rd√©sek kezdeti felt√°r√°s√°ra terveztek a tervez√©s, megval√≥s√≠t√°s √©s szervezeti kontextusokban.

### 3. Etikai szab√°lyoz√°sok

Az etika k√∂z√∂s √©rt√©kek meghat√°roz√°s√°r√≥l √©s a helyes cselekv√©sr≈ël sz√≥l _√∂nk√©ntesen_. **Megfelel√©s** arr√≥l sz√≥l, hogy _k√∂vetj√ºk a t√∂rv√©nyt_, ha √©s ahol meghat√°rozt√°k. **Ir√°ny√≠t√°s** sz√©les k√∂rben lefedi az √∂sszes m√≥dot, ahogyan a szervezetek m≈±k√∂dnek az etikai elvek √©rv√©nyes√≠t√©se √©s a meghat√°rozott t√∂rv√©nyek betart√°sa √©rdek√©ben.

Ma az ir√°ny√≠t√°s k√©t form√°t √∂lt a szervezeteken bel√ºl. El≈ësz√∂r is, az **etikus AI** elvek meghat√°roz√°s√°r√≥l √©s a gyakorlatok l√©trehoz√°s√°r√≥l sz√≥l, hogy operacionaliz√°lj√°k az elfogad√°st az √∂sszes AI-val kapcsolatos projektben a szervezeten bel√ºl. M√°sodszor, a korm√°ny √°ltal el≈ë√≠rt **adatv√©delmi szab√°lyoz√°sok** betart√°s√°r√≥l sz√≥l azokban a r√©gi√≥kban, ahol m≈±k√∂dik.

Adatv√©delmi √©s adatkezel√©si szab√°lyoz√°sok p√©ld√°i:

* `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - szab√°lyozza a _sz√∂vets√©gi korm√°ny_ szem√©lyes adatok gy≈±jt√©s√©t, haszn√°lat√°t √©s k√∂zz√©t√©tel√©t.
* `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - v√©di a szem√©lyes eg√©szs√©g√ºgyi adatokat.
* `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - v√©di a 13 √©v alatti gyermekek adatv√©delm√©t.
* `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - felhaszn√°l√≥i jogokat, adatv√©delmet √©s adatbiztons√°got biztos√≠t.
* `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) t√∂bb _jogot_ biztos√≠t a fogyaszt√≥knak a (szem√©lyes) adataik felett.
* `2021`, K√≠na [Szem√©lyes Adatv√©delmi T√∂rv√©nye](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) √©ppen elfogadva, l√©trehozva az egyik leger≈ësebb online adatv√©delmi szab√°lyoz√°st vil√°gszerte.

> üö® Az Eur√≥pai Uni√≥ √°ltal meghat√°rozott GDPR (General Data Protection Regulation) ma az egyik legbefoly√°sosabb adatv√©delmi szab√°lyoz√°s. Tudta, hogy ez [8 felhaszn√°l√≥i jogot](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) is meghat√°roz az √°llampolg√°rok digit√°lis adatv√©delm√©nek √©s szem√©lyes adat
* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lecke az igazs√°goss√°gr√≥l, a Microsoftt√≥l.
* [A Felel≈ës MI Alapelvei](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - ingyenes tanul√°si √∫tvonal a Microsoft Learn-t≈ël.
* [Etika √©s Adattudom√°ny](https://resources.oreilly.com/examples/0636920203964) - O'Reilly e-k√∂nyv (M. Loukides, H. Mason √©s m√°sok)
* [Adattudom√°nyi Etika](https://www.coursera.org/learn/data-science-ethics#syllabus) - online kurzus a Michigani Egyetemt≈ël.
* [Etika Kibontva](https://ethicsunwrapped.utexas.edu/case-studies) - esettanulm√°nyok a Texasi Egyetemt≈ël.

# Feladat

[√çrj egy esettanulm√°nyt az adatetik√°r√≥l](assignment.md)

---

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az [Co-op Translator](https://github.com/Azure/co-op-translator) AI ford√≠t√°si szolg√°ltat√°s seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.