<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ce95884566a74db72572cd51f0cb25ad",
  "translation_date": "2025-09-06T13:48:00+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "he"
}
-->
# מבוא קצר לסטטיסטיקה ותורת ההסתברות

|![ סקיצה מאת [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| סטטיסטיקה והסתברות - _סקיצה מאת [@nitya](https://twitter.com/nitya)_ |

סטטיסטיקה ותורת ההסתברות הן שני תחומים מתמטיים הקשורים זה לזה באופן הדוק, והם בעלי חשיבות רבה במדעי הנתונים. ניתן לעבוד עם נתונים גם ללא ידע מעמיק במתמטיקה, אך עדיין עדיף להכיר לפחות כמה מושגים בסיסיים. כאן נציג מבוא קצר שיעזור לכם להתחיל.

[![סרטון מבוא](../../../../translated_images/video-prob-and-stats.e4282e5efa2f2543400843ed98b1057065c9600cebfc8a728e8931b5702b2ae4.he.png)](https://youtu.be/Z5Zy85g4Yjw)

## [שאלון לפני השיעור](https://ff-quizzes.netlify.app/en/ds/quiz/6)

## הסתברות ומשתנים אקראיים

**הסתברות** היא מספר בין 0 ל-1 שמבטא עד כמה **אירוע** מסוים הוא סביר. היא מוגדרת כמספר התוצאות החיוביות (שמובילות לאירוע), מחולק במספר הכולל של התוצאות, בהנחה שכל התוצאות הן בעלות הסתברות שווה. לדוגמה, כאשר אנו מטילים קובייה, ההסתברות לקבל מספר זוגי היא 3/6 = 0.5.

כשמדברים על אירועים, אנו משתמשים ב**משתנים אקראיים**. לדוגמה, המשתנה האקראי שמייצג את המספר שמתקבל בהטלת קובייה יכול לקבל ערכים בין 1 ל-6. קבוצת המספרים מ-1 עד 6 נקראת **מרחב הדגימה**. ניתן לדבר על ההסתברות שמשתנה אקראי יקבל ערך מסוים, לדוגמה P(X=3)=1/6.

המשתנה האקראי בדוגמה הקודמת נקרא **בדיד**, מכיוון שמרחב הדגימה שלו ניתן לספירה, כלומר יש ערכים נפרדים שניתן למנות. ישנם מקרים שבהם מרחב הדגימה הוא טווח של מספרים ממשיים, או כל קבוצת המספרים הממשיים. משתנים כאלה נקראים **רציפים**. דוגמה טובה לכך היא הזמן שבו מגיע האוטובוס.

## התפלגות הסתברות

במקרה של משתנים אקראיים בדידים, קל לתאר את ההסתברות של כל אירוע באמצעות פונקציה P(X). עבור כל ערך *s* ממרחב הדגימה *S*, הפונקציה תיתן מספר בין 0 ל-1, כך שסכום כל הערכים של P(X=s) עבור כל האירועים יהיה 1.

ההתפלגות הבדידה המוכרת ביותר היא **התפלגות אחידה**, שבה יש מרחב דגימה של N אלמנטים, עם הסתברות שווה של 1/N לכל אחד מהם.

קשה יותר לתאר את התפלגות ההסתברות של משתנה רציף, עם ערכים שנלקחים מטווח מסוים [a,b], או מכל קבוצת המספרים הממשיים ℝ. קחו לדוגמה את זמן הגעת האוטובוס. למעשה, עבור כל זמן הגעה מדויק *t*, ההסתברות שהאוטובוס יגיע בדיוק בזמן הזה היא 0!

> עכשיו אתם יודעים שאירועים עם הסתברות 0 מתרחשים, ולעיתים קרובות! לפחות בכל פעם שהאוטובוס מגיע!

ניתן לדבר רק על ההסתברות שמשתנה ייפול בטווח ערכים מסוים, למשל P(t<sub>1</sub>≤X<t<sub>2</sub>). במקרה זה, התפלגות ההסתברות מתוארת באמצעות **פונקציית צפיפות הסתברות** p(x), כך ש-

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../translated_images/probability-density.a8aad29f17a14afb519b407c7b6edeb9f3f9aa5f69c9e6d9445f604e5f8a2bf7.he.png)

האנלוג הרציף של התפלגות אחידה נקרא **אחידה רציפה**, שמוגדרת על טווח סופי. ההסתברות שהערך X ייפול בטווח באורך l היא פרופורציונלית ל-l, ועולה עד 1.

התפלגות חשובה נוספת היא **התפלגות נורמלית**, עליה נדבר בפירוט בהמשך.

## ממוצע, שונות וסטיית תקן

נניח שאנו לוקחים רצף של n דגימות של משתנה אקראי X: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. ניתן להגדיר את **הממוצע** (או **הממוצע האריתמטי**) של הרצף באופן המסורתי כ-(x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. ככל שנגדיל את גודל המדגם (כלומר ניקח את הגבול עם n→∞), נקבל את הממוצע (שנקרא גם **תוחלת**) של ההתפלגות. נסמן את התוחלת כ-**E**(x).

> ניתן להראות כי עבור כל התפלגות בדידה עם ערכים {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} והסתברויות מתאימות p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, התוחלת תהיה E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

כדי לזהות עד כמה הערכים מפוזרים, ניתן לחשב את השונות σ<sup>2</sup> = ∑(x<sub>i</sub> - μ)<sup>2</sup>/n, כאשר μ הוא הממוצע של הרצף. הערך σ נקרא **סטיית תקן**, ו-σ<sup>2</sup> נקרא **שונות**.

## שכיח, חציון ורבעונים

לפעמים, הממוצע אינו מייצג באופן מספק את הערך "הטיפוסי" של הנתונים. לדוגמה, כאשר ישנם כמה ערכים קיצוניים שמחוץ לטווח, הם יכולים להשפיע על הממוצע. אינדיקציה טובה נוספת היא **חציון**, ערך כזה שחצי מהנתונים נמוכים ממנו, והחצי השני - גבוהים ממנו.

כדי לעזור לנו להבין את התפלגות הנתונים, כדאי לדבר על **רבעונים**:

* הרבעון הראשון, או Q1, הוא ערך כזה ש-25% מהנתונים נמוכים ממנו
* הרבעון השלישי, או Q3, הוא ערך כזה ש-75% מהנתונים נמוכים ממנו

ניתן לייצג באופן גרפי את הקשר בין החציון לרבעונים בדיאגרמה שנקראת **תיבת נתונים**:

<img src="images/boxplot_explanation.png" alt="הסבר על תיבת נתונים" width="50%">

כאן אנו גם מחשבים את **טווח הרבעונים** IQR=Q3-Q1, ואת מה שנקרא **ערכים חריגים** - ערכים שנמצאים מחוץ לגבולות [Q1-1.5*IQR,Q3+1.5*IQR].

עבור התפלגות סופית שמכילה מספר קטן של ערכים אפשריים, ערך "טיפוסי" טוב הוא זה שמופיע בתדירות הגבוהה ביותר, שנקרא **שכיח**. הוא מיושם לעיתים קרובות על נתונים קטגוריים, כמו צבעים. לדוגמה, אם יש לנו שתי קבוצות של אנשים - כאלה שמעדיפים מאוד אדום, ואחרים שמעדיפים כחול. אם נקודד צבעים במספרים, הערך הממוצע לצבע המועדף יהיה איפשהו בספקטרום כתום-ירוק, מה שלא מצביע על ההעדפה האמיתית של אף אחת מהקבוצות. עם זאת, השכיח יהיה אחד הצבעים, או שניהם, אם מספר האנשים שמעדיפים אותם שווה (במקרה זה נקרא לדגימה **רב-שכיחית**).

## נתונים מהעולם האמיתי

כאשר אנו מנתחים נתונים מהעולם האמיתי, הם לעיתים קרובות אינם משתנים אקראיים במובן זה שאיננו מבצעים ניסויים עם תוצאה לא ידועה. לדוגמה, קחו קבוצת שחקני בייסבול, ונתוני הגוף שלהם, כמו גובה, משקל וגיל. המספרים הללו אינם בדיוק אקראיים, אך עדיין ניתן ליישם את אותם מושגים מתמטיים. לדוגמה, רצף של משקלים של אנשים יכול להיחשב כרצף של ערכים שנלקחו ממשתנה אקראי כלשהו. להלן רצף המשקלים של שחקני בייסבול אמיתיים מ-[ליגת הבייסבול הראשית](http://mlb.mlb.com/index.jsp), שנלקח מ-[מערך נתונים זה](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (לנוחיותכם, מוצגים רק 20 הערכים הראשונים):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **הערה**: כדי לראות דוגמה לעבודה עם מערך נתונים זה, עיינו ב-[מחברת המצורפת](notebook.ipynb). ישנם גם מספר אתגרים לאורך השיעור, ואתם יכולים להשלים אותם על ידי הוספת קוד למחברת זו. אם אינכם בטוחים כיצד לעבוד עם נתונים, אל דאגה - נחזור לעבודה עם נתונים באמצעות Python בשלב מאוחר יותר. אם אינכם יודעים כיצד להריץ קוד ב-Jupyter Notebook, עיינו ב-[מאמר זה](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

להלן תיבת נתונים המציגה ממוצע, חציון ורבעונים עבור הנתונים שלנו:

![תיבת נתונים של משקל](../../../../translated_images/weight-boxplot.1dbab1c03af26f8a008fff4e17680082c8ab147d6df646cbac440bbf8f5b9c42.he.png)

מכיוון שהנתונים שלנו מכילים מידע על **תפקידים** שונים של שחקנים, ניתן גם ליצור תיבת נתונים לפי תפקיד - זה יאפשר לנו להבין כיצד ערכי הפרמטרים משתנים בין התפקידים. הפעם נבחן את הגובה:

![תיבת נתונים לפי תפקיד](../../../../translated_images/boxplot_byrole.036b27a1c3f52d42f66fba2324ec5cde0a1bca6a01a619eeb0ce7cd054b2527b.he.png)

דיאגרמה זו מציעה כי, בממוצע, גובהם של שחקני בסיס ראשון גבוה יותר מגובהם של שחקני בסיס שני. בהמשך השיעור נלמד כיצד ניתן לבדוק את ההשערה הזו בצורה פורמלית יותר, וכיצד להראות שהנתונים שלנו משמעותיים מבחינה סטטיסטית כדי להוכיח זאת.

> כאשר עובדים עם נתונים מהעולם האמיתי, אנו מניחים שכל נקודות הנתונים הן דגימות שנלקחו מהתפלגות הסתברות כלשהי. הנחה זו מאפשרת לנו ליישם טכניקות של למידת מכונה ולבנות מודלים חיזוי יעילים.

כדי לראות מהי התפלגות הנתונים שלנו, ניתן לשרטט גרף שנקרא **היסטוגרמה**. ציר ה-X יכיל מספר של טווחי משקל שונים (מה שנקרא **תאים**), וציר ה-Y יראה את מספר הפעמים שהדגימה של המשתנה האקראי הייתה בתוך טווח נתון.

![היסטוגרמה של נתונים מהעולם האמיתי](../../../../translated_images/weight-histogram.bfd00caf7fc30b145b21e862dba7def41c75635d5280de25d840dd7f0b00545e.he.png)

מההיסטוגרמה הזו ניתן לראות שכל הערכים מרוכזים סביב משקל ממוצע מסוים, וככל שמתרחקים מהמשקל הזה - פחות משקלים בערך זה מופיעים. כלומר, לא סביר שמשקלו של שחקן בייסבול יהיה שונה מאוד מהמשקל הממוצע. השונות של המשקלים מראה את המידה שבה המשקלים נוטים להיות שונים מהממוצע.

> אם ניקח משקלים של אנשים אחרים, לא מהליגה הבייסבול, סביר שהתפלגות תהיה שונה. עם זאת, צורת ההתפלגות תהיה זהה, אך הממוצע והשונות ישתנו. לכן, אם נלמד את המודל שלנו על שחקני בייסבול, סביר שהוא ייתן תוצאות שגויות כאשר ניישם אותו על סטודנטים באוניברסיטה, מכיוון שההתפלגות הבסיסית שונה.

## התפלגות נורמלית

התפלגות המשקלים שראינו לעיל היא מאוד טיפוסית, ורבים מהמדדים בעולם האמיתי עוקבים אחר אותו סוג של התפלגות, אך עם ממוצע ושונות שונים. התפלגות זו נקראת **התפלגות נורמלית**, והיא משחקת תפקיד חשוב מאוד בסטטיסטיקה.

שימוש בהתפלגות נורמלית הוא דרך נכונה לייצר משקלים אקראיים של שחקני בייסבול פוטנציאליים. ברגע שאנו יודעים את משקל הממוצע `mean` ואת סטיית התקן `std`, ניתן לייצר 1000 דגימות משקל בדרך הבאה:
```python
samples = np.random.normal(mean,std,1000)
```

אם נשרטט את ההיסטוגרמה של הדגימות שנוצרו, נראה תמונה דומה מאוד לזו שהוצגה לעיל. ואם נגדיל את מספר הדגימות ואת מספר התאים, נוכל ליצור תמונה של התפלגות נורמלית שקרובה יותר לאידיאל:

![התפלגות נורמלית עם ממוצע=0 וסטיית תקן=1](../../../../translated_images/normal-histogram.dfae0d67c202137d552d0015fb87581eca263925e512404f3c12d8885315432e.he.png)

*התפלגות נורמלית עם ממוצע=0 וסטיית תקן=1*

## רווחי סמך

כשמדברים על משקלם של שחקני בייסבול, אנו מניחים שיש **משתנה אקראי W** שמייצג את התפלגות ההסתברות האידיאלית של משקלם של כל שחקני הבייסבול (מה שנקרא **אוכלוסייה**). רצף המשקלים שלנו מייצג תת-קבוצה של כל שחקני הבייסבול שאנו קוראים לה **מדגם**. שאלה מעניינת היא, האם ניתן לדעת את הפרמטרים של התפלגות W, כלומר את הממוצע והשונות של האוכלוסייה?

התשובה הפשוטה ביותר תהיה לחשב את הממוצע והשונות של המדגם שלנו. עם זאת, ייתכן שהמדגם האקראי שלנו אינו מייצג באופן מדויק את האוכלוסייה המלאה. לכן יש היגיון לדבר על **רווח סמך**.

> **רווח סמך** הוא הערכה של הממוצע האמיתי של האוכלוסייה בהתחשב במדגם שלנו, שהיא מדויקת ברמת הסתברות מסוימת (או **רמת ביטחון**).

נניח שיש לנו מדגם X...
<תת>
1</sub>, ..., X<sub>n</sub> מההתפלגות שלנו. בכל פעם שנדגום מדגם מההתפלגות, נקבל ערך ממוצע שונה μ. לכן ניתן להתייחס ל-μ כמשתנה מקרי. **רווח סמך** עם רמת ביטחון p הוא זוג ערכים (L<sub>p</sub>,R<sub>p</sub>), כך ש-**P**(L<sub>p</sub>≤μ≤R<sub>p</sub>) = p, כלומר ההסתברות שהממוצע הנמדד ייפול בתוך הרווח שווה ל-p.

הדיון המלא על איך מחשבים רווחי סמך חורג מהמבוא הקצר שלנו. ניתן למצוא פרטים נוספים [בויקיפדיה](https://en.wikipedia.org/wiki/Confidence_interval). בקצרה, אנו מגדירים את ההתפלגות של ממוצע המדגם המחושב ביחס לממוצע האמיתי של האוכלוסייה, הנקראת **התפלגות סטודנט**.

> **עובדה מעניינת**: התפלגות סטודנט נקראת כך על שם המתמטיקאי ויליאם סילי גוסט, שפרסם את מאמרו תחת שם העט "סטודנט". הוא עבד במבשלת גינס, ולפי אחת הגרסאות, מעסיקו לא רצה שהציבור הרחב יידע שהם משתמשים במבחנים סטטיסטיים כדי לקבוע את איכות חומרי הגלם.

אם נרצה להעריך את הממוצע μ של האוכלוסייה שלנו עם רמת ביטחון p, נצטרך לקחת את *(1-p)/2-th percentile* מהתפלגות סטודנט A, שניתן לקחת מטבלאות או לחשב באמצעות פונקציות מובנות בתוכנות סטטיסטיות (כגון Python, R וכו'). אז הרווח עבור μ יינתן על ידי X±A*D/√n, כאשר X הוא הממוצע שהתקבל במדגם, ו-D הוא סטיית התקן.

> **הערה**: אנו גם מדלגים על הדיון במושג חשוב של [דרגות חופש](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), שהוא משמעותי בהקשר של התפלגות סטודנט. ניתן לעיין בספרים מקיפים יותר בסטטיסטיקה כדי להבין מושג זה לעומק.

דוגמה לחישוב רווח סמך עבור משקלים וגבהים ניתנת ב-[מחברות המצורפות](notebook.ipynb).

| p | ממוצע משקל |
|-----|-----------|
| 0.85 | 201.73±0.94 |
| 0.90 | 201.73±1.08 |
| 0.95 | 201.73±1.28 |

שימו לב שככל שההסתברות הביטחונית גבוהה יותר, כך רווח הסמך רחב יותר.

## בדיקת השערות

במאגר הנתונים של שחקני הבייסבול שלנו, ישנם תפקידים שונים לשחקנים, שניתן לסכם בטבלה הבאה (עיינו ב-[מחברת המצורפת](notebook.ipynb) כדי לראות כיצד לחשב טבלה זו):

| תפקיד | גובה | משקל | כמות |
|------|--------|--------|-------|
| Catcher | 72.723684 | 204.328947 | 76 |
| Designated_Hitter | 74.222222 | 220.888889 | 18 |
| First_Baseman | 74.000000 | 213.109091 | 55 |
| Outfielder | 73.010309 | 199.113402 | 194 |
| Relief_Pitcher | 74.374603 | 203.517460 | 315 |
| Second_Baseman | 71.362069 | 184.344828 | 58 |
| Shortstop | 71.903846 | 182.923077 | 52 |
| Starting_Pitcher | 74.719457 | 205.163636 | 221 |
| Third_Baseman | 73.044444 | 200.955556 | 45 |

ניתן להבחין שממוצע הגבהים של שחקני הבסיס הראשון גבוה מזה של שחקני הבסיס השני. לכן, ייתכן שנרצה להסיק ש-**שחקני הבסיס הראשון גבוהים יותר משחקני הבסיס השני**.

> הצהרה זו נקראת **השערה**, מכיוון שאיננו יודעים אם העובדה נכונה או לא.

עם זאת, לא תמיד ברור אם ניתן להסיק מסקנה זו. מהדיון לעיל אנו יודעים שלכל ממוצע יש רווח סמך משלו, ולכן ייתכן שההבדל הוא רק טעות סטטיסטית. אנו זקוקים לדרך פורמלית יותר לבדוק את ההשערה שלנו.

נחשב רווחי סמך בנפרד עבור גבהי שחקני הבסיס הראשון והשני:

| רמת ביטחון | שחקני בסיס ראשון | שחקני בסיס שני |
|------------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

ניתן לראות שבשום רמת ביטחון הרווחים אינם חופפים. זה מוכיח את ההשערה שלנו ששחקני הבסיס הראשון גבוהים יותר משחקני הבסיס השני.

באופן פורמלי יותר, הבעיה שאנו פותרים היא לבדוק אם **שתי התפלגויות הסתברות זהות**, או לפחות אם יש להן אותם פרמטרים. בהתאם להתפלגות, יש להשתמש במבחנים שונים. אם אנו יודעים שההתפלגויות שלנו נורמליות, נוכל להשתמש ב-**[מבחן t של סטודנט](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

במבחן t של סטודנט, אנו מחשבים את מה שנקרא **t-value**, שמצביע על ההבדל בין הממוצעים תוך התחשבות בשונות. הוכח ש-t-value עוקב אחרי **התפלגות סטודנט**, מה שמאפשר לנו לקבל את ערך הסף עבור רמת ביטחון נתונה **p** (ניתן לחשב זאת או לעיין בטבלאות מספריות). לאחר מכן נשווה את ה-t-value לערך הסף כדי לאשר או לדחות את ההשערה.

ב-Python, ניתן להשתמש בחבילת **SciPy**, הכוללת את הפונקציה `ttest_ind` (בנוסף לפונקציות סטטיסטיות שימושיות רבות אחרות!). פונקציה זו מחשבת עבורנו את ה-t-value, וגם מבצעת חיפוש הפוך של ערך הביטחון p, כך שנוכל פשוט להסתכל על רמת הביטחון כדי להסיק מסקנות.

לדוגמה, ההשוואה שלנו בין גבהי שחקני הבסיס הראשון והשני נותנת את התוצאות הבאות: 
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
במקרה שלנו, ערך ה-p נמוך מאוד, מה שמעיד על כך שיש ראיות חזקות לכך ששחקני הבסיס הראשון גבוהים יותר.

ישנם גם סוגים אחרים של השערות שנרצה לבדוק, לדוגמה:
* להוכיח שמדגם מסוים עוקב אחרי התפלגות מסוימת. במקרה שלנו הנחנו שהגבהים מתפלגים נורמלית, אך יש צורך באימות סטטיסטי פורמלי.
* להוכיח שממוצע של מדגם תואם לערך מוגדר מראש.
* להשוות ממוצעים של מספר מדגמים (לדוגמה, מה ההבדל ברמות האושר בין קבוצות גיל שונות).

## חוק המספרים הגדולים ותיאורמת הגבול המרכזי

אחת הסיבות לכך שהתפלגות נורמלית כה חשובה היא **תיאורמת הגבול המרכזי**. נניח שיש לנו מדגם גדול של N ערכים בלתי תלויים X<sub>1</sub>, ..., X<sub>N</sub>, שנדגמו מכל התפלגות עם ממוצע μ ושונות σ<sup>2</sup>. אז, עבור N גדול מספיק (במילים אחרות, כאשר N→∞), הממוצע Σ<sub>i</sub>X<sub>i</sub> יתפלג נורמלית, עם ממוצע μ ושונות σ<sup>2</sup>/N.

> דרך נוספת לפרש את תיאורמת הגבול המרכזי היא לומר שלא משנה מהי ההתפלגות, כאשר מחשבים את הממוצע של סכום ערכים אקראיים כלשהם, מגיעים להתפלגות נורמלית.

מתיאורמת הגבול המרכזי נובע גם שכאשר N→∞, ההסתברות שממוצע המדגם יהיה שווה ל-μ מתקרבת ל-1. זה ידוע כ-**חוק המספרים הגדולים**.

## שונות וקורלציה

אחד הדברים שמדעי הנתונים עושים הוא למצוא קשרים בין נתונים. אנו אומרים ששתי סדרות **מתואמות** כאשר הן מציגות התנהגות דומה באותו זמן, כלומר הן עולות/יורדות יחד, או שאחת עולה כאשר השנייה יורדת ולהפך. במילים אחרות, נראה שיש קשר כלשהו בין שתי הסדרות.

> קורלציה לא בהכרח מצביעה על קשר סיבתי בין שתי סדרות; לפעמים שני המשתנים תלויים בגורם חיצוני כלשהו, או שזה יכול להיות צירוף מקרים בלבד ששתי הסדרות מתואמות. עם זאת, קורלציה מתמטית חזקה היא אינדיקציה טובה לכך ששני המשתנים קשורים איכשהו.

מבחינה מתמטית, המושג המרכזי שמראה את הקשר בין שני משתנים מקריים הוא **שונות משותפת** (Covariance), שמחושבת כך: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. אנו מחשבים את הסטייה של שני המשתנים מערכי הממוצע שלהם, ואז מכפילים את הסטיות הללו. אם שני המשתנים סוטים יחד, המכפלה תמיד תהיה חיובית, מה שיוביל לשונות משותפת חיובית. אם שני המשתנים סוטים באופן לא מסונכרן (כלומר, אחד יורד מתחת לממוצע כאשר השני עולה מעל הממוצע), נקבל תמיד ערכים שליליים, שיובילו לשונות משותפת שלילית. אם הסטיות אינן תלויות, הן יתאזנו לכדי אפס.

הערך המוחלט של השונות המשותפת לא אומר לנו הרבה על עוצמת הקורלציה, מכיוון שהוא תלוי בגודל הערכים בפועל. כדי לנרמל אותו, ניתן לחלק את השונות המשותפת בסטיית התקן של שני המשתנים, כדי לקבל **קורלציה**. היתרון הוא שהקורלציה תמיד בטווח [-1,1], כאשר 1 מציין קורלציה חיובית חזקה בין הערכים, -1 - קורלציה שלילית חזקה, ו-0 - אין קורלציה כלל (המשתנים בלתי תלויים).

**דוגמה**: נוכל לחשב את הקורלציה בין משקלים וגבהים של שחקני בייסבול מהמאגר שהוזכר לעיל:
```python
print(np.corrcoef(weights,heights))
```
כתוצאה מכך, נקבל **מטריצת קורלציה** כמו זו:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> מטריצת קורלציה C יכולה להיות מחושבת עבור כל מספר של סדרות קלט S<sub>1</sub>, ..., S<sub>n</sub>. הערך של C<sub>ij</sub> הוא הקורלציה בין S<sub>i</sub> ו-S<sub>j</sub>, והאלמנטים האלכסוניים תמיד שווים ל-1 (שזו גם הקורלציה העצמית של S<sub>i</sub>).

במקרה שלנו, הערך 0.53 מצביע על כך שיש קורלציה מסוימת בין משקל לגובה של אדם. נוכל גם ליצור תרשים פיזור של ערך אחד מול השני כדי לראות את הקשר באופן חזותי:

![קשר בין משקל לגובה](../../../../translated_images/weight-height-relationship.3f06bde4ca2aba9974182c4ef037ed602acd0fbbbbe2ca91cefd838a9e66bcf9.he.png)

> דוגמאות נוספות לקורלציה ושונות משותפת ניתן למצוא ב-[מחברת המצורפת](notebook.ipynb).

## סיכום

בפרק זה למדנו:

* תכונות סטטיסטיות בסיסיות של נתונים, כגון ממוצע, שונות, חציון ורבעונים
* התפלגויות שונות של משתנים מקריים, כולל התפלגות נורמלית
* כיצד למצוא קורלציה בין תכונות שונות
* כיצד להשתמש במתמטיקה וסטטיסטיקה כדי להוכיח השערות
* כיצד לחשב רווחי סמך עבור משתנה מקרי בהתבסס על מדגם נתונים

למרות שזו אינה רשימה ממצה של נושאים בסטטיסטיקה והסתברות, היא אמורה להספיק כדי לתת לכם התחלה טובה בקורס זה.

## 🚀 אתגר

השתמשו בקוד הדוגמה במחברת כדי לבדוק השערות נוספות:
1. שחקני בסיס ראשון מבוגרים יותר משחקני בסיס שני
2. שחקני בסיס ראשון גבוהים יותר משחקני בסיס שלישי
3. שחקני שורטסטופ גבוהים יותר משחקני בסיס שני

## [שאלון לאחר ההרצאה](https://ff-quizzes.netlify.app/en/ds/quiz/7)

## סקירה ולמידה עצמית

הסתברות וסטטיסטיקה הוא נושא רחב שמצדיק קורס משלו. אם אתם מעוניינים להעמיק בתיאוריה, ייתכן שתרצו להמשיך לקרוא את הספרים הבאים:

1. [קרלוס פרננדז-גרנדה](https://cims.nyu.edu/~cfgranda/) מאוניברסיטת ניו יורק כתב סיכומי הרצאות מצוינים [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (זמין אונליין)
1. [פיטר ואנדרו ברוס. סטטיסטיקה מעשית למדעני נתונים.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[קוד לדוגמה ב-R](https://github.com/andrewgbruce/statistics-for-data-scientists)]. 
1. [ג'יימס ד. מילר. סטטיסטיקה למדעי הנתונים](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[קוד לדוגמה ב-R](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## משימה

[מחקר קטן על סוכרת](assignment.md)

## קרדיטים

השיעור נכתב באהבה על ידי [דמיטרי סושניקוב](http://soshnikov.com)

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי-דיוקים. המסמך המקורי בשפתו המקורית נחשב למקור הסמכותי. למידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי בני אדם. איננו נושאים באחריות לכל אי-הבנה או פרשנות שגויה הנובעת משימוש בתרגום זה.  