<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "58860ce9a4b8a564003d2752f7c72851",
  "translation_date": "2025-10-03T16:43:24+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "he"
}
-->
# מבוא לאתיקה של נתונים

|![ סקיצה מאת [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| אתיקה במדעי הנתונים - _סקיצה מאת [@nitya](https://twitter.com/nitya)_ |

---

כולנו אזרחים של נתונים החיים בעולם מבוסס נתונים.

מגמות השוק מראות כי עד שנת 2022, אחת מתוך שלוש ארגונים גדולים תקנה ותמכור את הנתונים שלה דרך [שווקים ומרכזי מסחר](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/) מקוונים. בתור **מפתחי אפליקציות**, יהיה לנו קל וזול יותר לשלב תובנות מבוססות נתונים ואוטומציה מבוססת אלגוריתמים בחוויות היומיות של המשתמשים. אך ככל שהבינה המלאכותית הופכת לנפוצה, נצטרך גם להבין את הנזקים הפוטנציאליים הנגרמים מ[שימוש לרעה](https://www.youtube.com/watch?v=TQHs8SA1qpk) באלגוריתמים בקנה מידה רחב.

המגמות מצביעות על כך שעד שנת 2025, נייצר ונצרוך מעל [180 זטה-בייטים](https://www.statista.com/statistics/871513/worldwide-data-created/) של נתונים. עבור **מדעני נתונים**, התפוצצות המידע הזו מספקת גישה חסרת תקדים לנתונים אישיים והתנהגותיים. עם זאת מגיעה היכולת לבנות פרופילים מפורטים של משתמשים ולהשפיע בעדינות על קבלת ההחלטות שלהם—לעיתים בדרכים שמטפחות [אשליה של בחירה חופשית](https://www.datasciencecentral.com/the-pareto-set-and-the-paradox-of-choice/). בעוד שניתן להשתמש בכך כדי להניע משתמשים לתוצאות מועדפות, הדבר גם מעלה שאלות קריטיות לגבי פרטיות נתונים, אוטונומיה, והגבולות האתיים של השפעה אלגוריתמית.

אתיקה של נתונים היא כיום _מעקה בטיחות הכרחי_ עבור מדעי הנתונים וההנדסה, המסייעת לנו למזער נזקים פוטנציאליים ותוצאות בלתי מכוונות מפעולות מבוססות נתונים. [מעגל ההייפ של גרטנר עבור AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) מזהה מגמות רלוונטיות באתיקה דיגיטלית, AI אחראי, וממשל AI כגורמים מרכזיים למגמות גדולות יותר סביב _דמוקרטיזציה_ ו_תיעוש_ של AI.

![מעגל ההייפ של גרטנר עבור AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

בשיעור זה, נחקור את התחום המרתק של אתיקה של נתונים - החל ממושגים ואתגרים מרכזיים, ועד מחקרי מקרה ומושגים יישומיים כמו ממשל AI - המסייעים לבסס תרבות אתית בצוותים ובארגונים שעובדים עם נתונים ו-AI.




## [שאלון לפני השיעור](https://ff-quizzes.netlify.app/en/ds/quiz/2) 🎯

## הגדרות בסיסיות

נתחיל בהבנת המונחים הבסיסיים.

המילה "אתיקה" מגיעה מהמילה היוונית ["ethikos"](https://en.wikipedia.org/wiki/Ethics) (ושורשה "ethos") שמשמעותה _אופי או טבע מוסרי_. 

**אתיקה** עוסקת בערכים משותפים ועקרונות מוסריים שמנחים את ההתנהגות שלנו בחברה. אתיקה מבוססת לא על חוקים אלא על נורמות מקובלות של מה "נכון מול לא נכון". עם זאת, שיקולים אתיים יכולים להשפיע על יוזמות ממשל תאגידי ורגולציות ממשלתיות שיוצרות יותר תמריצים לציות.

**אתיקה של נתונים** היא [ענף חדש של אתיקה](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) שחוקר ומעריך בעיות מוסריות הקשורות ל_נתונים, אלגוריתמים ופרקטיקות תואמות_. כאן, **"נתונים"** מתמקדים בפעולות הקשורות ליצירה, הקלטה, אצירה, עיבוד, הפצה, שיתוף ושימוש, **"אלגוריתמים"** מתמקדים ב-AI, סוכנים, למידת מכונה ורובוטים, ו**"פרקטיקות"** מתמקדות בנושאים כמו חדשנות אחראית, תכנות, פריצה וקודי אתיקה.

**אתיקה יישומית** היא [יישום מעשי של שיקולים מוסריים](https://en.wikipedia.org/wiki/Applied_ethics). זהו תהליך של חקירה פעילה של סוגיות אתיות בהקשר של _פעולות, מוצרים ותהליכים בעולם האמיתי_, ונקיטת צעדים מתקנים כדי להבטיח שהם נשארים מיושרים עם הערכים האתיים שהוגדרו.

**תרבות אתית** עוסקת ב[_הפעלה_ של אתיקה יישומית](https://hbr.org/2019/05/how-to-design-an-ethical-organization) כדי להבטיח שהעקרונות והפרקטיקות האתיים שלנו יאומצו באופן עקבי וניתן להרחבה בכל רחבי הארגון. תרבויות אתיות מצליחות מגדירות עקרונות אתיים ברמת הארגון, מספקות תמריצים משמעותיים לציות, ומחזקות נורמות אתיות על ידי עידוד והגברת התנהגויות רצויות בכל רמות הארגון.


## מושגי אתיקה

בקטע זה, נדון במושגים כמו **ערכים משותפים** (עקרונות) ו**אתגרים אתיים** (בעיות) באתיקה של נתונים - ונחקור **מחקרי מקרה** שיעזרו לכם להבין את המושגים הללו בהקשרים של העולם האמיתי.

### 1. עקרונות אתיים

כל אסטרטגיה של אתיקה של נתונים מתחילה בהגדרת _עקרונות אתיים_ - "ערכים משותפים" שמתארים התנהגויות מקובלות ומנחים פעולות תואמות בפרויקטים של נתונים ו-AI. ניתן להגדיר אותם ברמה אישית או צוותית. עם זאת, רוב הארגונים הגדולים מגדירים אותם בהצהרת משימה או מסגרת של _AI אתי_ ברמת הארגון, ומיישמים אותם באופן עקבי בכל הצוותים.

**דוגמה:** הצהרת המשימה של [AI אחראי](https://www.microsoft.com/en-us/ai/responsible-ai) של מיקרוסופט אומרת: _"אנחנו מחויבים לקידום AI מונחה עקרונות אתיים שמעמידים את האדם במרכז"_ - ומזהה 6 עקרונות אתיים במסגרת הבאה:

![AI אחראי במיקרוסופט](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

בואו נחקור בקצרה את העקרונות הללו. _שקיפות_ ו_אחריות_ הם ערכים יסודיים שעליהם נבנים עקרונות אחרים - אז נתחיל שם:

* [**אחריות**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) הופכת את העוסקים בתחום ל_אחראים_ על פעולות הנתונים וה-AI שלהם, ועל הציות לעקרונות האתיים הללו.
* [**שקיפות**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) מבטיחה שפעולות נתונים ו-AI יהיו _מובנות_ (ניתנות לפרשנות) למשתמשים, ומסבירה את מה ולמה מאחורי ההחלטות.
* [**הוגנות**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - מתמקדת בהבטחת AI שמתייחס _לכל האנשים_ באופן הוגן, ומתמודדת עם הטיות חברתיות-טכניות מערכתיות או סמיות בנתונים ובמערכות.
* [**אמינות ובטיחות**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - מבטיחה ש-AI מתנהג _בעקביות_ עם ערכים מוגדרים, וממזערת נזקים פוטנציאליים או תוצאות בלתי מכוונות.
* [**פרטיות ואבטחה**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - עוסקת בהבנת שושלת הנתונים, ומתן _הגנות פרטיות נתונים_ למשתמשים.
* [**הכללה**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - עוסקת בעיצוב פתרונות AI בכוונה, והתאמתם כדי לענות על _מגוון רחב של צרכים_ ויכולות אנושיות.

> 🚨 חשבו על מה יכולה להיות הצהרת המשימה של אתיקה של נתונים שלכם. חקרו מסגרות AI אתיות מארגונים אחרים - הנה דוגמאות מ-[IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles), ו-[Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). אילו ערכים משותפים יש להם במשותף? כיצד עקרונות אלו קשורים למוצרי AI או לתעשייה שבה הם פועלים?

### 2. אתגרים אתיים

לאחר שהגדרנו עקרונות אתיים, השלב הבא הוא להעריך את פעולות הנתונים וה-AI שלנו כדי לראות אם הן מתיישרות עם הערכים המשותפים הללו. חשבו על הפעולות שלכם בשתי קטגוריות: _איסוף נתונים_ ו_עיצוב אלגוריתמים_. 

באיסוף נתונים, הפעולות יכללו ככל הנראה **נתונים אישיים** או מידע אישי מזהה (PII) עבור אנשים מזוהים. זה כולל [פריטים מגוונים של נתונים לא אישיים](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) שמזהים _ביחד_ אדם. אתגרים אתיים יכולים להיות קשורים ל_פרטיות נתונים_, _בעלות על נתונים_, ונושאים קשורים כמו _הסכמה מדעת_ ו_זכויות קניין רוחני_ עבור משתמשים.

בעיצוב אלגוריתמים, הפעולות יכללו איסוף ואצירה של **מאגרי נתונים**, ואז שימוש בהם כדי לאמן ולפרוס **מודלים נתונים** שמנבאים תוצאות או מבצעים אוטומציה של החלטות בהקשרים של העולם האמיתי. אתגרים אתיים יכולים לנבוע מ_הטיות במאגרי נתונים_, בעיות _איכות נתונים_, _חוסר הוגנות_, ו_ייצוג שגוי_ באלגוריתמים - כולל כמה בעיות שהן מערכתיות בטבען.

בשני המקרים, אתגרים אתיים מדגישים תחומים שבהם הפעולות שלנו עשויות להיתקל בקונפליקט עם הערכים המשותפים שלנו. כדי לזהות, למזער, למנוע או להסיר את החששות הללו - עלינו לשאול שאלות מוסריות "כן/לא" הקשורות לפעולות שלנו, ואז לנקוט צעדים מתקנים לפי הצורך. בואו נבחן כמה אתגרים אתיים והשאלות המוסריות שהם מעלים:


#### 2.1 בעלות על נתונים

איסוף נתונים כולל לעיתים קרובות נתונים אישיים שיכולים לזהות את נושאי הנתונים. [בעלות על נתונים](https://permission.io/blog/data-ownership) עוסקת ב_שליטה_ ו[זכויות משתמש](https://permission.io/blog/data-ownership) הקשורות ליצירה, עיבוד והפצה של נתונים. 

השאלות המוסריות שעלינו לשאול הן: 
 * מי הבעלים של הנתונים? (משתמש או ארגון)
 * אילו זכויות יש לנושאי הנתונים? (לדוגמה: גישה, מחיקה, ניידות)
 * אילו זכויות יש לארגונים? (לדוגמה: תיקון ביקורות משתמשים זדוניות)

#### 2.2 הסכמה מדעת

[הסכמה מדעת](https://legaldictionary.net/informed-consent/) מגדירה את פעולת המשתמשים בהסכמה לפעולה (כמו איסוף נתונים) עם _הבנה מלאה_ של עובדות רלוונטיות כולל המטרה, הסיכונים הפוטנציאליים, והחלופות. 

שאלות לחקור כאן הן:
 * האם המשתמש (נושא הנתונים) נתן רשות ללכידת נתונים ושימוש בהם?
 * האם המשתמש הבין את המטרה שלשמה הנתונים נלכדו?
 * האם המשתמש הבין את הסיכונים הפוטנציאליים מהשתתפותו?

#### 2.3 קניין רוחני

[קניין רוחני](https://en.wikipedia.org/wiki/Intellectual_property) מתייחס ליצירות בלתי מוחשיות הנובעות מיוזמה אנושית, שעשויות _להיות בעלות ערך כלכלי_ לאנשים או עסקים. 

שאלות לחקור כאן הן:
 * האם הנתונים שנאספו היו בעלי ערך כלכלי למשתמש או לעסק?
 * האם ל**משתמש** יש קניין רוחני כאן?
 * האם ל**ארגון** יש קניין רוחני כאן?
 * אם זכויות אלו קיימות, כיצד אנו מגנים עליהן?

#### 2.4 פרטיות נתונים

[פרטיות נתונים](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) או פרטיות מידע מתייחסת לשמירה על פרטיות המשתמש והגנה על זהותו ביחס למידע אישי מזהה. 

שאלות לחקור כאן הן:
 * האם הנתונים האישיים של המשתמשים מאובטחים מפני פריצות ודליפות?
 * האם הנתונים של המשתמשים נגישים רק למשתמשים והקשרים מורשים?
 * האם האנונימיות של המשתמשים נשמרת כאשר הנתונים משותפים או מופצים?
 * האם ניתן להסיר את זיהוי המשתמש ממאגרי נתונים אנונימיים?


#### 2.5 הזכות להישכח

[הזכות להישכח](https://en.wikipedia.org/wiki/Right_to_be_forgotten) או [הזכות למחיקה](https://www.gdpreu.org/right-to-be-forgotten/) מספקת הגנה נוספת על נתונים אישיים למשתמשים. באופן ספציפי, היא מעניקה למשתמשים את הזכות לבקש מחיקה או הסרה של נתונים אישיים מחיפושים באינטרנט וממקומות אחרים, _בנסיבות מסוימות_ - ומאפשרת להם התחלה חדשה ברשת מבלי שפעולות עבר יעמדו נגדם.

שאלות לחקור כאן הן:
 * האם המערכת מאפשרת לנושאי נתונים לבקש מחיקה?
 * האם ביטול הסכמת המשתמש צריך להפעיל מחיקה אוטומטית?
 * האם נתונים נאספו ללא הסכמה או באמצעים בלתי חוקיים?
 * האם אנו עומדים בתקנות ממשלתיות לפרטיות נתונים?


#### 2.6 הטיות במאגרי נתונים

הטיות במאגרי נתונים או [הטיות באיסוף](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) עוסקות בבחירת תת-קבוצה _לא מייצגת_ של נתונים לפיתוח אלגוריתמים, ויוצרת פוטנציאל לחוסר הוגנות בתוצאות עבור קבוצות מגוונות. סוגי הטיות כוללים הטיות בבחירה או דגימה, הטיות מתנדבים, והטיות מכשירים. 

שאלות לחקור כאן הן:
 * האם גייסנו קבוצה מייצגת של נושאי נתונים?
 * האם בדקנו את מאגר הנתונים שנאסף או נאצר עבור הטיות שונות?
 * האם אנו יכולים למזער או להסיר הטיות שהתגלו?

#### 2.7 איכות נתונים

[איכות נתונים](https://lakefs.io/data-quality-testing/) בוחנת את תקפות מאגר הנתונים שנאצר לשם פיתוח האלגוריתמים שלנו, ובודקת אם התכונות והרשומות עומדות בדרישות לרמת דיוק ועקביות הנדרשת למטרת ה-AI שלנו.

שאלות לחקור כאן הן:
 * האם לכדנו תכונות _תקפות_ למקרה השימוש שלנו?
 * האם הנתונים נלכדו _בעקביות_ ממקורות נתונים מגוונים?
 * האם מאגר הנתונים _שלם_ עבור תנאים או תרחישים מגוונים?
* האם המידע שנאסף משקף _בדיוק_ את המציאות?

#### 2.8 הוגנות אלגוריתמית

[הוגנות אלגוריתמית](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) בודקת האם עיצוב האלגוריתם מפלה באופן שיטתי קבוצות מסוימות של נבדקים, מה שעלול להוביל ל[נזקים פוטנציאליים](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) ב-_הקצאה_ (כאשר משאבים נשללים או נמנעים מקבוצה זו) וב-_איכות השירות_ (כאשר הבינה המלאכותית אינה מדויקת עבור קבוצות מסוימות כמו שהיא עבור אחרות).

שאלות שכדאי לבחון כאן:
* האם הערכנו את דיוק המודל עבור קבוצות מגוונות ותנאים שונים?
* האם בדקנו את המערכת לנזקים פוטנציאליים (לדוגמה, סטריאוטיפים)?
* האם ניתן לשנות נתונים או לאמן מחדש מודלים כדי לצמצם נזקים שזוהו?

חקרו משאבים כמו [רשימות בדיקה להוגנות בבינה מלאכותית](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) כדי ללמוד עוד.

#### 2.9 הצגת נתונים באופן מטעה

[הצגת נתונים באופן מטעה](https://www.sciencedirect.com/topics/computer-science/misrepresentation) עוסקת בשאלה האם אנו מתקשרים תובנות מתוך נתונים מדווחים בצורה כנה באופן שמטעה כדי לתמוך בנרטיב רצוי.

שאלות שכדאי לבחון כאן:
* האם אנו מדווחים נתונים לא שלמים או לא מדויקים?
* האם אנו מציגים נתונים באופן שמוביל למסקנות מטעות?
* האם אנו משתמשים בטכניקות סטטיסטיות סלקטיביות כדי לשנות תוצאות?
* האם קיימות הסברים חלופיים שיכולים להציע מסקנה שונה?

#### 2.10 בחירה חופשית

[אשליית הבחירה החופשית](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) מתרחשת כאשר "ארכיטקטורות בחירה" של מערכות משתמשות באלגוריתמים לקבלת החלטות כדי להניע אנשים לבחור בתוצאה מועדפת תוך יצירת רושם שיש להם אפשרויות ושליטה. [דפוסים אפלים](https://www.darkpatterns.org/) אלו יכולים לגרום לנזקים חברתיים וכלכליים למשתמשים. מכיוון שהחלטות משתמש משפיעות על פרופילי התנהגות, פעולות אלו עשויות להניע בחירות עתידיות שיכולות להעצים או להרחיב את השפעת הנזקים הללו.

שאלות שכדאי לבחון כאן:
* האם המשתמש הבין את ההשלכות של קבלת הבחירה הזו?
* האם המשתמש היה מודע לאפשרויות (חלופיות) וליתרונות וחסרונות של כל אחת?
* האם המשתמש יכול להפוך בחירה אוטומטית או מושפעת מאוחר יותר?

### 3. מקרי בוחן

כדי לשים את האתגרים האתיים בהקשרים של העולם האמיתי, כדאי לבחון מקרי בוחן שמדגישים את הנזקים וההשלכות הפוטנציאליים על יחידים וחברה, כאשר הפרות אתיות כאלו נעלמות מעינינו.

הנה כמה דוגמאות:

| אתגר אתי | מקרה בוחן | 
|--- |--- |
| **הסכמה מדעת** | 1972 - [מחקר העגבת בטסקיגי](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - גברים אפרו-אמריקאים שהשתתפו במחקר הובטחה להם טיפול רפואי חינם _אך הוטעו_ על ידי חוקרים שלא הודיעו להם על האבחנה או על זמינות הטיפול. רבים מהנבדקים מתו, ושותפים או ילדים נפגעו; המחקר נמשך 40 שנה. | 
| **פרטיות נתונים** | 2007 - [פרס נתוני נטפליקס](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) סיפק לחוקרים _10 מיליון דירוגי סרטים אנונימיים מ-50 אלף לקוחות_ כדי לשפר אלגוריתמי המלצות. עם זאת, חוקרים הצליחו לקשר נתונים אנונימיים לנתונים מזהים אישית ב-_מאגרי נתונים חיצוניים_ (לדוגמה, תגובות IMDb) - למעשה "דה-אנונימיזציה" של חלק ממנויי נטפליקס.|
| **הטיה באיסוף נתונים** | 2013 - עיריית בוסטון [פיתחה את Street Bump](https://www.boston.gov/transportation/street-bump), אפליקציה שאפשרה לתושבים לדווח על בורות בכביש, מה שנתן לעיר נתוני כבישים טובים יותר למציאת ותיקון בעיות. עם זאת, [אנשים בקבוצות הכנסה נמוכה היו בעלי פחות גישה למכוניות וטלפונים](https://hbr.org/2013/04/the-hidden-biases-in-big-data), מה שהפך את בעיות הכבישים שלהם לבלתי נראות באפליקציה זו. המפתחים עבדו עם אקדמאים כדי לטפל ב-_נגישות שוויונית ופערים דיגיטליים_ למען הוגנות. |
| **הוגנות אלגוריתמית** | 2018 - מחקר [Gender Shades של MIT](http://gendershades.org/overview.html) העריך את דיוק מוצרי AI לסיווג מגדר, וחשף פערים בדיוק עבור נשים ואנשים בעלי צבע עור כהה. [כרטיס Apple משנת 2019](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) נראה שהציע פחות אשראי לנשים מאשר לגברים. שניהם הדגימו בעיות בהטיה אלגוריתמית שהובילה לנזקים חברתיים-כלכליים.|
| **הצגת נתונים באופן מטעה** | 2020 - [משרד הבריאות של ג'ורג'יה פרסם גרפים של מקרי COVID-19](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) שנראה כי הטעו את האזרחים לגבי מגמות במקרים מאושרים עם סדר לא כרונולוגי על ציר ה-x. זה מדגים הצגה מטעה באמצעות טריקים ויזואליים. |
| **אשליית הבחירה החופשית** | 2020 - אפליקציית לימוד [ABCmouse שילמה 10 מיליון דולר כדי ליישב תלונה של ה-FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) שבה הורים נלכדו בתשלום עבור מנויים שלא יכלו לבטל. זה מדגים דפוסים אפלים בארכיטקטורות בחירה, שבהן משתמשים הונעו לעבר בחירות שעלולות להזיק. |
| **פרטיות נתונים וזכויות משתמש** | 2021 - [פרצת נתונים בפייסבוק](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) חשפה נתונים מ-530 מיליון משתמשים, מה שהוביל להסדר של 5 מיליארד דולר עם ה-FTC. עם זאת, החברה סירבה להודיע למשתמשים על הפרצה, מה שהפר את זכויות המשתמשים בנוגע לשקיפות נתונים וגישה. |

רוצים לחקור עוד מקרי בוחן? בדקו את המשאבים הבאים:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - דילמות אתיות בתעשיות מגוונות. 
* [קורס אתיקה במדעי הנתונים](https://www.coursera.org/learn/data-science-ethics#syllabus) - מקרי בוחן מרכזיים נבחנים.
* [מקרים שבהם דברים השתבשו](https://deon.drivendata.org/examples/) - רשימת Deon עם דוגמאות.

> 🚨 חשבו על מקרי הבוחן שראיתם - האם חוויתם או הושפעתם מאתגר אתי דומה בחייכם? האם תוכלו לחשוב על לפחות מקרה בוחן אחד נוסף שממחיש אחד מהאתגרים האתיים שדנו בהם בסעיף זה?

## אתיקה יישומית

דיברנו על מושגי אתיקה, אתגרים ומקרי בוחן בהקשרים של העולם האמיתי. אבל איך מתחילים _ליישם_ עקרונות ופרקטיקות אתיות בפרויקטים שלנו? ואיך _מפעילים_ את הפרקטיקות הללו למען ממשל טוב יותר? בואו נחקור כמה פתרונות בעולם האמיתי:

### 1. קודים מקצועיים

קודים מקצועיים מציעים אפשרות אחת לארגונים "לתמרץ" חברים לתמוך בעקרונות האתיים שלהם ובהצהרת המשימה. קודים הם _הנחיות מוסריות_ להתנהגות מקצועית, המסייעות לעובדים או חברים לקבל החלטות שמתיישרות עם עקרונות הארגון שלהם. הם טובים רק כמו הציות מרצון מצד החברים; עם זאת, ארגונים רבים מציעים תגמולים ועונשים נוספים כדי להניע ציות מצד החברים.

דוגמאות כוללות:

* [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) קוד אתיקה
* [Data Science Association](http://datascienceassn.org/code-of-conduct.html) קוד התנהגות (נוצר ב-2013)
* [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (מאז 1993)

> 🚨 האם אתם חברים בארגון מקצועי להנדסה או מדעי הנתונים? חקרו את האתר שלהם כדי לראות אם הם מגדירים קוד אתיקה מקצועי. מה זה אומר על העקרונות האתיים שלהם? איך הם "מתמרצים" חברים לעקוב אחרי הקוד?

### 2. רשימות בדיקה אתיות

בעוד שקודים מקצועיים מגדירים _התנהגות אתית_ נדרשת מצד העוסקים בתחום, יש להם [מגבלות ידועות](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) באכיפה, במיוחד בפרויקטים רחבי היקף. במקום זאת, מומחי מדעי הנתונים רבים [ממליצים על רשימות בדיקה](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), שיכולות **לחבר עקרונות לפרקטיקות** בדרכים יותר דטרמיניסטיות וניתנות לפעולה.

רשימות בדיקה ממירות שאלות ל"משימות כן/לא" שניתן להפעיל, ומאפשרות לעקוב אחריהן כחלק מזרימות עבודה סטנדרטיות לשחרור מוצרים.

דוגמאות כוללות:
* [Deon](https://deon.drivendata.org/) - רשימת בדיקה כללית לאתיקה במדעי הנתונים שנוצרה מתוך [המלצות תעשייה](https://deon.drivendata.org/#checklist-citations) עם כלי שורת פקודה לשילוב קל.
* [רשימת בדיקה לביקורת פרטיות](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - מספקת הנחיות כלליות לפרקטיקות טיפול במידע מנקודות מבט משפטיות וחברתיות.
* [רשימת בדיקה להוגנות בבינה מלאכותית](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - נוצרה על ידי מומחי AI לתמוך באימוץ ושילוב בדיקות הוגנות במחזורי פיתוח AI.
* [22 שאלות לאתיקה במדעי הנתונים ובינה מלאכותית](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - מסגרת פתוחה יותר, מובנית לחקירה ראשונית של סוגיות אתיות בעיצוב, יישום והקשרים ארגוניים.

### 3. רגולציות אתיות

אתיקה עוסקת בהגדרת ערכים משותפים ועשיית הדבר הנכון _מרצון_. **ציות** עוסק ב-_עמידה בחוק_ אם וכאשר מוגדר. **ממשל** מכסה באופן רחב את כל הדרכים שבהן ארגונים פועלים כדי לאכוף עקרונות אתיים ולעמוד בחוקים שנקבעו.

כיום, ממשל לובש שתי צורות בתוך ארגונים. ראשית, מדובר בהגדרת עקרונות **AI אתיים** והקמת פרקטיקות להפעלת אימוץ בכל הפרויקטים הקשורים ל-AI בארגון. שנית, מדובר בעמידה בכל רגולציות **הגנת נתונים** שהממשלה מחייבת עבור האזורים שבהם היא פועלת.

דוגמאות לרגולציות הגנת נתונים ופרטיות:

* `1974`, [חוק הפרטיות בארה"ב](https://www.just
* [למידת מכונה למתחילים](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - שיעור על הוגנות, מבית מיקרוסופט.  
* [עקרונות הבינה המלאכותית האחראית](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - מסלול לימוד חינמי מבית Microsoft Learn.  
* [אתיקה ומדעי הנתונים](https://resources.oreilly.com/examples/0636920203964) - ספר אלקטרוני של O'Reilly (מ. לוקיידס, ה. מייסון ואחרים).  
* [אתיקה במדעי הנתונים](https://www.coursera.org/learn/data-science-ethics#syllabus) - קורס מקוון מאוניברסיטת מישיגן.  
* [אתיקה ללא מסכות](https://ethicsunwrapped.utexas.edu/case-studies) - מחקרי מקרה מאוניברסיטת טקסס.  

# משימה  

[כתיבת מחקר מקרה על אתיקה בנתונים](assignment.md)  

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי אדם. איננו נושאים באחריות לאי הבנות או לפרשנויות שגויות הנובעות משימוש בתרגום זה.