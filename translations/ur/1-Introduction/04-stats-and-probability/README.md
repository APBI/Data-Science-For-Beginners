<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8bbb3fa0d4ad61384a3b4b5f7560226f",
  "translation_date": "2025-09-04T16:05:54+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "ur"
}
-->
# شماریات اور احتمال کا مختصر تعارف

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| شماریات اور احتمال - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

شماریات اور احتمال کا نظریہ ریاضی کے دو ایسے شعبے ہیں جو ڈیٹا سائنس کے لیے انتہائی اہم ہیں۔ اگرچہ گہرے ریاضیاتی علم کے بغیر بھی ڈیٹا کے ساتھ کام کرنا ممکن ہے، لیکن کچھ بنیادی تصورات کا جاننا بہتر ہے۔ یہاں ہم ایک مختصر تعارف پیش کریں گے جو آپ کو آغاز کرنے میں مدد دے گا۔

[![تعارفی ویڈیو](../../../../translated_images/video-prob-and-stats.e4282e5efa2f2543400843ed98b1057065c9600cebfc8a728e8931b5702b2ae4.ur.png)](https://youtu.be/Z5Zy85g4Yjw)

## [لیکچر سے پہلے کا کوئز](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/6)

## احتمال اور بے ترتیب متغیرات

**احتمال** ایک ایسا عدد ہے جو 0 اور 1 کے درمیان ہوتا ہے اور کسی **واقعے** کے ہونے کے امکان کو ظاہر کرتا ہے۔ یہ مثبت نتائج (جو واقعے کی طرف لے جاتے ہیں) کی تعداد کو کل نتائج کی تعداد سے تقسیم کر کے حاصل کیا جاتا ہے، بشرطیکہ تمام نتائج کے امکانات برابر ہوں۔ مثال کے طور پر، جب ہم ایک ڈائس پھینکتے ہیں، تو جفت عدد حاصل کرنے کا احتمال 3/6 = 0.5 ہے۔

جب ہم واقعات کی بات کرتے ہیں تو ہم **بے ترتیب متغیرات** استعمال کرتے ہیں۔ مثال کے طور پر، وہ بے ترتیب متغیر جو ڈائس پھینکنے پر حاصل ہونے والے عدد کو ظاہر کرتا ہے، وہ 1 سے 6 تک کے اعداد لے سکتا ہے۔ 1 سے 6 تک کے اعداد کے مجموعے کو **نمونہ جگہ** کہا جاتا ہے۔ ہم بے ترتیب متغیر کے کسی خاص قدر کو لینے کے احتمال کے بارے میں بات کر سکتے ہیں، مثلاً P(X=3)=1/6۔

پچھلی مثال میں بے ترتیب متغیر کو **منقطع** کہا جاتا ہے، کیونکہ اس کی نمونہ جگہ گنی جا سکتی ہے، یعنی الگ الگ قدریں ہیں جنہیں شمار کیا جا سکتا ہے۔ کچھ صورتوں میں نمونہ جگہ حقیقی اعداد کے کسی وقفے یا پورے مجموعے پر مشتمل ہوتی ہے۔ ایسے متغیرات کو **مسلسل** کہا جاتا ہے۔ ایک اچھی مثال بس کے آنے کا وقت ہے۔

## احتمال کی تقسیم

منقطع بے ترتیب متغیرات کے معاملے میں، ہر واقعے کے احتمال کو ایک فنکشن P(X) کے ذریعے بیان کرنا آسان ہے۔ نمونہ جگہ *S* سے ہر قدر *s* کے لیے یہ 0 سے 1 کے درمیان ایک عدد دے گا، اس طرح کہ تمام واقعات کے لیے P(X=s) کی تمام قدروں کا مجموعہ 1 ہوگا۔

سب سے مشہور منقطع تقسیم **یکساں تقسیم** ہے، جس میں N عناصر کی نمونہ جگہ ہوتی ہے، اور ہر ایک کے لیے احتمال 1/N ہوتا ہے۔

مسلسل متغیر کی احتمال تقسیم کو بیان کرنا زیادہ مشکل ہے، جس کی قدریں کسی وقفے [a,b] یا حقیقی اعداد کے پورے مجموعے ℝ سے لی جاتی ہیں۔ بس کے آنے کے وقت کے معاملے پر غور کریں۔ حقیقت میں، کسی خاص وقت *t* پر بس کے بالکل اسی وقت آنے کا احتمال 0 ہے!

> اب آپ جانتے ہیں کہ 0 احتمال والے واقعات ہوتے ہیں، اور اکثر ہوتے ہیں! کم از کم ہر بار جب بس آتی ہے!

ہم صرف اس بات کے احتمال کے بارے میں بات کر سکتے ہیں کہ متغیر کسی دیے گئے وقفے میں آتا ہے، مثلاً P(t<sub>1</sub>≤X<t<sub>2</sub>)۔ اس صورت میں، احتمال کی تقسیم کو **احتمال کثافت فنکشن** p(x) کے ذریعے بیان کیا جاتا ہے، اس طرح کہ

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../translated_images/probability-density.a8aad29f17a14afb519b407c7b6edeb9f3f9aa5f69c9e6d9445f604e5f8a2bf7.ur.png)

مسلسل یکساں تقسیم کا ایک مسلسل متبادل ہے، جو ایک محدود وقفے پر متعین ہوتا ہے۔ احتمال کہ قدر X کسی وقفے کی لمبائی l میں آتی ہے، l کے متناسب ہے، اور 1 تک بڑھتا ہے۔

ایک اور اہم تقسیم **معمولی تقسیم** ہے، جس کے بارے میں ہم نیچے مزید تفصیل سے بات کریں گے۔

## اوسط، واریانس اور معیاری انحراف

فرض کریں کہ ہم بے ترتیب متغیر X کے n نمونوں کی ایک ترتیب نکالتے ہیں: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>۔ ہم ترتیب کی **اوسط** (یا **حسابی اوسط**) کو روایتی طریقے سے (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n کے طور پر بیان کر سکتے ہیں۔ جیسے جیسے ہم نمونے کے سائز کو بڑھاتے ہیں (یعنی n→∞ کی حد لیتے ہیں)، ہم تقسیم کی اوسط (جسے **توقع** بھی کہا جاتا ہے) حاصل کریں گے۔ ہم توقع کو **E**(x) سے ظاہر کریں گے۔

> یہ دکھایا جا سکتا ہے کہ کسی بھی منقطع تقسیم کے لیے، جس میں قدریں {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} اور متعلقہ احتمالات p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub> ہوں، توقع E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub> کے برابر ہوگی۔

قدروں کے پھیلاؤ کو جانچنے کے لیے، ہم واریانس σ<sup>2</sup> = ∑(x<sub>i</sub> - μ)<sup>2</sup>/n کا حساب لگا سکتے ہیں، جہاں μ ترتیب کی اوسط ہے۔ قدر σ کو **معیاری انحراف** کہا جاتا ہے، اور σ<sup>2</sup> کو **واریانس** کہا جاتا ہے۔

## موڈ، میڈین اور چارٹائلز

کبھی کبھار، اوسط ڈیٹا کی "عام" قدر کو مناسب طریقے سے ظاہر نہیں کرتی۔ مثال کے طور پر، جب کچھ انتہائی قدریں موجود ہوں جو مکمل طور پر حد سے باہر ہوں، تو وہ اوسط کو متاثر کر سکتی ہیں۔ ایک اور اچھا اشارہ **میڈین** ہے، ایک ایسی قدر جس کے نیچے 50% ڈیٹا پوائنٹس آتے ہیں، اور اوپر 50%۔

ڈیٹا کی تقسیم کو سمجھنے میں مدد کے لیے، **چارٹائلز** کے بارے میں بات کرنا مفید ہے:

* پہلا چارٹائل، یا Q1، وہ قدر ہے جس کے نیچے 25% ڈیٹا آتا ہے
* تیسرا چارٹائل، یا Q3، وہ قدر ہے جس کے نیچے 75% ڈیٹا آتا ہے

گرافک طور پر، ہم میڈین اور چارٹائلز کے تعلق کو ایک ڈایاگرام میں ظاہر کر سکتے ہیں جسے **باکس پلاٹ** کہا جاتا ہے:

<img src="images/boxplot_explanation.png" width="50%"/>

یہاں ہم **انٹر-چارٹائل رینج** IQR=Q3-Q1 اور نام نہاد **آؤٹ لائرز** کا بھی حساب لگاتے ہیں - وہ قدریں جو حدود [Q1-1.5*IQR,Q3+1.5*IQR] سے باہر ہوتی ہیں۔

اگر تقسیم محدود ہو اور ممکنہ قدروں کی تعداد کم ہو، تو ایک اچھی "عام" قدر وہ ہوتی ہے جو سب سے زیادہ بار ظاہر ہو، جسے **موڈ** کہا جاتا ہے۔ یہ اکثر زمرہ جاتی ڈیٹا پر لاگو ہوتا ہے، جیسے رنگ۔ فرض کریں کہ ہمارے پاس لوگوں کے دو گروپ ہیں - کچھ جو سرخ رنگ کو ترجیح دیتے ہیں، اور کچھ جو نیلے رنگ کو۔ اگر ہم رنگوں کو نمبروں سے کوڈ کریں، تو پسندیدہ رنگ کے لیے اوسط قدر کہیں نارنجی-سبز کے اسپیکٹرم میں ہوگی، جو کسی بھی گروپ کی اصل ترجیح کو ظاہر نہیں کرتی۔ تاہم، موڈ یا تو ایک رنگ ہوگا، یا دونوں رنگ، اگر ان کے لیے ووٹ دینے والے لوگوں کی تعداد برابر ہو (اس صورت میں ہم نمونے کو **ملٹی موڈل** کہتے ہیں)۔

## حقیقی دنیا کے ڈیٹا

جب ہم حقیقی زندگی کے ڈیٹا کا تجزیہ کرتے ہیں، تو وہ اکثر بے ترتیب متغیرات کی طرح نہیں ہوتے، اس معنی میں کہ ہم نامعلوم نتائج کے ساتھ تجربات نہیں کرتے۔ مثال کے طور پر، بیس بال کھلاڑیوں کی ایک ٹیم پر غور کریں، اور ان کے جسمانی ڈیٹا جیسے قد، وزن اور عمر۔ یہ اعداد و شمار بالکل بے ترتیب نہیں ہیں، لیکن ہم پھر بھی وہی ریاضیاتی تصورات لاگو کر سکتے ہیں۔ مثال کے طور پر، لوگوں کے وزن کی ترتیب کو کسی بے ترتیب متغیر سے نکالی گئی قدروں کی ترتیب سمجھا جا سکتا ہے۔ نیچے بیس بال کے کھلاڑیوں کے وزن کی ترتیب دی گئی ہے، جو [میجر لیگ بیس بال](http://mlb.mlb.com/index.jsp) سے لی گئی ہے، اور [اس ڈیٹاسیٹ](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) سے حاصل کی گئی ہے (آپ کی سہولت کے لیے، صرف پہلے 20 قدریں دکھائی گئی ہیں):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **نوٹ**: اس ڈیٹاسیٹ کے ساتھ کام کرنے کی مثال دیکھنے کے لیے، [ساتھ والے نوٹ بک](notebook.ipynb) پر نظر ڈالیں۔ اس سبق کے دوران کئی چیلنجز بھی ہیں، اور آپ انہیں اس نوٹ بک میں کچھ کوڈ شامل کر کے مکمل کر سکتے ہیں۔ اگر آپ کو ڈیٹا پر کام کرنے کا طریقہ معلوم نہیں ہے، تو فکر نہ کریں - ہم بعد میں Python کا استعمال کرتے ہوئے ڈیٹا پر کام کرنے پر واپس آئیں گے۔ اگر آپ کو Jupyter Notebook میں کوڈ چلانے کا طریقہ معلوم نہیں ہے، تو [اس مضمون](https://soshnikov.com/education/how-to-execute-notebooks-from-github/) کو دیکھیں۔

یہاں ہمارے ڈیٹا کے لیے اوسط، میڈین اور چارٹائلز کو ظاہر کرنے والا باکس پلاٹ ہے:

![وزن کا باکس پلاٹ](../../../../translated_images/weight-boxplot.1dbab1c03af26f8a008fff4e17680082c8ab147d6df646cbac440bbf8f5b9c42.ur.png)

چونکہ ہمارے ڈیٹا میں مختلف کھلاڑیوں کے **کردار** کے بارے میں معلومات شامل ہیں، ہم کردار کے لحاظ سے بھی باکس پلاٹ بنا سکتے ہیں - یہ ہمیں یہ سمجھنے کی اجازت دے گا کہ مختلف کرداروں کے درمیان پیرامیٹرز کی قدریں کیسے مختلف ہوتی ہیں۔ اس بار ہم قد پر غور کریں گے:

![کردار کے لحاظ سے باکس پلاٹ](../../../../translated_images/boxplot_byrole.036b27a1c3f52d42f66fba2324ec5cde0a1bca6a01a619eeb0ce7cd054b2527b.ur.png)

یہ ڈایاگرام تجویز کرتا ہے کہ، اوسطاً، پہلے بیس مین کا قد دوسرے بیس مین کے قد سے زیادہ ہے۔ اس سبق کے بعد کے حصے میں ہم سیکھیں گے کہ ہم اس مفروضے کو مزید رسمی طور پر کیسے جانچ سکتے ہیں، اور یہ ظاہر کرنے کے لیے کہ ہمارا ڈیٹا شماریاتی طور پر اہم ہے۔

> جب ہم حقیقی دنیا کے ڈیٹا کے ساتھ کام کرتے ہیں، تو ہم فرض کرتے ہیں کہ تمام ڈیٹا پوائنٹس کسی احتمال تقسیم سے نکالے گئے نمونے ہیں۔ یہ مفروضہ ہمیں مشین لرننگ تکنیکوں کو لاگو کرنے اور کام کرنے والے پیش گوئی ماڈلز بنانے کی اجازت دیتا ہے۔

یہ دیکھنے کے لیے کہ ہمارے ڈیٹا کی تقسیم کیا ہے، ہم ایک گراف بنا سکتے ہیں جسے **ہسٹوگرام** کہا جاتا ہے۔ X-محور مختلف وزن کے وقفوں (نام نہاد **بِنز**) کی تعداد پر مشتمل ہوگا، اور عمودی محور یہ ظاہر کرے گا کہ ہمارے بے ترتیب متغیر کا نمونہ کسی دیے گئے وقفے میں کتنی بار آیا۔

![حقیقی دنیا کے ڈیٹا کا ہسٹوگرام](../../../../translated_images/weight-histogram.bfd00caf7fc30b145b21e862dba7def41c75635d5280de25d840dd7f0b00545e.ur.png)

اس ہسٹوگرام سے آپ دیکھ سکتے ہیں کہ تمام قدریں ایک خاص اوسط وزن کے گرد مرکوز ہیں، اور جیسے جیسے ہم اس وزن سے دور جاتے ہیں - ان قدروں کے وزن کم ہوتے جاتے ہیں۔ یعنی، یہ بہت غیر ممکن ہے کہ کسی بیس بال کھلاڑی کا وزن اوسط وزن سے بہت مختلف ہو۔ وزن کا واریانس یہ ظاہر کرتا ہے کہ وزن اوسط سے کتنا مختلف ہو سکتا ہے۔

> اگر ہم دوسرے لوگوں کے وزن لیں، جو بیس بال لیگ سے نہیں ہیں، تو تقسیم مختلف ہونے کا امکان ہے۔ تاہم، تقسیم کی شکل وہی ہوگی، لیکن اوسط اور واریانس بدل جائیں گے۔ لہذا، اگر ہم اپنے ماڈل کو بیس بال کھلاڑیوں پر تربیت دیں، تو یہ یونیورسٹی کے طلباء پر لاگو ہونے پر غلط نتائج دے سکتا ہے، کیونکہ بنیادی تقسیم مختلف ہے۔

## معمولی تقسیم

وزن کی وہ تقسیم جو ہم نے اوپر دیکھی، وہ بہت عام ہے، اور حقیقی دنیا سے لی گئی بہت سی پیمائشیں اسی قسم کی تقسیم کی پیروی کرتی ہیں، لیکن مختلف اوسط اور واریانس کے ساتھ۔ اس تقسیم کو **معمولی تقسیم** کہا جاتا ہے، اور یہ شماریات میں بہت اہم کردار ادا کرتی ہے۔

معمولی تقسیم کا استعمال ممکنہ بیس بال کھلاڑیوں کے بے ترتیب وزن پیدا کرنے کا ایک درست طریقہ ہے۔ ایک بار جب ہم اوسط وزن `mean` اور معیاری انحراف `std` جان لیں، تو ہم 1000 وزن کے نمونے درج ذیل طریقے سے پیدا کر سکتے ہیں:
```python
samples = np.random.normal(mean,std,1000)
``` 

اگر ہم پیدا کیے گئے نمونوں کا ہسٹوگرام بنائیں تو ہمیں اوپر دکھائی گئی تصویر سے بہت ملتی جلتی تصویر نظر آئے گی۔ اور اگر ہم نمونوں کی تعداد اور بِنز کی تعداد بڑھائیں، تو ہم معمولی تقسیم کی ایک تصویر بنا سکتے ہیں جو مثالی کے قریب ہو:

![معمولی تقسیم اوسط=0 اور معیاری انحراف=1 کے ساتھ](../../../../translated_images/normal-histogram.dfae0d67c202137d552d0015fb87581eca263925e512404f3c12d8885315432e.ur.png)

*معمولی تقسیم اوسط=0 اور معیاری انحراف=1 کے ساتھ*

## اعتماد کے وقفے

جب ہم بیس بال کھلاڑیوں کے وزن کی بات کرتے ہیں، تو ہم فرض کرتے ہیں کہ ایک خاص **بے ترتیب متغیر W** ہے جو تمام بیس بال کھلاڑیوں کے وزن کی مثالی احتمال تقسیم سے مطابقت رکھتا ہے (جسے **آبادی** کہا جاتا ہے)۔ ہمارے وزن کی ترتیب تمام بیس بال کھلاڑیوں کے ایک ذیلی مجموعے سے مطابقت رکھتی ہے جسے ہم **نمونہ** کہتے ہیں۔ ایک دلچسپ سوال یہ ہے کہ کیا ہم W کی تقسیم کے پیرامیٹرز، یعنی آبادی کی اوسط اور واریانس کو جان سکتے ہیں؟

سب سے آسان جواب یہ ہوگا کہ ہمارے نمونے کی اوسط اور واریانس کا حساب لگایا جائے۔ تاہم، یہ ہو سکتا ہے کہ ہمارا بے ترتیب نمونہ مکمل آبادی کی درست نمائندگی نہ کرے۔ اس لیے **اعتماد کے وقفے** کے بارے میں بات کرنا معنی خیز ہے۔
> **اعتماد کا وقفہ** ہماری نمونہ کے مطابق آبادی کے حقیقی اوسط کا اندازہ ہے، جو ایک خاص احتمال (یا **اعتماد کی سطح**) کے ساتھ درست ہوتا ہے۔
فرض کریں کہ ہمارے پاس X<sub>1</sub>, ..., X<sub>n</sub> کا نمونہ ہے جو ہماری تقسیم سے لیا گیا ہے۔ ہر بار جب ہم اپنی تقسیم سے نمونہ لیتے ہیں، تو ہمیں مختلف اوسط قدر μ حاصل ہوتی ہے۔ اس طرح μ کو ایک بے ترتیب متغیر سمجھا جا سکتا ہے۔ **اعتماد وقفہ** جس کا اعتماد p ہو، دو اقدار (L<sub>p</sub>,R<sub>p</sub>) کا جوڑا ہوتا ہے، اس طرح کہ **P**(L<sub>p</sub>≤μ≤R<sub>p</sub>) = p، یعنی ماپے گئے اوسط قدر کے وقفے میں آنے کا امکان p کے برابر ہوتا ہے۔

یہ مختصر تعارف سے آگے بڑھ کر تفصیل سے بحث کرنا ممکن نہیں کہ یہ اعتماد وقفے کیسے حساب کیے جاتے ہیں۔ مزید تفصیلات [ویکیپیڈیا](https://en.wikipedia.org/wiki/Confidence_interval) پر مل سکتی ہیں۔ مختصراً، ہم نمونے کی اوسط کو آبادی کی حقیقی اوسط کے مقابلے میں تقسیم کرتے ہیں، جسے **طالب علم تقسیم** کہا جاتا ہے۔

> **دلچسپ حقیقت**: طالب علم تقسیم کا نام ریاضی دان ولیم سیلی گوسٹ کے نام پر رکھا گیا ہے، جنہوں نے اپنا مقالہ "طالب علم" کے قلمی نام سے شائع کیا۔ وہ گینیس بریوری میں کام کرتے تھے، اور ایک روایت کے مطابق، ان کے آجر نہیں چاہتے تھے کہ عام عوام کو معلوم ہو کہ وہ خام مال کے معیار کا تعین کرنے کے لیے شماریاتی ٹیسٹ استعمال کر رہے ہیں۔

اگر ہم اپنی آبادی کی اوسط μ کو اعتماد p کے ساتھ اندازہ لگانا چاہتے ہیں، تو ہمیں طالب علم تقسیم A کا *(1-p)/2-واں پرسنٹائل* لینا ہوگا، جو یا تو جدولوں سے لیا جا سکتا ہے، یا شماریاتی سافٹ ویئر (جیسے Python، R، وغیرہ) کے کچھ بلٹ ان فنکشنز کا استعمال کرتے ہوئے حساب کیا جا سکتا ہے۔ پھر μ کے لیے وقفہ X±A*D/√n ہوگا، جہاں X نمونے کی حاصل شدہ اوسط ہے، اور D معیاری انحراف ہے۔

> **نوٹ**: ہم [آزادی کے درجات](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)) کے ایک اہم تصور پر بحث کو بھی چھوڑ دیتے ہیں، جو طالب علم تقسیم کے حوالے سے اہم ہے۔ اس تصور کو گہرائی سے سمجھنے کے لیے آپ شماریات پر مکمل کتابوں کا حوالہ دے سکتے ہیں۔

وزن اور قد کے لیے اعتماد وقفہ کا حساب کرنے کی ایک مثال [ساتھ والے نوٹ بک](notebook.ipynb) میں دی گئی ہے۔

| p | وزن کی اوسط |
|-----|-----------|
| 0.85 | 201.73±0.94 |
| 0.90 | 201.73±1.08 |
| 0.95 | 201.73±1.28 |

نوٹ کریں کہ جتنا زیادہ اعتماد کا امکان ہوگا، اتنا ہی وسیع اعتماد وقفہ ہوگا۔

## مفروضہ ٹیسٹنگ

ہمارے بیس بال کھلاڑیوں کے ڈیٹا سیٹ میں مختلف کھلاڑیوں کے کردار ہیں، جنہیں نیچے خلاصہ کیا جا سکتا ہے (دیکھیں [ساتھ والا نوٹ بک](notebook.ipynb) کہ یہ جدول کیسے حساب کیا جا سکتا ہے):

| کردار | قد | وزن | تعداد |
|------|--------|--------|-------|
| کیچر | 72.723684 | 204.328947 | 76 |
| نامزد ہٹر | 74.222222 | 220.888889 | 18 |
| پہلا بیس مین | 74.000000 | 213.109091 | 55 |
| آؤٹ فیلڈر | 73.010309 | 199.113402 | 194 |
| ریلیف پچر | 74.374603 | 203.517460 | 315 |
| دوسرا بیس مین | 71.362069 | 184.344828 | 58 |
| شارٹ اسٹاپ | 71.903846 | 182.923077 | 52 |
| ابتدائی پچر | 74.719457 | 205.163636 | 221 |
| تیسرا بیس مین | 73.044444 | 200.955556 | 45 |

ہم دیکھ سکتے ہیں کہ پہلے بیس مین کی اوسط قد دوسرے بیس مین سے زیادہ ہے۔ اس طرح، ہم یہ نتیجہ اخذ کرنے کی طرف مائل ہو سکتے ہیں کہ **پہلے بیس مین دوسرے بیس مین سے زیادہ قد والے ہیں**۔

> اس بیان کو **مفروضہ** کہا جاتا ہے، کیونکہ ہمیں معلوم نہیں کہ یہ حقیقت میں درست ہے یا نہیں۔

تاہم، یہ ہمیشہ واضح نہیں ہوتا کہ آیا ہم یہ نتیجہ اخذ کر سکتے ہیں۔ اوپر کی بحث سے ہم جانتے ہیں کہ ہر اوسط کے ساتھ ایک متعلقہ اعتماد وقفہ ہوتا ہے، اور اس فرق کو محض ایک شماریاتی غلطی بھی سمجھا جا سکتا ہے۔ ہمیں اپنے مفروضے کو جانچنے کے لیے کچھ زیادہ رسمی طریقہ کی ضرورت ہے۔

آئیے پہلے اور دوسرے بیس مین کے قد کے لیے اعتماد وقفے الگ الگ حساب کرتے ہیں:

| اعتماد | پہلا بیس مین | دوسرا بیس مین |
|------------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

ہم دیکھ سکتے ہیں کہ کسی بھی اعتماد کے تحت وقفے ایک دوسرے سے اوورلیپ نہیں کرتے۔ یہ ہمارے مفروضے کو ثابت کرتا ہے کہ پہلے بیس مین دوسرے بیس مین سے زیادہ قد والے ہیں۔

زیادہ رسمی طور پر، مسئلہ جو ہم حل کر رہے ہیں وہ یہ دیکھنا ہے کہ **دو احتمال تقسیم ایک جیسی ہیں**، یا کم از کم ان کے پیرامیٹرز ایک جیسے ہیں۔ تقسیم کے لحاظ سے، ہمیں اس کے لیے مختلف ٹیسٹ استعمال کرنے کی ضرورت ہوتی ہے۔ اگر ہمیں معلوم ہو کہ ہماری تقسیم نارمل ہے، تو ہم **[طالب علم ٹی-ٹیسٹ](https://en.wikipedia.org/wiki/Student%27s_t-test)** کا اطلاق کر سکتے ہیں۔

طالب علم ٹی-ٹیسٹ میں، ہم نام نہاد **ٹی-ویلیو** کا حساب کرتے ہیں، جو اوسط کے فرق کو ظاہر کرتا ہے، انحراف کو مدنظر رکھتے ہوئے۔ یہ ظاہر کیا گیا ہے کہ ٹی-ویلیو **طالب علم تقسیم** کی پیروی کرتا ہے، جو ہمیں دیے گئے اعتماد سطح **p** کے لیے حد قدر حاصل کرنے کی اجازت دیتا ہے (یہ حساب کیا جا سکتا ہے، یا عددی جدولوں میں دیکھا جا سکتا ہے)۔ پھر ہم ٹی-ویلیو کو اس حد سے موازنہ کرتے ہیں تاکہ مفروضے کو منظور یا مسترد کریں۔

Python میں، ہم **SciPy** پیکیج استعمال کر سکتے ہیں، جس میں `ttest_ind` فنکشن شامل ہے (بہت سے دیگر مفید شماریاتی فنکشنز کے علاوہ!)۔ یہ ہمارے لیے ٹی-ویلیو کا حساب کرتا ہے، اور اعتماد p-ویلیو کا ریورس لک اپ بھی کرتا ہے، تاکہ ہم صرف اعتماد کو دیکھ کر نتیجہ اخذ کر سکیں۔

مثال کے طور پر، پہلے اور دوسرے بیس مین کے قد کے موازنہ سے ہمیں درج ذیل نتائج ملتے ہیں:
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
ہمارے معاملے میں، p-ویلیو بہت کم ہے، جس کا مطلب ہے کہ پہلے بیس مین کے زیادہ قد ہونے کے حق میں مضبوط ثبوت موجود ہیں۔

مفروضہ ٹیسٹنگ کے دیگر مختلف اقسام بھی ہیں، جیسے:
* یہ ثابت کرنا کہ دیا گیا نمونہ کسی تقسیم کی پیروی کرتا ہے۔ ہمارے معاملے میں ہم نے فرض کیا ہے کہ قد نارمل تقسیم شدہ ہیں، لیکن اس کی رسمی شماریاتی تصدیق کی ضرورت ہے۔
* یہ ثابت کرنا کہ نمونے کی اوسط قدر کسی پہلے سے طے شدہ قدر کے مطابق ہے۔
* کئی نمونوں کی اوسط کا موازنہ کرنا (مثلاً مختلف عمر کے گروپوں میں خوشی کی سطح کا فرق کیا ہے)

## بڑے نمبروں کا قانون اور مرکزی حد نظریہ

نارمل تقسیم اتنی اہم ہونے کی ایک وجہ **مرکزی حد نظریہ** ہے۔ فرض کریں کہ ہمارے پاس آزاد N اقدار X<sub>1</sub>, ..., X<sub>N</sub> کا بڑا نمونہ ہے، جو کسی بھی تقسیم سے لیا گیا ہے جس کی اوسط μ اور انحراف σ<sup>2</sup> ہے۔ پھر، کافی بڑے N کے لیے (دوسرے الفاظ میں، جب N→∞)، اوسط Σ<sub>i</sub>X<sub>i</sub> نارمل تقسیم شدہ ہوگا، جس کی اوسط μ اور انحراف σ<sup>2</sup>/N ہوگا۔

> مرکزی حد نظریہ کی ایک اور تشریح یہ ہے کہ قطع نظر تقسیم کے، جب آپ کسی بے ترتیب متغیر اقدار کے مجموعے کی اوسط کا حساب کرتے ہیں تو آپ نارمل تقسیم پر پہنچتے ہیں۔

مرکزی حد نظریہ سے یہ بھی معلوم ہوتا ہے کہ، جب N→∞، نمونے کی اوسط کے μ کے برابر ہونے کا امکان 1 بن جاتا ہے۔ یہ **بڑے نمبروں کا قانون** کے نام سے جانا جاتا ہے۔

## کوورینس اور تعلق

ڈیٹا سائنس کا ایک کام ڈیٹا کے درمیان تعلقات تلاش کرنا ہے۔ ہم کہتے ہیں کہ دو سلسلے **تعلق رکھتے ہیں** جب وہ ایک ہی وقت میں ایک جیسا رویہ ظاہر کرتے ہیں، یعنی وہ یا تو ایک ساتھ بڑھتے/گرتے ہیں، یا ایک سلسلہ بڑھتا ہے جب دوسرا گرتا ہے اور اس کے برعکس۔ دوسرے الفاظ میں، دو سلسلوں کے درمیان کچھ تعلق معلوم ہوتا ہے۔

> تعلق ضروری نہیں کہ دو سلسلوں کے درمیان سببی تعلق کی نشاندہی کرے؛ کبھی کبھی دونوں متغیرات کسی بیرونی وجہ پر منحصر ہو سکتے ہیں، یا یہ محض اتفاقیہ ہو سکتا ہے کہ دونوں سلسلے تعلق رکھتے ہیں۔ تاہم، مضبوط ریاضیاتی تعلق اس بات کی اچھی نشاندہی ہے کہ دو متغیرات کسی نہ کسی طرح جڑے ہوئے ہیں۔

ریاضیاتی طور پر، دو بے ترتیب متغیرات کے درمیان تعلق ظاہر کرنے والا بنیادی تصور **کوورینس** ہے، جسے اس طرح حساب کیا جاتا ہے: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]۔ ہم دونوں متغیرات کے ان کی اوسط اقدار سے انحراف کا حساب کرتے ہیں، اور پھر ان انحرافات کی پیداوار لیتے ہیں۔ اگر دونوں متغیرات ایک ساتھ انحراف کرتے ہیں، تو پیداوار ہمیشہ مثبت قدر ہوگی، جو مثبت کوورینس میں شامل ہوگی۔ اگر دونوں متغیرات غیر مطابقت سے انحراف کرتے ہیں (یعنی ایک اوسط سے نیچے گرتا ہے جب دوسرا اوسط سے اوپر بڑھتا ہے)، تو ہمیں ہمیشہ منفی نمبر ملیں گے، جو منفی کوورینس میں شامل ہوں گے۔ اگر انحرافات غیر متعلق ہوں، تو وہ تقریباً صفر میں شامل ہوں گے۔

کوورینس کی مطلق قدر ہمیں یہ نہیں بتاتی کہ تعلق کتنا بڑا ہے، کیونکہ یہ اصل اقدار کی شدت پر منحصر ہے۔ اسے معمول پر لانے کے لیے، ہم کوورینس کو دونوں متغیرات کے معیاری انحراف سے تقسیم کر سکتے ہیں، تاکہ **تعلق** حاصل ہو۔ اچھی بات یہ ہے کہ تعلق ہمیشہ [-1,1] کی حد میں ہوتا ہے، جہاں 1 اقدار کے درمیان مضبوط مثبت تعلق کی نشاندہی کرتا ہے، -1 - مضبوط منفی تعلق، اور 0 - کوئی تعلق نہیں (متغیرات آزاد ہیں)۔

**مثال**: ہم بیس بال کھلاڑیوں کے وزن اور قد کے درمیان تعلق کا حساب کر سکتے ہیں:
```python
print(np.corrcoef(weights,heights))
```
نتیجے کے طور پر، ہمیں **تعلق میٹرکس** اس طرح ملتا ہے:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> تعلق میٹرکس C کسی بھی تعداد کے ان پٹ سلسلوں S<sub>1</sub>, ..., S<sub>n</sub> کے لیے حساب کیا جا سکتا ہے۔ C<sub>ij</sub> کی قدر S<sub>i</sub> اور S<sub>j</sub> کے درمیان تعلق ہے، اور قطر عناصر ہمیشہ 1 ہوتے ہیں (جو S<sub>i</sub> کی خود تعلق بھی ہے)۔

ہمارے معاملے میں، قدر 0.53 اس بات کی نشاندہی کرتی ہے کہ کسی شخص کے وزن اور قد کے درمیان کچھ تعلق موجود ہے۔ ہم ایک قدر کے خلاف دوسرے کی اسکیٹر پلاٹ بھی بنا سکتے ہیں تاکہ تعلق کو بصری طور پر دیکھ سکیں:

![وزن اور قد کے درمیان تعلق](../../../../translated_images/weight-height-relationship.3f06bde4ca2aba9974182c4ef037ed602acd0fbbbbe2ca91cefd838a9e66bcf9.ur.png)

> تعلق اور کوورینس کی مزید مثالیں [ساتھ والے نوٹ بک](notebook.ipynb) میں مل سکتی ہیں۔

## نتیجہ

اس سیکشن میں، ہم نے سیکھا:

* ڈیٹا کی بنیادی شماریاتی خصوصیات، جیسے اوسط، انحراف، موڈ اور کوارٹائلز
* بے ترتیب متغیرات کی مختلف تقسیم، بشمول نارمل تقسیم
* مختلف خصوصیات کے درمیان تعلق کیسے تلاش کریں
* کچھ مفروضوں کو ثابت کرنے کے لیے ریاضی اور شماریات کے مضبوط آلات کا استعمال کیسے کریں
* دیے گئے ڈیٹا نمونے کے لیے بے ترتیب متغیر کے اعتماد وقفے کیسے حساب کریں

جبکہ یہ احتمال اور شماریات کے اندر موجود موضوعات کی مکمل فہرست نہیں ہے، یہ اس کورس میں آپ کو اچھی شروعات دینے کے لیے کافی ہونا چاہیے۔

## 🚀 چیلنج

نوٹ بک میں دیے گئے نمونے کے کوڈ کا استعمال کریں تاکہ دیگر مفروضوں کو جانچیں:
1. پہلے بیس مین دوسرے بیس مین سے زیادہ عمر کے ہیں
2. پہلے بیس مین تیسرے بیس مین سے زیادہ قد والے ہیں
3. شارٹ اسٹاپ دوسرے بیس مین سے زیادہ قد والے ہیں

## [لیکچر کے بعد کوئز](https://ff-quizzes.netlify.app/en/ds/)

## جائزہ اور خود مطالعہ

احتمال اور شماریات ایک وسیع موضوع ہے جو اپنے کورس کا مستحق ہے۔ اگر آپ نظریہ میں مزید گہرائی میں جانا چاہتے ہیں، تو آپ درج ذیل کتابوں کو پڑھنا جاری رکھ سکتے ہیں:

1. [کارلوس فرنانڈیز-گرانڈا](https://cims.nyu.edu/~cfgranda/) نیویارک یونیورسٹی سے، کے عظیم لیکچر نوٹس [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (آن لائن دستیاب)
1. [پیٹر اور اینڈریو بروس۔ عملی شماریات برائے ڈیٹا سائنسدان۔](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[R میں نمونے کا کوڈ](https://github.com/andrewgbruce/statistics-for-data-scientists)]۔
1. [جیمز ڈی. ملر۔ ڈیٹا سائنس کے لیے شماریات](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[R میں نمونے کا کوڈ](https://github.com/PacktPublishing/Statistics-for-Data-Science)]۔

## اسائنمنٹ

[چھوٹا ذیابیطس مطالعہ](assignment.md)

## کریڈٹس

یہ سبق [دمیتری سوشنیکوف](http://soshnikov.com) کے ذریعے ♥️ کے ساتھ لکھا گیا ہے۔

---

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا غیر درستیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔