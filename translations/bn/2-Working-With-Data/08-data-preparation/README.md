<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "90a815d332aea41a222f4c6372e7186e",
  "translation_date": "2025-09-04T16:27:55+00:00",
  "source_file": "2-Working-With-Data/08-data-preparation/README.md",
  "language_code": "bn"
}
-->
# ডেটার সাথে কাজ করা: ডেটা প্রস্তুতি

|![ স্কেচনোট [(@sketchthedocs)](https://sketchthedocs.dev) দ্বারা ](../../sketchnotes/08-DataPreparation.png)|
|:---:|
|ডেটা প্রস্তুতি - _[@nitya](https://twitter.com/nitya) দ্বারা স্কেচনোট_ |

## [পূর্ব-লেকচার কুইজ](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/14)

ডেটার উৎসের উপর নির্ভর করে, কাঁচা ডেটাতে এমন কিছু অসঙ্গতি থাকতে পারে যা বিশ্লেষণ এবং মডেলিংয়ে চ্যালেঞ্জ সৃষ্টি করবে। অন্য কথায়, এই ডেটাকে "নোংরা" হিসাবে শ্রেণীবদ্ধ করা যেতে পারে এবং এটি পরিষ্কার করা প্রয়োজন। এই পাঠে ডেটার অনুপস্থিতি, ভুল বা অসম্পূর্ণতার চ্যালেঞ্জ মোকাবিলার জন্য ডেটা পরিষ্কার এবং রূপান্তর করার কৌশলগুলির উপর ফোকাস করা হয়েছে। এই পাঠে আলোচনা করা বিষয়গুলি পাইথন এবং প্যান্ডাস লাইব্রেরি ব্যবহার করবে এবং এই ডিরেক্টরির [নোটবুকে](notebook.ipynb) প্রদর্শিত হবে।

## ডেটা পরিষ্কারের গুরুত্ব

- **ব্যবহার এবং পুনঃব্যবহারের সহজতা**: যখন ডেটা সঠিকভাবে সংগঠিত এবং স্বাভাবিকীকৃত হয়, তখন এটি অনুসন্ধান, ব্যবহার এবং অন্যদের সাথে শেয়ার করা সহজ হয়।

- **সঙ্গতি**: ডেটা সায়েন্স প্রায়শই একাধিক ডেটাসেট নিয়ে কাজ করার প্রয়োজন হয়, যেখানে বিভিন্ন উৎস থেকে আসা ডেটাসেটগুলোকে একত্রিত করতে হয়। নিশ্চিত করা যে প্রতিটি পৃথক ডেটাসেটের সাধারণ মানকরণ রয়েছে, এটি নিশ্চিত করবে যে একত্রিত হওয়ার পরেও ডেটা কার্যকর থাকবে।

- **মডেলের নির্ভুলতা**: পরিষ্কার করা ডেটা সেই মডেলগুলোর নির্ভুলতা উন্নত করে যা এর উপর নির্ভর করে।

## সাধারণ পরিষ্কারের লক্ষ্য এবং কৌশল

- **ডেটাসেট অন্বেষণ**: ডেটা অন্বেষণ, যা [পরবর্তী পাঠে](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/4-Data-Science-Lifecycle/15-analyzing) আলোচনা করা হয়েছে, আপনাকে এমন ডেটা আবিষ্কার করতে সাহায্য করতে পারে যা পরিষ্কার করা প্রয়োজন। ডেটাসেটের মানগুলো ভিজ্যুয়ালি পর্যবেক্ষণ করলে বাকি অংশটি কেমন হবে তার ধারণা পাওয়া যায় বা সমাধানযোগ্য সমস্যাগুলোর একটি ধারণা পাওয়া যায়। অন্বেষণ মৌলিক কোয়েরি, ভিজ্যুয়ালাইজেশন এবং স্যাম্পলিং অন্তর্ভুক্ত করতে পারে।

- **ফরম্যাটিং**: উৎসের উপর নির্ভর করে, ডেটাতে উপস্থাপনার ক্ষেত্রে অসঙ্গতি থাকতে পারে। এটি ডেটাসেটে মানটি দেখা গেলেও ভিজ্যুয়ালাইজেশন বা কোয়েরি ফলাফলে সঠিকভাবে উপস্থাপিত না হওয়ার কারণে সমস্যার সৃষ্টি করতে পারে। সাধারণ ফরম্যাটিং সমস্যাগুলোর মধ্যে রয়েছে হোয়াইটস্পেস, তারিখ এবং ডেটা টাইপ ঠিক করা। ফরম্যাটিং সমস্যাগুলো সমাধান সাধারণত ডেটা ব্যবহারকারীদের উপর নির্ভর করে। উদাহরণস্বরূপ, তারিখ এবং সংখ্যাগুলো কীভাবে উপস্থাপন করা হবে তা দেশের উপর ভিত্তি করে ভিন্ন হতে পারে।

- **ডুপ্লিকেশন**: একাধিকবার উপস্থিত ডেটা ভুল ফলাফল তৈরি করতে পারে এবং সাধারণত এটি সরিয়ে ফেলা উচিত। এটি দুই বা ততোধিক ডেটাসেট একত্রিত করার সময় একটি সাধারণ ঘটনা। তবে, এমন কিছু ক্ষেত্রে ডুপ্লিকেশন থাকা ডেটাসেটে অতিরিক্ত তথ্য প্রদান করতে পারে এবং সংরক্ষণ করা প্রয়োজন হতে পারে।

- **অনুপস্থিত ডেটা**: অনুপস্থিত ডেটা ভুল বা পক্ষপাতদুষ্ট ফলাফল তৈরি করতে পারে। কখনও কখনও এগুলো ডেটা পুনরায় লোড করে, পাইথনের মতো কোড ব্যবহার করে অনুপস্থিত মান পূরণ করে বা কেবল মান এবং সংশ্লিষ্ট ডেটা সরিয়ে ফেলে সমাধান করা যায়। ডেটা কেন অনুপস্থিত এবং কীভাবে এটি সমাধান করা হবে তা নির্ভর করে এটি কীভাবে এবং কেন অনুপস্থিত হয়েছে তার উপর।

## ডেটাফ্রেম তথ্য অন্বেষণ
> **শিক্ষার লক্ষ্য:** এই উপ-অধ্যায়ের শেষে, আপনি প্যান্ডাস ডেটাফ্রেমে সংরক্ষিত ডেটার সাধারণ তথ্য খুঁজে পেতে স্বাচ্ছন্দ্যবোধ করবেন।

আপনার ডেটা প্যান্ডাসে লোড করার পরে, এটি সম্ভবত একটি ডেটাফ্রেমে থাকবে (পূর্ববর্তী [পাঠ](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/2-Working-With-Data/07-python#dataframe) থেকে বিস্তারিত পর্যালোচনা দেখুন)। তবে, যদি আপনার ডেটাফ্রেমে ৬০,০০০ সারি এবং ৪০০ কলাম থাকে, তাহলে আপনি কীভাবে শুরু করবেন? সৌভাগ্যক্রমে, [প্যান্ডাস](https://pandas.pydata.org/) ডেটাফ্রেমের সামগ্রিক তথ্য দ্রুত দেখার জন্য কিছু সুবিধাজনক টুল সরবরাহ করে, পাশাপাশি প্রথম এবং শেষ কয়েকটি সারি দেখার জন্য।

এই কার্যকারিতা অন্বেষণ করতে, আমরা পাইথনের স্কিকিট-লার্ন লাইব্রেরি আমদানি করব এবং একটি আইকনিক ডেটাসেট ব্যবহার করব: **আইরিস ডেটাসেট**।

```python
import pandas as pd
from sklearn.datasets import load_iris

iris = load_iris()
iris_df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])
```
|                                        |sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|
|----------------------------------------|-----------------|----------------|-----------------|----------------|
|0                                       |5.1              |3.5             |1.4              |0.2             |
|1                                       |4.9              |3.0             |1.4              |0.2             |
|2                                       |4.7              |3.2             |1.3              |0.2             |
|3                                       |4.6              |3.1             |1.5              |0.2             |
|4                                       |5.0              |3.6             |1.4              |0.2             |

- **DataFrame.info**: শুরুতে, `info()` পদ্ধতিটি একটি ডেটাফ্রেমে উপস্থিত সামগ্রীর সারাংশ প্রিন্ট করতে ব্যবহৃত হয়। আসুন এই ডেটাসেটটি দেখি:
```python
iris_df.info()
```
```
RangeIndex: 150 entries, 0 to 149
Data columns (total 4 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   sepal length (cm)  150 non-null    float64
 1   sepal width (cm)   150 non-null    float64
 2   petal length (cm)  150 non-null    float64
 3   petal width (cm)   150 non-null    float64
dtypes: float64(4)
memory usage: 4.8 KB
```
এটি থেকে, আমরা জানি যে *আইরিস* ডেটাসেটে চারটি কলামে ১৫০টি এন্ট্রি রয়েছে এবং কোনো নাল এন্ট্রি নেই। সমস্ত ডেটা ৬৪-বিট ফ্লোটিং-পয়েন্ট সংখ্যার হিসাবে সংরক্ষিত।

- **DataFrame.head()**: পরবর্তী, ডেটাফ্রেমের প্রকৃত সামগ্রী পরীক্ষা করতে, আমরা `head()` পদ্ধতিটি ব্যবহার করি। আসুন দেখি আমাদের `iris_df`-এর প্রথম কয়েকটি সারি কেমন দেখাচ্ছে:
```python
iris_df.head()
```
```
   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
0                5.1               3.5                1.4               0.2
1                4.9               3.0                1.4               0.2
2                4.7               3.2                1.3               0.2
3                4.6               3.1                1.5               0.2
4                5.0               3.6                1.4               0.2
```
- **DataFrame.tail()**: বিপরীতে, ডেটাফ্রেমের শেষ কয়েকটি সারি পরীক্ষা করতে, আমরা `tail()` পদ্ধতিটি ব্যবহার করি:
```python
iris_df.tail()
```
```
     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
145                6.7               3.0                5.2               2.3
146                6.3               2.5                5.0               1.9
147                6.5               3.0                5.2               2.0
148                6.2               3.4                5.4               2.3
149                5.9               3.0                5.1               1.8
```
> **মূল কথা:** শুধুমাত্র ডেটাফ্রেমের তথ্য বা প্রথম এবং শেষ কয়েকটি মান দেখেই, আপনি আপনার ডেটার আকার, গঠন এবং বিষয়বস্তু সম্পর্কে একটি তাত্ক্ষণিক ধারণা পেতে পারেন।

## অনুপস্থিত ডেটা মোকাবিলা
> **শিক্ষার লক্ষ্য:** এই উপ-অধ্যায়ের শেষে, আপনি ডেটাফ্রেম থেকে নাল মান প্রতিস্থাপন বা সরানোর পদ্ধতি জানতে পারবেন।

অধিকাংশ সময় আপনি যে ডেটাসেট ব্যবহার করতে চান (বা ব্যবহার করতে বাধ্য হন) তাতে অনুপস্থিত মান থাকে। অনুপস্থিত ডেটা কীভাবে পরিচালনা করা হয়, তা সূক্ষ্ম আপস নিয়ে আসে যা আপনার চূড়ান্ত বিশ্লেষণ এবং বাস্তব-জীবনের ফলাফলে প্রভাব ফেলতে পারে।

প্যান্ডাস দুটি উপায়ে অনুপস্থিত মান পরিচালনা করে। প্রথমটি আপনি পূর্ববর্তী অংশে দেখেছেন: `NaN`, বা Not a Number। এটি আসলে IEEE ফ্লোটিং-পয়েন্ট স্পেসিফিকেশনের একটি বিশেষ মান এবং এটি শুধুমাত্র অনুপস্থিত ফ্লোটিং-পয়েন্ট মান নির্দেশ করতে ব্যবহৃত হয়।

ফ্লোট ছাড়া অন্য অনুপস্থিত মানগুলোর জন্য, প্যান্ডাস পাইথনের `None` অবজেক্ট ব্যবহার করে। যদিও এটি বিভ্রান্তিকর মনে হতে পারে যে আপনি দুটি ভিন্ন ধরনের মানের সম্মুখীন হবেন যা মূলত একই জিনিস বলে, এই নকশা পছন্দের জন্য সাউন্ড প্রোগ্রাম্যাটিক কারণ রয়েছে এবং বাস্তবে, এটি বেশিরভাগ ক্ষেত্রে একটি ভাল আপস প্রদান করে। তবুও, `None` এবং `NaN` উভয়েরই কিছু সীমাবদ্ধতা রয়েছে যা তাদের ব্যবহারের ক্ষেত্রে আপনাকে সচেতন থাকতে হবে।

`NaN` এবং `None` সম্পর্কে আরও জানুন [নোটবুক](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/4-Data-Science-Lifecycle/15-analyzing/notebook.ipynb) থেকে!

- **নাল মান সনাক্ত করা**: প্যান্ডাসে, `isnull()` এবং `notnull()` পদ্ধতিগুলো আপনার নাল ডেটা সনাক্ত করার প্রধান পদ্ধতি। উভয়ই আপনার ডেটার উপর বুলিয়ান মাস্ক প্রদান করে। আমরা `NaN` মানের জন্য `numpy` ব্যবহার করব:
```python
import numpy as np

example1 = pd.Series([0, np.nan, '', None])
example1.isnull()
```
```
0    False
1     True
2    False
3     True
dtype: bool
```
আউটপুটটি ভালো করে দেখুন। এটি কি আপনাকে অবাক করেছে? যদিও `0` একটি গাণিতিক নাল, এটি তবুও একটি বৈধ পূর্ণসংখ্যা এবং প্যান্ডাস এটিকে সেভাবেই বিবেচনা করে। `''` একটু বেশি সূক্ষ্ম। যদিও আমরা এটি সেকশন ১-এ একটি খালি স্ট্রিং মান উপস্থাপন করতে ব্যবহার করেছি, এটি তবুও একটি স্ট্রিং অবজেক্ট এবং প্যান্ডাসের দৃষ্টিতে এটি নাল নয়।

এখন, আসুন এটি উল্টে দিই এবং এই পদ্ধতিগুলোকে এমনভাবে ব্যবহার করি যেভাবে আপনি বাস্তবে ব্যবহার করবেন। আপনি বুলিয়ান মাস্কগুলো সরাসরি একটি ``Series`` বা ``DataFrame`` সূচক হিসাবে ব্যবহার করতে পারেন, যা অনুপস্থিত (বা উপস্থিত) মান নিয়ে কাজ করার সময় কার্যকর হতে পারে।

> **মূল কথা**: `isnull()` এবং `notnull()` পদ্ধতিগুলো `DataFrame`-এ ব্যবহার করলে একই ধরনের ফলাফল দেয়: এগুলো ফলাফল এবং সেই ফলাফলের সূচক দেখায়, যা আপনার ডেটার সাথে কাজ করার সময় আপনাকে অনেক সাহায্য করবে।

- **নাল মান বাদ দেওয়া**: অনুপস্থিত মান সনাক্ত করার বাইরে, প্যান্ডাস `Series` এবং `DataFrame` থেকে নাল মান সরানোর একটি সুবিধাজনক উপায় প্রদান করে। (বিশেষ করে বড় ডেটাসেটে, এটি প্রায়শই বিশ্লেষণ থেকে অনুপস্থিত [NA] মান সরিয়ে ফেলা আরও উপযুক্ত হয়।) এটি দেখতে, আসুন `example1`-এ ফিরে যাই:
```python
example1 = example1.dropna()
example1
```
```
0    0
2     
dtype: object
```
এটি আপনার `example3[example3.notnull()]` আউটপুটের মতো হওয়া উচিত। এখানে পার্থক্য হলো, কেবল মাস্কড মানগুলোর উপর সূচক করার পরিবর্তে, `dropna` সেই অনুপস্থিত মানগুলোকে `Series` `example1` থেকে সরিয়ে দিয়েছে।

`DataFrame`-এর দুটি মাত্রা থাকায়, এগুলো ডেটা বাদ দেওয়ার জন্য আরও বিকল্প সরবরাহ করে।

```python
example2 = pd.DataFrame([[1,      np.nan, 7], 
                         [2,      5,      8], 
                         [np.nan, 6,      9]])
example2
```
|      | 0 | 1 | 2 |
|------|---|---|---|
|0     |1.0|NaN|7  |
|1     |2.0|5.0|8  |
|2     |NaN|6.0|9  |

(আপনি কি লক্ষ্য করেছেন যে প্যান্ডাস দুটি কলামকে ফ্লোটে আপকাস্ট করেছে `NaN`-কে সামঞ্জস্য করার জন্য?)

আপনি একটি `DataFrame` থেকে একটি একক মান বাদ দিতে পারবেন না, তাই আপনাকে সম্পূর্ণ সারি বা কলাম বাদ দিতে হবে। আপনি যা করছেন তার উপর নির্ভর করে, আপনি একটির পরিবর্তে অন্যটি করতে চাইতে পারেন, এবং তাই প্যান্ডাস আপনাকে উভয়ের জন্য বিকল্প দেয়। ডেটা সায়েন্সে, কলামগুলো সাধারণত ভেরিয়েবল এবং সারিগুলো পর্যবেক্ষণ উপস্থাপন করে, তাই আপনি ডেটার সারি বাদ দেওয়ার সম্ভাবনা বেশি; `dropna()`-এর ডিফল্ট সেটিং হলো যেকোনো নাল মান ধারণকারী সমস্ত সারি বাদ দেওয়া:

```python
example2.dropna()
```
```
	0	1	2
1	2.0	5.0	8
```
যদি প্রয়োজন হয়, আপনি কলাম থেকে NA মান বাদ দিতে পারেন। এটি করতে `axis=1` ব্যবহার করুন:
```python
example2.dropna(axis='columns')
```
```
	2
0	7
1	8
2	9
```
লক্ষ্য করুন যে এটি এমন অনেক ডেটা বাদ দিতে পারে যা আপনি রাখতে চাইতে পারেন, বিশেষ করে ছোট ডেটাসেটে। যদি আপনি কেবল এমন সারি বা কলাম বাদ দিতে চান যা কয়েকটি বা এমনকি সমস্ত নাল মান ধারণ করে? আপনি `dropna`-তে `how` এবং `thresh` প্যারামিটার দিয়ে সেই সেটিংগুলো নির্দিষ্ট করতে পারেন।

ডিফল্টভাবে, `how='any'` (আপনি যদি নিজের জন্য পরীক্ষা করতে চান বা পদ্ধতিটির অন্য কোন প্যারামিটার আছে কিনা দেখতে চান, একটি কোড সেলে `example4.dropna?` চালান)। আপনি বিকল্পভাবে `how='all'` নির্দিষ্ট করতে পারেন যাতে শুধুমাত্র এমন সারি বা কলাম বাদ দেওয়া হয় যা সমস্ত নাল মান ধারণ করে। আমাদের উদাহরণ `DataFrame` প্রসারিত করে এটি দেখুন।

```python
example2[3] = np.nan
example2
```
|      |0  |1  |2  |3  |
|------|---|---|---|---|
|0     |1.0|NaN|7  |NaN|
|1     |2.0|5.0|8  |NaN|
|2     |NaN|6.0|9  |NaN|

`thresh` প্যারামিটার আপনাকে আরও সূক্ষ্ম নিয়ন্ত্রণ দেয়: আপনি এমন সংখ্যক *নন-নাল* মান নির্ধারণ করেন যা একটি সারি বা কলামের থাকতে হবে যাতে এটি রাখা হয়:
```python
example2.dropna(axis='rows', thresh=3)
```
```
	0	1	2	3
1	2.0	5.0	8	NaN
```
এখানে, প্রথম এবং শেষ সারি বাদ দেওয়া হয়েছে, কারণ এগুলো কেবল দুটি নন-নাল মান ধারণ করে।

- **নাল মান পূরণ করা**: আপনার ডেটাসেটের উপর নির্ভর করে, কখনও কখনও নাল মানগুলো বৈধ মান দিয়ে পূরণ করা ড্রপ করার চেয়ে বেশি অর্থবহ হতে পারে। আপনি এটি ইন-প্লেসে করতে `isnull` ব্যবহার করতে পারেন, তবে এটি শ্রমসাধ্য হতে পারে, বিশেষ করে যদি আপনার অনেক মান পূরণ করতে হয়। যেহেতু এটি ডেটা সায়েন্সে একটি সাধারণ কাজ, প্যান্ডাস `fillna` প্রদান করে, যা একটি কপি প্রদান করে `Series` বা `DataFrame`-এর যেখানে অনুপস্থিত মানগুলো আপনার পছন্দের একটি মান দিয়ে প্রতিস্থাপিত হয়। এটি বাস্তবে কীভাবে কাজ করে তা দেখতে একটি নতুন উদাহরণ `Series` তৈরি করা যাক।
```python
example3 = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))
example3
```
```
a    1.0
b    NaN
c    2.0
d    NaN
e    3.0
dtype: float64
```
আপনি সমস্ত নাল এন্ট্রিগুলো একটি একক মান, যেমন `0` দিয়ে পূরণ করতে পারেন:
```python
example3.fillna(0)
```
```
a    1.0
b    0.0
c    2.0
d    0.0
e    3.0
dtype: float64
```
আপনি নাল মানগুলো **ফরওয়ার্ড-ফিল** করতে পারেন, অর্থাৎ শেষ বৈধ মানটি ব্যবহার করে একটি নাল পূরণ করতে পারেন:
```python
example3.fillna(method='ffill')
```
```
a    1.0
b    1.0
c    2.0
d    2.0
e    3.0
dtype: float64
```
আপনি **ব্যাক-ফিল** করেও নাল পূরণ করতে পারেন, অর্থাৎ পরবর্তী বৈধ মানটি পেছনে নিয়ে একটি নাল পূরণ করতে পারেন:
```python
example3.fillna(method='bfill')
```
```
a    1.0
b    2.0
c    2.0
d    3.0
e    3.0
dtype: float64
```
আপনি অনুমান করতে পারেন, এটি `DataFrame`-এর ক্ষেত্রেও একইভাবে কাজ করে, তবে আপনি কোন `axis` বরাবর নাল মান পূরণ করবেন তা নির্দিষ্ট করতে পারেন। পূর্বে ব্যবহৃত `example2` আবার নিন:
```python
example2.fillna(method='ffill', axis=1)
```
```
	0	1	2	3
0	1.0	1.0	7.0	7.0
1	2.0	5.0	8.0	8.0
2	NaN	6.0	9.0	9.0
```
লক্ষ্য করুন যে যখন ফরওয়ার্ড-ফিলের জন্য পূর্ববর্তী মান উপলব্ধ নয়, তখন নাল মানটি রয়ে যায়।
> **মূল কথা:** আপনার ডেটাসেটে অনুপস্থিত মানগুলোর সাথে মোকাবিলা করার একাধিক উপায় রয়েছে। আপনি যে নির্দিষ্ট কৌশলটি ব্যবহার করবেন (অনুপস্থিত মানগুলো সরানো, প্রতিস্থাপন করা, বা কীভাবে প্রতিস্থাপন করবেন) তা সেই ডেটার বৈশিষ্ট্যের উপর নির্ভর করবে। ডেটাসেটের সাথে যত বেশি কাজ করবেন এবং যোগাযোগ করবেন, অনুপস্থিত মানগুলোর সাথে কীভাবে মোকাবিলা করতে হবে তা সম্পর্কে তত ভালো ধারণা তৈরি হবে।

## ডুপ্লিকেট ডেটা সরানো

> **শেখার লক্ষ্য:** এই উপ-অধ্যায়ের শেষে, আপনি ডেটাফ্রেম থেকে ডুপ্লিকেট মানগুলো সনাক্ত এবং সরাতে স্বাচ্ছন্দ্যবোধ করবেন।

অনুপস্থিত ডেটার পাশাপাশি, বাস্তব জীবনের ডেটাসেটে আপনি প্রায়ই ডুপ্লিকেট ডেটার সম্মুখীন হবেন। সৌভাগ্যক্রমে, `pandas` ডুপ্লিকেট এন্ট্রি সনাক্ত এবং সরানোর একটি সহজ উপায় প্রদান করে।

- **ডুপ্লিকেট সনাক্ত করা: `duplicated`**: আপনি সহজেই `pandas`-এর `duplicated` মেথড ব্যবহার করে ডুপ্লিকেট মানগুলো সনাক্ত করতে পারেন, যা একটি বুলিয়ান মাস্ক প্রদান করে যা নির্দেশ করে যে একটি `DataFrame`-এর এন্ট্রি পূর্বের একটি এন্ট্রির ডুপ্লিকেট কিনা। এটি কার্যকরভাবে দেখার জন্য আমরা একটি উদাহরণ `DataFrame` তৈরি করব।
```python
example4 = pd.DataFrame({'letters': ['A','B'] * 2 + ['B'],
                         'numbers': [1, 2, 1, 3, 3]})
example4
```
|      |letters|numbers|
|------|-------|-------|
|0     |A      |1      |
|1     |B      |2      |
|2     |A      |1      |
|3     |B      |3      |
|4     |B      |3      |

```python
example4.duplicated()
```
```
0    False
1    False
2     True
3    False
4     True
dtype: bool
```
- **ডুপ্লিকেট সরানো: `drop_duplicates`:** এটি শুধুমাত্র সেই ডেটার একটি কপি প্রদান করে যেখানে সমস্ত `duplicated` মানগুলো `False`:
```python
example4.drop_duplicates()
```
```
	letters	numbers
0	A	1
1	B	2
3	B	3
```
`duplicated` এবং `drop_duplicates` উভয়ই ডিফল্টভাবে সমস্ত কলাম বিবেচনা করে, তবে আপনি নির্দিষ্ট করতে পারেন যে তারা আপনার `DataFrame`-এর শুধুমাত্র একটি কলামের উপসেট পরীক্ষা করবে:
```python
example4.drop_duplicates(['letters'])
```
```
letters	numbers
0	A	1
1	B	2
```

> **মূল কথা:** ডুপ্লিকেট ডেটা সরানো প্রায় প্রতিটি ডেটা-সায়েন্স প্রকল্পের একটি গুরুত্বপূর্ণ অংশ। ডুপ্লিকেট ডেটা আপনার বিশ্লেষণের ফলাফল পরিবর্তন করতে পারে এবং আপনাকে ভুল ফলাফল দিতে পারে!


## 🚀 চ্যালেঞ্জ

এই আলোচিত উপকরণগুলো একটি [Jupyter Notebook](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/2-Working-With-Data/08-data-preparation/notebook.ipynb) হিসেবে প্রদান করা হয়েছে। এছাড়াও, প্রতিটি অধ্যায়ের শেষে অনুশীলন রয়েছে, সেগুলো চেষ্টা করে দেখুন!

## [পোস্ট-লেকচার কুইজ](https://ff-quizzes.netlify.app/en/ds/)



## পর্যালোচনা ও স্ব-অধ্যয়ন

আপনার ডেটা বিশ্লেষণ এবং মডেলিংয়ের জন্য প্রস্তুত করার বিভিন্ন উপায় আবিষ্কার এবং এগুলোর সাথে কাজ করার পদ্ধতি রয়েছে। ডেটা পরিষ্কার করা একটি গুরুত্বপূর্ণ ধাপ যা "হ্যান্ডস অন" অভিজ্ঞতা। Kaggle-এর এই চ্যালেঞ্জগুলো চেষ্টা করুন যা এই পাঠে আলোচনা করা হয়নি।

- [ডেটা ক্লিনিং চ্যালেঞ্জ: তারিখ পার্সিং](https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/)

- [ডেটা ক্লিনিং চ্যালেঞ্জ: ডেটা স্কেল এবং নরমালাইজ করা](https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data)


## অ্যাসাইনমেন্ট

[ফর্ম থেকে ডেটা মূল্যায়ন](assignment.md)

---

**অস্বীকৃতি**:  
এই নথিটি AI অনুবাদ পরিষেবা [Co-op Translator](https://github.com/Azure/co-op-translator) ব্যবহার করে অনুবাদ করা হয়েছে। আমরা যথাসম্ভব সঠিক অনুবাদের চেষ্টা করি, তবে অনুগ্রহ করে মনে রাখবেন যে স্বয়ংক্রিয় অনুবাদে ত্রুটি বা অসঙ্গতি থাকতে পারে। নথিটির মূল ভাষায় লেখা সংস্করণটিকেই প্রামাণিক উৎস হিসেবে বিবেচনা করা উচিত। গুরুত্বপূর্ণ তথ্যের জন্য, পেশাদার মানব অনুবাদ ব্যবহার করার পরামর্শ দেওয়া হচ্ছে। এই অনুবাদ ব্যবহারের ফলে সৃষ্ট কোনো ভুল বোঝাবুঝি বা ভুল ব্যাখ্যার জন্য আমরা দায়ী নই।