<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8bbb3fa0d4ad61384a3b4b5f7560226f",
  "translation_date": "2025-09-04T16:51:41+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "mr"
}
-->
# सांख्यिकी आणि संभाव्यता यांचे संक्षिप्त परिचय

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| सांख्यिकी आणि संभाव्यता - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

सांख्यिकी आणि संभाव्यता सिद्धांत हे गणिताचे दोन परस्पर संबंधित क्षेत्र आहेत जे डेटा सायन्ससाठी अत्यंत महत्त्वाचे आहेत. गणिताचा सखोल अभ्यास न करता डेटा हाताळणे शक्य आहे, परंतु काही मूलभूत संकल्पना जाणून घेणे नेहमीच चांगले असते. येथे आम्ही एक संक्षिप्त परिचय देऊ जो तुम्हाला सुरुवात करण्यास मदत करेल.

[![Intro Video](../../../../translated_images/video-prob-and-stats.e4282e5efa2f2543400843ed98b1057065c9600cebfc8a728e8931b5702b2ae4.mr.png)](https://youtu.be/Z5Zy85g4Yjw)

## [पूर्व-व्याख्यान प्रश्नमंजुषा](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/6)

## संभाव्यता आणि रँडम व्हेरिएबल्स

**संभाव्यता** ही 0 ते 1 दरम्यानची संख्या आहे जी एखाद्या **घटने**ची शक्यता व्यक्त करते. ती सकारात्मक परिणामांची संख्या (जे त्या घटनेला कारणीभूत ठरतात) एकूण परिणामांच्या संख्येने विभागून परिभाषित केली जाते, असे गृहीत धरून की सर्व परिणाम समान शक्यतेचे आहेत. उदाहरणार्थ, जर आपण एक फासे टाकला, तर सम संख्या येण्याची शक्यता 3/6 = 0.5 आहे.

जेव्हा आपण घटनांबद्दल बोलतो, तेव्हा आपण **रँडम व्हेरिएबल्स** वापरतो. उदाहरणार्थ, फासे टाकल्यावर मिळालेली संख्या दर्शवणारा रँडम व्हेरिएबल 1 ते 6 पर्यंतच्या मूल्ये घेईल. 1 ते 6 पर्यंतच्या संख्यांचा संच **नमुनासंच** (sample space) म्हणून ओळखला जातो. आपण रँडम व्हेरिएबलने विशिष्ट मूल्य घेण्याची शक्यता बोलू शकतो, उदाहरणार्थ P(X=3)=1/6.

वरील उदाहरणातील रँडम व्हेरिएबल **विभक्त** (discrete) म्हणून ओळखला जातो, कारण त्याचा नमुनासंच मोजता येण्याजोगा आहे, म्हणजेच वेगवेगळ्या मूल्यांची गणना करता येते. काही वेळा नमुनासंच वास्तविक संख्यांच्या श्रेणीमध्ये किंवा संपूर्ण वास्तविक संख्यांच्या संचामध्ये असतो. अशा व्हेरिएबल्सना **सातत्यपूर्ण** (continuous) म्हणतात. बस येण्याच्या वेळेचे उदाहरण यासाठी चांगले आहे.

## संभाव्यता वितरण

विभक्त रँडम व्हेरिएबल्सच्या बाबतीत, प्रत्येक घटनेची संभाव्यता P(X) फंक्शनद्वारे वर्णन करणे सोपे आहे. नमुनासंच *S* मधील प्रत्येक मूल्यासाठी *s*, 0 ते 1 दरम्यानची संख्या दिली जाते, ज्यामुळे सर्व घटनांसाठी P(X=s) च्या सर्व मूल्यांची बेरीज 1 होते.

सर्वात प्रसिद्ध विभक्त वितरण म्हणजे **समान वितरण** (uniform distribution), ज्यामध्ये N घटकांचा नमुनासंच असतो आणि प्रत्येक घटकासाठी समान संभाव्यता 1/N असते.

सातत्यपूर्ण व्हेरिएबल्सच्या संभाव्यता वितरणाचे वर्णन करणे अधिक कठीण आहे, ज्याचे मूल्य [a,b] या श्रेणीतून किंवा संपूर्ण वास्तविक संख्यांच्या संच ℝ मधून घेतले जाते. बस येण्याच्या वेळेचा विचार करा. प्रत्यक्षात, प्रत्येक विशिष्ट वेळ *t* साठी, बस नेमक्या त्या वेळी येण्याची शक्यता 0 आहे!

> आता तुम्हाला माहित आहे की 0 संभाव्यतेच्या घटना घडतात, आणि खूप वेळा घडतात! किमान प्रत्येक वेळी जेव्हा बस येते!

आपण फक्त एखाद्या व्हेरिएबलने दिलेल्या मूल्यांच्या श्रेणीत पडण्याची शक्यता बोलू शकतो, उदा. P(t<sub>1</sub>≤X<t<sub>2</sub>). अशा परिस्थितीत, संभाव्यता वितरण **संभाव्यता घनता फंक्शन** p(x) द्वारे वर्णन केले जाते, ज्यामुळे

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../translated_images/probability-density.a8aad29f17a14afb519b407c7b6edeb9f3f9aa5f69c9e6d9445f604e5f8a2bf7.mr.png)

सातत्यपूर्ण समान वितरणाचा एक प्रकार म्हणजे **सातत्यपूर्ण समान वितरण**, जो मर्यादित श्रेणीवर परिभाषित केला जातो. मूल्य X एका लांबीच्या l श्रेणीत पडण्याची संभाव्यता l च्या प्रमाणात असते आणि ती 1 पर्यंत वाढते.

आणखी एक महत्त्वाचे वितरण म्हणजे **सामान्य वितरण** (normal distribution), ज्याबद्दल आपण खाली अधिक तपशीलवार चर्चा करू.

## सरासरी, विचलन आणि मानक विचलन

समजा आपण रँडम व्हेरिएबल X चे n नमुने घेतो: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. आपण **सरासरी** (किंवा **गुणाकार सरासरी**) मूल्य पारंपरिक पद्धतीने परिभाषित करू शकतो: (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. नमुन्याचा आकार वाढवताना (म्हणजे n→∞), आम्हाला वितरणाची सरासरी (ज्याला **अपेक्षा** म्हणतात) मिळेल. आम्ही अपेक्षेला **E**(x) असे दर्शवू.

> हे दाखवता येते की कोणत्याही विभक्त वितरणासाठी, ज्यामध्ये मूल्ये {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} आणि संबंधित संभाव्यता p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub> असतात, अपेक्षा E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub> असेल.

मूल्ये किती प्रमाणात पसरलेली आहेत हे ओळखण्यासाठी, आपण विचलन σ<sup>2</sup> = ∑(x<sub>i</sub> - μ)<sup>2</sup>/n, जिथे μ ही अनुक्रमाची सरासरी आहे, गणना करू शकतो. σ ला **मानक विचलन** म्हणतात आणि σ<sup>2</sup> ला **विचलन** म्हणतात.

## मोड, माध्य आणि चतुर्थांश

कधी कधी, सरासरी डेटा साठी "सामान्य" मूल्य योग्य प्रकारे दर्शवत नाही. उदाहरणार्थ, जेव्हा काही अत्यंत मूल्ये असतात जी पूर्णपणे श्रेणीबाहेर असतात, ते सरासरीवर परिणाम करू शकतात. आणखी एक चांगला संकेत म्हणजे **माध्य** (median), एक मूल्य ज्यामुळे अर्धा डेटा पॉइंट्स त्यापेक्षा कमी असतो आणि उर्वरित अर्धा - जास्त असतो.

डेटाचा वितरण समजून घेण्यासाठी **चतुर्थांश** (quartiles) बद्दल बोलणे उपयुक्त आहे:

* पहिला चतुर्थांश, किंवा Q1, असे मूल्य आहे ज्यामुळे 25% डेटा त्यापेक्षा कमी असतो
* तिसरा चतुर्थांश, किंवा Q3, असे मूल्य आहे ज्यामुळे 75% डेटा त्यापेक्षा कमी असतो

ग्राफिकदृष्ट्या आपण माध्य आणि चतुर्थांश यांच्यातील संबंध **बॉक्स प्लॉट** (box plot) मध्ये दर्शवू शकतो:

<img src="images/boxplot_explanation.png" width="50%"/>

येथे आपण **आंतर-चतुर्थांश श्रेणी** IQR=Q3-Q1 आणि तथाकथित **अतिरिक्त मूल्ये** (outliers) - जी [Q1-1.5*IQR,Q3+1.5*IQR] च्या मर्यादेबाहेर असतात, गणना करतो.

लहान संख्येच्या संभाव्य मूल्यांसह मर्यादित वितरणासाठी, एक चांगले "सामान्य" मूल्य म्हणजे जे सर्वात जास्त वारंवारतेने दिसते, ज्याला **मोड** म्हणतात. हे सहसा श्रेणीबद्ध डेटावर लागू होते, जसे की रंग. उदाहरणार्थ, जर दोन गट असतील - काही लोकांना लाल रंग आवडतो आणि काहींना निळा रंग आवडतो. जर आपण रंगांना क्रमांकांनी कोड केले, तर आवडत्या रंगाची सरासरी मूल्य नारंगी-हिरव्या स्पेक्ट्रममध्ये असेल, जे कोणत्याही गटाच्या वास्तविक पसंतीचे संकेत देत नाही. परंतु मोड लाल किंवा निळा रंग असेल, किंवा दोन्ही रंग असतील, जर त्यांना पसंती देणाऱ्या लोकांची संख्या समान असेल (अशा परिस्थितीत नमुना **मल्टीमोडल** म्हणतो).

## वास्तविक जीवनातील डेटा

जेव्हा आपण वास्तविक जीवनातील डेटा विश्लेषित करतो, तेव्हा ते नेहमी रँडम व्हेरिएबल्स नसतात, कारण आपण अज्ञात परिणामांसह प्रयोग करत नाही. उदाहरणार्थ, बेसबॉल खेळाडूंचा संघ विचार करा आणि त्यांचे शरीर डेटा, जसे की उंची, वजन आणि वय. ही संख्या नेमकी रँडम नसली तरी आपण त्याच गणितीय संकल्पना लागू करू शकतो. उदाहरणार्थ, लोकांच्या वजनाचा अनुक्रम काही रँडम व्हेरिएबल्समधून घेतलेल्या मूल्यांचा अनुक्रम मानला जाऊ शकतो. खाली [मेजर लीग बेसबॉल](http://mlb.mlb.com/index.jsp) मधील वास्तविक बेसबॉल खेळाडूंच्या वजनाचा अनुक्रम दिला आहे, जो [या डेटासेट](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) मधून घेतला आहे (तुमच्या सोयीसाठी, फक्त पहिले 20 मूल्ये दाखवली आहेत):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Note**: या डेटासेटसह काम करण्याचे उदाहरण पाहण्यासाठी [संबंधित नोटबुक](notebook.ipynb) पहा. या धड्यादरम्यान अनेक आव्हाने आहेत, आणि तुम्ही त्या नोटबुकमध्ये काही कोड जोडून पूर्ण करू शकता. जर तुम्हाला डेटावर ऑपरेट कसे करायचे हे माहित नसेल, तर काळजी करू नका - आम्ही नंतर पायथन वापरून डेटावर काम करण्याकडे परत येऊ. जर तुम्हाला जुपिटर नोटबुकमध्ये कोड कसे चालवायचे हे माहित नसेल, तर [हा लेख](https://soshnikov.com/education/how-to-execute-notebooks-from-github/) पहा.

आमच्या डेटासाठी सरासरी, माध्य आणि चतुर्थांश दर्शवणारा बॉक्स प्लॉट येथे आहे:

![Weight Box Plot](../../../../translated_images/weight-boxplot.1dbab1c03af26f8a008fff4e17680082c8ab147d6df646cbac440bbf8f5b9c42.mr.png)

आमच्या डेटामध्ये वेगवेगळ्या खेळाडूंच्या **भूमिका** याबद्दल माहिती असल्यामुळे, आम्ही भूमिकेनुसार बॉक्स प्लॉट देखील करू शकतो - यामुळे आम्हाला मापदंड मूल्ये भूमिकांमध्ये कशी भिन्न आहेत याची कल्पना मिळेल. यावेळी आपण उंची विचारात घेऊ:

![Box plot by role](../../../../translated_images/boxplot_byrole.036b27a1c3f52d42f66fba2324ec5cde0a1bca6a01a619eeb0ce7cd054b2527b.mr.png)

हा आकृती सूचित करतो की, सरासरी पाहता, पहिल्या बेसमनची उंची दुसऱ्या बेसमनच्या उंचीपेक्षा जास्त आहे. या धड्याच्या पुढील भागात आपण अधिक औपचारिकपणे ही गृहीतके कशी तपासू शकतो आणि आमचा डेटा सांख्यिकीयदृष्ट्या महत्त्वाचा आहे हे कसे सिद्ध करू शकतो ते शिकू.

> वास्तविक जीवनातील डेटावर काम करताना, आपण गृहीत धरतो की सर्व डेटा पॉइंट्स काही संभाव्यता वितरणातून घेतलेले नमुने आहेत. या गृहीतकामुळे आम्हाला मशीन लर्निंग तंत्र लागू करता येते आणि कार्यरत भविष्यवाणी मॉडेल तयार करता येते.

आमच्या डेटाचे वितरण काय आहे हे पाहण्यासाठी, आम्ही **हिस्टोग्राम** नावाचा ग्राफ प्लॉट करू शकतो. X-अक्षामध्ये वेगवेगळ्या वजन श्रेणी (ज्यांना **बिन्स** म्हणतात) असतील, आणि Y-अक्षामध्ये आमच्या रँडम व्हेरिएबल नमुना दिलेल्या श्रेणीत किती वेळा होता हे दर्शवले जाईल.

![Histogram of real world data](../../../../translated_images/weight-histogram.bfd00caf7fc30b145b21e862dba7def41c75635d5280de25d840dd7f0b00545e.mr.png)

या हिस्टोग्राममधून तुम्ही पाहू शकता की सर्व मूल्ये विशिष्ट सरासरी वजनाभोवती केंद्रित आहेत, आणि त्या वजनापासून जितके दूर जातो - त्या मूल्याचे वजन असण्याची शक्यता कमी होते. म्हणजेच, बेसबॉल खेळाडूचे वजन सरासरी वजनापासून खूप वेगळे असण्याची शक्यता खूप कमी आहे. वजनाचे विचलन सरासरीपासून वजन किती प्रमाणात वेगळे असण्याची शक्यता दर्शवते.

> जर आपण बेसबॉल लीगमधील लोकांऐवजी इतर लोकांचे वजन घेतले, तर वितरण वेगळे असण्याची शक्यता आहे. तथापि, वितरणाचा आकार समान असेल, परंतु सरासरी आणि विचलन बदलतील. त्यामुळे, जर आपण आमचे मॉडेल बेसबॉल खेळाडूंवर प्रशिक्षित केले, तर ते विद्यापीठातील विद्यार्थ्यांवर लागू केल्यास चुकीचे परिणाम देण्याची शक्यता आहे, कारण अंतर्निहित वितरण वेगळे आहे.

## सामान्य वितरण

आम्ही वर पाहिलेल्या वजनाचे वितरण खूप सामान्य आहे, आणि वास्तविक जीवनातील अनेक मोजमापे समान प्रकारच्या वितरणाचे अनुसरण करतात, परंतु वेगवेगळ्या सरासरी आणि विचलनासह. या वितरणाला **सामान्य वितरण** म्हणतात, आणि ते सांख्यिकीमध्ये खूप महत्त्वाची भूमिका बजावते.

सामान्य वितरणाचा वापर संभाव्य बेसबॉल खेळाडूंचे वजन तयार करण्याचा योग्य मार्ग आहे. एकदा आम्हाला सरासरी वजन `mean` आणि मानक विचलन `std` माहित झाल्यावर, आम्ही खालीलप्रमाणे 1000 वजन नमुने तयार करू शकतो:
```python
samples = np.random.normal(mean,std,1000)
``` 

जर आम्ही तयार केलेल्या नमुन्यांचा हिस्टोग्राम प्लॉट केला, तर आम्हाला वर दर्शवलेल्या चित्रासारखे चित्र दिसेल. आणि जर आम्ही नमुन्यांची संख्या आणि बिन्सची संख्या वाढवली, तर आम्ही आदर्श सामान्य वितरणाच्या अधिक जवळचे चित्र तयार करू शकतो:

![Normal Distribution with mean=0 and std.dev=1](../../../../translated_images/normal-histogram.dfae0d67c202137d552d0015fb87581eca263925e512404f3c12d8885315432e.mr.png)

*सरासरी=0 आणि मानक विचलन=1 असलेले सामान्य वितरण*

## विश्वास अंतर

जेव्हा आपण बेसबॉल खेळाडूंच्या वजनाबद्दल बोलतो, तेव्हा आपण गृहीत धरतो की **रँडम व्हेरिएबल W** आहे, जो सर्व बेसबॉल खेळाडूंच्या वजनाच्या आदर्श संभाव्यता वितरणाशी संबंधित आहे (ज्याला **लोकसंख्या** म्हणतात). आमचा वजनाचा अनुक्रम सर्व बेसबॉल खेळाडूंच्या उपसंचाशी संबंधित आहे, ज्याला **नमुना** म्हणतात. एक मनोरंजक प्रश्न म्हणजे, W च्या वितरणाचे मापदंड, म्हणजेच लोकसंख्येची सरासरी आणि विचलन, आपण जाणून घेऊ शकतो का?

सर्वात सोपा उत्तर म्हणजे आमच्या नमुन्याची सरासरी आणि विचलन गणना करणे. तथापि, असे होऊ शकते की आमचा रँडम नमुना संपूर्ण लोकसंख्येचे अचूक प्रतिनिधित्व करत नाही. त्यामुळे **विश्वास अंतर** (confidence interval) बद्दल बोलणे योग्य ठरेल.
> **विश्वास अंतराल** म्हणजे आपल्या नमुन्याच्या आधारे लोकसंख्येचा खरा सरासरी अंदाज लावणे, जो विशिष्ट संभाव्यता (किंवा **विश्वासाचा स्तर**) असताना अचूक असतो.
समजा आपल्याकडे आपल्या वितरणातून घेतलेले X<sub>1</sub>, ..., X<sub>n</sub> नमुने आहेत. प्रत्येक वेळी आपण आपल्या वितरणातून नमुना घेतो, तेव्हा आपल्याला भिन्न सरासरी मूल्य μ मिळेल. त्यामुळे μ ला एक यादृच्छिक चल मानले जाऊ शकते. **विश्वास अंतर** (confidence interval) हे विश्वास p सह दोन मूल्यांचा जोडा (L<sub>p</sub>,R<sub>p</sub>) असतो, ज्यामध्ये **P**(L<sub>p</sub>≤μ≤R<sub>p</sub>) = p, म्हणजेच मोजलेल्या सरासरी मूल्याच्या त्या अंतरात येण्याची शक्यता p असते.

विश्वास अंतर कसे मोजले जातात याबद्दल सविस्तर चर्चा करणे या छोट्या परिचयाच्या पलीकडे जाते. याबद्दल अधिक तपशील [विकिपीडियावर](https://en.wikipedia.org/wiki/Confidence_interval) सापडू शकतो. थोडक्यात, आपण लोकसंख्येच्या खऱ्या सरासरीच्या संदर्भात मोजलेल्या नमुन्याच्या सरासरीचे वितरण परिभाषित करतो, ज्याला **स्टुडंट वितरण** (student distribution) म्हणतात.

> **रोचक तथ्य**: स्टुडंट वितरणाचे नाव गणितज्ञ विल्यम सीली गॉसेट यांच्या नावावरून ठेवले गेले आहे, ज्यांनी "स्टुडंट" या टोपणनावाने आपले संशोधन प्रकाशित केले. ते गिनीज ब्रुअरीमध्ये काम करत होते, आणि एका कथेनुसार, त्यांच्या नियोक्त्याला सामान्य लोकांना हे कळू द्यायचे नव्हते की ते कच्च्या मालाच्या गुणवत्तेचे परीक्षण करण्यासाठी सांख्यिकी चाचण्या वापरत होते.

जर आपल्याला विश्वास p सह आपल्या लोकसंख्येची सरासरी μ मोजायची असेल, तर आपल्याला स्टुडंट वितरण A च्या *(1-p)/2-थ टक्केवारी* घ्यावी लागेल, जी टेबल्समधून घेतली जाऊ शकते किंवा सांख्यिकी सॉफ्टवेअरच्या (उदा. Python, R इ.) अंगभूत फंक्शन्सचा वापर करून मोजली जाऊ शकते. मग μ साठीचे अंतर असेल X±A*D/√n, जिथे X हा नमुन्याची मिळालेली सरासरी आहे, D हा मानक विचलन आहे.

> **टीप**: स्टुडंट वितरणाशी संबंधित [स्वातंत्र्याच्या अंश](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)) या महत्त्वाच्या संकल्पनेची चर्चा येथे वगळली आहे. या संकल्पनेचा सखोल अभ्यास करण्यासाठी अधिक सविस्तर सांख्यिकी पुस्तके पाहावीत.

वजन आणि उंचींसाठी विश्वास अंतर कसे मोजले जाते याचे उदाहरण [सोबतच्या नोटबुकमध्ये](notebook.ipynb) दिले आहे.

| p | वजनाची सरासरी |
|-----|-----------|
| 0.85 | 201.73±0.94 |
| 0.90 | 201.73±1.08 |
| 0.95 | 201.73±1.28 |

लक्षात घ्या की विश्वासाची शक्यता जशी जास्त होते, तशी विश्वास अंतराची रुंदी वाढते.

## गृहीतक चाचणी 

आपल्या बेसबॉल खेळाडूंच्या डेटासेटमध्ये विविध खेळाडूंच्या भूमिका आहेत, ज्यांचे सारांश खालीलप्रमाणे दिले आहेत (हे टेबल कसे मोजले जाते हे पाहण्यासाठी [सोबतचा नोटबुक](notebook.ipynb) पहा):

| भूमिका | उंची | वजन | संख्या |
|------|--------|--------|-------|
| कॅचर | 72.723684 | 204.328947 | 76 |
| डिझिग्नेटेड हिटर | 74.222222 | 220.888889 | 18 |
| फर्स्ट बेसमन | 74.000000 | 213.109091 | 55 |
| आऊटफिल्डर | 73.010309 | 199.113402 | 194 |
| रिलीफ पिचर | 74.374603 | 203.517460 | 315 |
| सेकंड बेसमन | 71.362069 | 184.344828 | 58 |
| शॉर्टस्टॉप | 71.903846 | 182.923077 | 52 |
| स्टार्टिंग पिचर | 74.719457 | 205.163636 | 221 |
| थर्ड बेसमन | 73.044444 | 200.955556 | 45 |

आपण पाहतो की फर्स्ट बेसमनची सरासरी उंची सेकंड बेसमनपेक्षा जास्त आहे. त्यामुळे, आपण असा निष्कर्ष काढण्याचा मोह होतो की **फर्स्ट बेसमन हे सेकंड बेसमनपेक्षा उंच आहेत**.

> हे विधान **गृहीतक** (hypothesis) म्हणून ओळखले जाते, कारण आपल्याला हे खरे आहे की नाही हे माहित नाही.

तथापि, हा निष्कर्ष आपण काढू शकतो की नाही हे नेहमी स्पष्ट नसते. वरील चर्चेतून आपल्याला माहित आहे की प्रत्येक सरासरीला संबंधित विश्वास अंतर असतो, आणि त्यामुळे हा फरक केवळ सांख्यिकी त्रुटी असू शकतो. आपल्याला आपल्या गृहीतकाची चाचणी घेण्यासाठी अधिक औपचारिक पद्धतीची आवश्यकता आहे.

चला फर्स्ट आणि सेकंड बेसमनच्या उंचींसाठी विश्वास अंतर स्वतंत्रपणे मोजूया:

| विश्वास | फर्स्ट बेसमन | सेकंड बेसमन |
|------------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

आपण पाहतो की कोणत्याही विश्वास पातळीवर ही अंतरं ओव्हरलॅप होत नाहीत. यामुळे आपले गृहीतक सिद्ध होते की फर्स्ट बेसमन हे सेकंड बेसमनपेक्षा उंच आहेत.

अधिक औपचारिकपणे, आपण सोडवत असलेली समस्या म्हणजे **दोन संभाव्यता वितरण सारखी आहेत का**, किंवा किमान त्यांचे पॅरामीटर्स सारखे आहेत का हे पाहणे. वितरणाच्या प्रकारावर अवलंबून, आपल्याला त्यासाठी वेगवेगळ्या चाचण्या वापराव्या लागतात. जर आपल्याला माहित असेल की आपली वितरणे सामान्य आहेत, तर आपण **[स्टुडंट टी-चाचणी](https://en.wikipedia.org/wiki/Student%27s_t-test)** लागू करू शकतो.

स्टुडंट टी-चाचणीत, आपण तथाकथित **t-मूल्य** मोजतो, जे सरासरींमधील फरक दर्शवते, विचलन लक्षात घेऊन. हे सिद्ध झाले आहे की t-मूल्य **स्टुडंट वितरणाचे** अनुसरण करते, ज्यामुळे आपल्याला दिलेल्या विश्वास पातळी **p** साठी थ्रेशोल्ड मूल्य मिळते (हे मोजले जाऊ शकते किंवा संख्यात्मक टेबल्समध्ये पाहिले जाऊ शकते). मग आपण t-मूल्य थ्रेशोल्डशी तुलना करतो आणि गृहीतक मान्य किंवा नाकारतो.

Python मध्ये, आपण **SciPy** पॅकेज वापरू शकतो, ज्यामध्ये `ttest_ind` फंक्शन समाविष्ट आहे (इतर अनेक उपयुक्त सांख्यिकी फंक्शन्ससह!). हे आपल्यासाठी t-मूल्य मोजते, आणि विश्वास p-मूल्याचा रिव्हर्स लुकअप देखील करते, ज्यामुळे आपण फक्त विश्वास पाहून निष्कर्ष काढू शकतो.

उदाहरणार्थ, फर्स्ट आणि सेकंड बेसमनच्या उंचींच्या तुलनेत आपल्याला खालील परिणाम मिळतात: 
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
आपल्या बाबतीत, p-मूल्य खूपच कमी आहे, याचा अर्थ फर्स्ट बेसमन उंच असल्याचे समर्थन करणारे ठोस पुरावे आहेत.

तसेच, आपण इतर प्रकारची गृहीतके चाचणी करू इच्छितो, उदाहरणार्थ:
* एखादा नमुना विशिष्ट वितरणाचे अनुसरण करतो हे सिद्ध करणे. आपल्या बाबतीत आपण गृहीत धरले आहे की उंची सामान्य वितरणाचे अनुसरण करते, परंतु त्यासाठी औपचारिक सांख्यिकी पडताळणी आवश्यक आहे.
* एखाद्या नमुन्याच्या सरासरी मूल्याचे पूर्वनिर्धारित मूल्याशी जुळते हे सिद्ध करणे
* अनेक नमुन्यांच्या सरासरींची तुलना करणे (उदा. वेगवेगळ्या वयोगटांमधील आनंदाच्या पातळीतील फरक काय आहे)

## मोठ्या संख्यांचा नियम आणि केंद्रीय मर्यादा प्रमेय

सामान्य वितरण इतके महत्त्वाचे का आहे याचे एक कारण म्हणजे **केंद्रीय मर्यादा प्रमेय**. समजा आपल्याकडे स्वतंत्र N मूल्यांचा मोठा नमुना X<sub>1</sub>, ..., X<sub>N</sub> आहे, जो कोणत्याही वितरणातून घेतला गेला आहे, ज्याची सरासरी μ आणि विचलन σ<sup>2</sup> आहे. मग, पुरेशा मोठ्या N साठी (म्हणजेच, जेव्हा N→∞), Σ<sub>i</sub>X<sub>i</sub> ची सरासरी सामान्य वितरणाचे अनुसरण करेल, ज्याची सरासरी μ आणि विचलन σ<sup>2</sup>/N असेल.

> केंद्रीय मर्यादा प्रमेयाचा दुसरा अर्थ असा आहे की कोणत्याही यादृच्छिक चलांच्या मूल्यांच्या बेरीजाची सरासरी मोजल्यावर आपण नेहमी सामान्य वितरणाकडे पोहोचतो.

केंद्रीय मर्यादा प्रमेयावरून असेही दिसून येते की, जेव्हा N→∞, तेव्हा नमुन्याच्या सरासरीचे μ बरोबर असण्याची शक्यता 1 होते. याला **मोठ्या संख्यांचा नियम** म्हणतात.

## सहसंबंध आणि सहप्रसरण

डेटा सायन्समध्ये एक महत्त्वाचे काम म्हणजे डेटामधील संबंध शोधणे. दोन अनुक्रम **सहसंबद्ध** (correlate) आहेत असे म्हणतो जेव्हा ते एकाच वेळी समान वर्तन प्रदर्शित करतात, म्हणजेच ते एकत्र वाढतात/घटतात, किंवा एक अनुक्रम वाढतो तेव्हा दुसरा घटतो आणि उलट. 

> सहसंबंध नेहमी दोन अनुक्रमांमधील कारणात्मक संबंध दर्शवतो असे नाही; कधी कधी दोन्ही चल बाह्य कारणावर अवलंबून असू शकतात, किंवा केवळ योगायोगाने दोन अनुक्रम सहसंबद्ध असू शकतात. तथापि, मजबूत गणितीय सहसंबंध हे दोन चल कसेतरी जोडलेले असल्याचे चांगले संकेत आहे.

गणितीयदृष्ट्या, दोन यादृच्छिक चलांमधील संबंध दर्शवणारी मुख्य संकल्पना म्हणजे **सहप्रसरण** (covariance), जी अशा प्रकारे मोजली जाते: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. आपण दोन्ही चलांच्या सरासरी मूल्यांपासून विचलन मोजतो, आणि नंतर त्या विचलनांचे गुणाकार घेतो. 

सहसंबंधाचे प्रमाण अधिक चांगल्या प्रकारे समजण्यासाठी, आपण सहप्रसरणाला दोन्ही चलांच्या मानक विचलनाने विभागतो, ज्यामुळे **सहसंबंध** मिळतो. सहसंबंध नेहमी [-1,1] या श्रेणीत असतो, जिथे 1 मजबूत सकारात्मक सहसंबंध दर्शवतो, -1 मजबूत नकारात्मक सहसंबंध दर्शवतो, आणि 0 म्हणजे कोणताही सहसंबंध नाही (चल स्वतंत्र आहेत).

**उदाहरण**: आपण वरील बेसबॉल खेळाडूंच्या डेटासेटमधून वजन आणि उंची यांच्यातील सहसंबंध मोजू शकतो:
```python
print(np.corrcoef(weights,heights))
```
यामुळे आपल्याला **सहसंबंध मॅट्रिक्स** मिळतो:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> सहसंबंध मॅट्रिक्स C कोणत्याही संख्येच्या इनपुट अनुक्रमांसाठी S<sub>1</sub>, ..., S<sub>n</sub> साठी मोजला जाऊ शकतो. C<sub>ij</sub> चे मूल्य S<sub>i</sub> आणि S<sub>j</sub> यांच्यातील सहसंबंध आहे, आणि कर्णरेषेवरील घटक नेहमी 1 असतात (जे S<sub>i</sub> चे स्व-सहसंबंध आहे).

आपल्या बाबतीत, 0.53 हे मूल्य व्यक्तीच्या वजन आणि उंचीमध्ये काही प्रमाणात सहसंबंध असल्याचे दर्शवते. आपण एकमेकांच्या विरोधात एक मूल्याचे स्कॅटर प्लॉट देखील तयार करू शकतो जेणेकरून संबंध दृश्यमान होईल:

![वजन आणि उंची यांच्यातील संबंध](../../../../translated_images/weight-height-relationship.3f06bde4ca2aba9974182c4ef037ed602acd0fbbbbe2ca91cefd838a9e66bcf9.mr.png)

> सहसंबंध आणि सहप्रसरण यांचे अधिक उदाहरणे [सोबतच्या नोटबुकमध्ये](notebook.ipynb) सापडतील.

## निष्कर्ष

या विभागात, आपण शिकले:

* डेटाच्या मूलभूत सांख्यिकी गुणधर्म, जसे की सरासरी, विचलन, मोड आणि चतुर्थांश
* यादृच्छिक चलांचे विविध वितरण, ज्यामध्ये सामान्य वितरण समाविष्ट आहे
* विविध गुणधर्मांमधील सहसंबंध कसा शोधायचा
* काही गृहीतक सिद्ध करण्यासाठी गणित आणि सांख्यिकीचा योग्य वापर कसा करायचा
* दिलेल्या डेटाच्या नमुन्यावरून यादृच्छिक चलासाठी विश्वास अंतर कसे मोजायचे

जरी हे संभाव्यता आणि सांख्यिकीतील सर्व विषयांचा समावेश करणारे नसले तरी, या कोर्समध्ये सुरुवात करण्यासाठी हे पुरेसे आहे.

## 🚀 आव्हान

नोटबुकमधील नमुना कोड वापरून खालील गृहीतकांची चाचणी घ्या:
1. फर्स्ट बेसमन हे सेकंड बेसमनपेक्षा वयाने मोठे आहेत.
2. फर्स्ट बेसमन हे थर्ड बेसमनपेक्षा उंच आहेत.
3. शॉर्टस्टॉप हे सेकंड बेसमनपेक्षा उंच आहेत.

## [पाठानंतरचा क्विझ](https://ff-quizzes.netlify.app/en/ds/)

## पुनरावलोकन आणि स्व-अभ्यास

संभाव्यता आणि सांख्यिकी हा इतका विस्तृत विषय आहे की त्यासाठी स्वतंत्र कोर्स आवश्यक आहे. जर तुम्हाला सिद्धांतात अधिक खोलवर जायचे असेल, तर तुम्ही खालील पुस्तके वाचू शकता:

1. [कार्लोस फर्नांडीझ-ग्रांडा](https://cims.nyu.edu/~cfgranda/) यांनी लिहिलेली [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (ऑनलाइन उपलब्ध)
1. [पीटर आणि अँड्र्यू ब्रूस. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[R मध्ये नमुना कोड](https://github.com/andrewgbruce/statistics-for-data-scientists)].
1. [जेम्स डी. मिलर. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[R मध्ये नमुना कोड](https://github.com/PacktPublishing/Statistics-for-Data-Science)].

## असाइनमेंट

[लहान मधुमेह अभ्यास](assignment.md)

## श्रेय

हा धडा [दिमित्री सोश्निकोव्ह](http://soshnikov.com) यांनी ♥️ सह तयार केला आहे.

---

**अस्वीकरण**:  
हा दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) वापरून भाषांतरित करण्यात आला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी कृपया लक्षात ठेवा की स्वयंचलित भाषांतरांमध्ये त्रुटी किंवा अचूकतेचा अभाव असू शकतो. मूळ भाषेतील दस्तऐवज हा अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर करून निर्माण होणाऱ्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.