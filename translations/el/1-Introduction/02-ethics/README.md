<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "58860ce9a4b8a564003d2752f7c72851",
  "translation_date": "2025-10-03T16:32:38+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "el"
}
-->
# Εισαγωγή στην Ηθική των Δεδομένων

|![ Σκίτσο από [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Ηθική Επιστήμης Δεδομένων - _Σκίτσο από [@nitya](https://twitter.com/nitya)_ |

---

Είμαστε όλοι πολίτες δεδομένων που ζούμε σε έναν κόσμο γεμάτο δεδομένα.

Οι τάσεις της αγοράς δείχνουν ότι μέχρι το 2022, 1 στους 3 μεγάλους οργανισμούς θα αγοράζει και θα πουλάει δεδομένα μέσω διαδικτυακών [Αγορών και Ανταλλακτηρίων](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Ως **Προγραμματιστές Εφαρμογών**, θα βρούμε πιο εύκολο και οικονομικό να ενσωματώσουμε πληροφορίες που βασίζονται σε δεδομένα και αυτοματισμούς που βασίζονται σε αλγόριθμους στις καθημερινές εμπειρίες των χρηστών. Αλλά καθώς η τεχνητή νοημοσύνη γίνεται πανταχού παρούσα, θα χρειαστεί επίσης να κατανοήσουμε τις πιθανές βλάβες που προκαλούνται από την [εργαλειοποίηση](https://www.youtube.com/watch?v=TQHs8SA1qpk) τέτοιων αλγορίθμων σε μεγάλη κλίμακα.

Οι τάσεις δείχνουν ότι μέχρι το 2025, θα δημιουργούμε και θα καταναλώνουμε πάνω από [180 zettabytes](https://www.statista.com/statistics/871513/worldwide-data-created/) δεδομένων. Για τους **Επιστήμονες Δεδομένων**, αυτή η έκρηξη πληροφοριών παρέχει πρωτοφανή πρόσβαση σε προσωπικά και συμπεριφορικά δεδομένα. Μαζί με αυτήν έρχεται η δύναμη να δημιουργούμε λεπτομερή προφίλ χρηστών και να επηρεάζουμε διακριτικά τη λήψη αποφάσεων—συχνά με τρόπους που ενισχύουν την [ψευδαίσθηση της ελεύθερης επιλογής](https://www.datasciencecentral.com/the-pareto-set-and-the-paradox-of-choice/). Ενώ αυτό μπορεί να χρησιμοποιηθεί για να καθοδηγήσει τους χρήστες προς επιθυμητά αποτελέσματα, εγείρει επίσης κρίσιμα ερωτήματα σχετικά με την ιδιωτικότητα των δεδομένων, την αυτονομία και τα ηθικά όρια της επιρροής των αλγορίθμων.

Η ηθική των δεδομένων είναι πλέον _απαραίτητα προστατευτικά μέτρα_ για την επιστήμη και τη μηχανική των δεδομένων, βοηθώντας μας να ελαχιστοποιήσουμε τις πιθανές βλάβες και τις ακούσιες συνέπειες από τις ενέργειές μας που βασίζονται σε δεδομένα. Ο [Κύκλος Υπερβολής της Gartner για την Τεχνητή Νοημοσύνη](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) εντοπίζει σχετικές τάσεις στην ψηφιακή ηθική, την υπεύθυνη τεχνητή νοημοσύνη και τη διακυβέρνηση της τεχνητής νοημοσύνης ως βασικούς παράγοντες για μεγαλύτερες τάσεις γύρω από τη _δημοκρατικοποίηση_ και τη _βιομηχανοποίηση_ της τεχνητής νοημοσύνης.

![Κύκλος Υπερβολής της Gartner για την Τεχνητή Νοημοσύνη - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

Σε αυτό το μάθημα, θα εξερευνήσουμε τον συναρπαστικό τομέα της ηθικής των δεδομένων - από βασικές έννοιες και προκλήσεις, μέχρι μελέτες περιπτώσεων και εφαρμοσμένες έννοιες τεχνητής νοημοσύνης όπως η διακυβέρνηση - που βοηθούν στη δημιουργία μιας κουλτούρας ηθικής σε ομάδες και οργανισμούς που εργάζονται με δεδομένα και τεχνητή νοημοσύνη.




## [Κουίζ πριν το μάθημα](https://ff-quizzes.netlify.app/en/ds/quiz/2) 🎯

## Βασικοί Ορισμοί

Ας ξεκινήσουμε κατανοώντας τη βασική ορολογία.

Η λέξη "ηθική" προέρχεται από την [ελληνική λέξη "ηθικός"](https://en.wikipedia.org/wiki/Ethics) (και τη ρίζα της "ήθος") που σημαίνει _χαρακτήρας ή ηθική φύση_. 

**Ηθική** αφορά τις κοινές αξίες και τις ηθικές αρχές που διέπουν τη συμπεριφορά μας στην κοινωνία. Η ηθική βασίζεται όχι σε νόμους αλλά σε ευρέως αποδεκτούς κανόνες για το τι είναι "σωστό έναντι λάθους". Ωστόσο, οι ηθικές σκέψεις μπορούν να επηρεάσουν πρωτοβουλίες εταιρικής διακυβέρνησης και κυβερνητικούς κανονισμούς που δημιουργούν περισσότερα κίνητρα για συμμόρφωση.

**Ηθική Δεδομένων** είναι ένας [νέος κλάδος της ηθικής](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) που "μελετά και αξιολογεί ηθικά προβλήματα που σχετίζονται με _δεδομένα, αλγόριθμους και αντίστοιχες πρακτικές_". Εδώ, **"δεδομένα"** εστιάζουν σε ενέργειες που σχετίζονται με τη δημιουργία, καταγραφή, επιμέλεια, επεξεργασία, διάδοση, κοινή χρήση και χρήση, **"αλγόριθμοι"** εστιάζουν στην τεχνητή νοημοσύνη, τους πράκτορες, τη μηχανική μάθηση και τα ρομπότ, και **"πρακτικές"** εστιάζουν σε θέματα όπως η υπεύθυνη καινοτομία, ο προγραμματισμός, το hacking και οι κώδικες ηθικής.

**Εφαρμοσμένη Ηθική** είναι η [πρακτική εφαρμογή ηθικών σκέψεων](https://en.wikipedia.org/wiki/Applied_ethics). Είναι η διαδικασία ενεργής διερεύνησης ηθικών ζητημάτων στο πλαίσιο _πραγματικών ενεργειών, προϊόντων και διαδικασιών_, και η λήψη διορθωτικών μέτρων για να διασφαλιστεί ότι αυτά παραμένουν ευθυγραμμισμένα με τις καθορισμένες ηθικές αξίες μας.

**Κουλτούρα Ηθικής** αφορά την [_επιχειρησιακή εφαρμογή_ της εφαρμοσμένης ηθικής](https://hbr.org/2019/05/how-to-design-an-ethical-organization) για να διασφαλιστεί ότι οι ηθικές μας αρχές και πρακτικές υιοθετούνται με συνεπή και επεκτάσιμο τρόπο σε ολόκληρο τον οργανισμό. Οι επιτυχημένες κουλτούρες ηθικής ορίζουν ηθικές αρχές σε επίπεδο οργανισμού, παρέχουν ουσιαστικά κίνητρα για συμμόρφωση και ενισχύουν τους κανόνες ηθικής ενθαρρύνοντας και ενισχύοντας τις επιθυμητές συμπεριφορές σε κάθε επίπεδο του οργανισμού.


## Έννοιες Ηθικής

Σε αυτή την ενότητα, θα συζητήσουμε έννοιες όπως **κοινές αξίες** (αρχές) και **ηθικές προκλήσεις** (προβλήματα) για την ηθική των δεδομένων - και θα εξερευνήσουμε **μελέτες περιπτώσεων** που σας βοηθούν να κατανοήσετε αυτές τις έννοιες σε πραγματικά πλαίσια.

### 1. Αρχές Ηθικής

Κάθε στρατηγική ηθικής δεδομένων ξεκινά με τον ορισμό των _ηθικών αρχών_ - των "κοινών αξιών" που περιγράφουν αποδεκτές συμπεριφορές και καθοδηγούν συμμορφούμενες ενέργειες στα έργα δεδομένων και τεχνητής νοημοσύνης μας. Μπορείτε να τις ορίσετε σε ατομικό ή ομαδικό επίπεδο. Ωστόσο, οι περισσότερες μεγάλες οργανώσεις τις περιγράφουν σε μια δήλωση αποστολής ή πλαίσιο _ηθικής τεχνητής νοημοσύνης_ που ορίζεται σε εταιρικό επίπεδο και εφαρμόζεται με συνέπεια σε όλες τις ομάδες.

**Παράδειγμα:** Η δήλωση αποστολής της Microsoft για την [Υπεύθυνη Τεχνητή Νοημοσύνη](https://www.microsoft.com/en-us/ai/responsible-ai) αναφέρει: _"Δεσμευόμαστε για την προώθηση της τεχνητής νοημοσύνης που καθοδηγείται από ηθικές αρχές που βάζουν τους ανθρώπους πρώτα"_ - προσδιορίζοντας 6 ηθικές αρχές στο παρακάτω πλαίσιο:

![Υπεύθυνη Τεχνητή Νοημοσύνη στη Microsoft](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Ας εξερευνήσουμε σύντομα αυτές τις αρχές. _Η διαφάνεια_ και _η λογοδοσία_ είναι θεμελιώδεις αξίες πάνω στις οποίες βασίζονται οι άλλες αρχές - ας ξεκινήσουμε από εκεί:

* [**Λογοδοσία**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) καθιστά τους επαγγελματίες _υπεύθυνους_ για τις λειτουργίες δεδομένων και τεχνητής νοημοσύνης τους και τη συμμόρφωση με αυτές τις ηθικές αρχές.
* [**Διαφάνεια**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) διασφαλίζει ότι οι ενέργειες δεδομένων και τεχνητής νοημοσύνης είναι _κατανοητές_ (ερμηνεύσιμες) από τους χρήστες, εξηγώντας το τι και το γιατί πίσω από τις αποφάσεις.
* [**Δικαιοσύνη**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - εστιάζει στη διασφάλιση ότι η τεχνητή νοημοσύνη αντιμετωπίζει _όλους τους ανθρώπους_ δίκαια, αντιμετωπίζοντας τυχόν συστημικές ή έμμεσες κοινωνικοτεχνικές προκαταλήψεις στα δεδομένα και τα συστήματα.
* [**Αξιοπιστία & Ασφάλεια**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - διασφαλίζει ότι η τεχνητή νοημοσύνη συμπεριφέρεται _συνεπώς_ με καθορισμένες αξίες, ελαχιστοποιώντας πιθανές βλάβες ή ακούσιες συνέπειες.
* [**Ιδιωτικότητα & Ασφάλεια**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - αφορά την κατανόηση της προέλευσης των δεδομένων και την παροχή _προστασίας ιδιωτικότητας δεδομένων_ στους χρήστες.
* [**Συμπερίληψη**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - αφορά τον σχεδιασμό λύσεων τεχνητής νοημοσύνης με πρόθεση, προσαρμόζοντάς τες για να καλύψουν ένα _ευρύ φάσμα ανθρώπινων αναγκών_ και δυνατοτήτων.

> 🚨 Σκεφτείτε ποια θα μπορούσε να είναι η δήλωση αποστολής σας για την ηθική των δεδομένων. Εξερευνήστε πλαίσια ηθικής τεχνητής νοημοσύνης από άλλους οργανισμούς - εδώ είναι παραδείγματα από [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles), και [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Ποιες κοινές αξίες έχουν; Πώς σχετίζονται αυτές οι αρχές με το προϊόν ή τη βιομηχανία τεχνητής νοημοσύνης στην οποία δραστηριοποιούνται;

### 2. Προκλήσεις Ηθικής

Αφού ορίσουμε τις ηθικές αρχές, το επόμενο βήμα είναι να αξιολογήσουμε τις ενέργειες μας στα δεδομένα και την τεχνητή νοημοσύνη για να δούμε αν ευθυγραμμίζονται με αυτές τις κοινές αξίες. Σκεφτείτε τις ενέργειές σας σε δύο κατηγορίες: _συλλογή δεδομένων_ και _σχεδιασμός αλγορίθμων_. 

Στη συλλογή δεδομένων, οι ενέργειες πιθανότατα θα περιλαμβάνουν **προσωπικά δεδομένα** ή προσωπικά αναγνωρίσιμες πληροφορίες (PII) για αναγνωρίσιμα ζωντανά άτομα. Αυτό περιλαμβάνει [διάφορα στοιχεία μη προσωπικών δεδομένων](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) που _συλλογικά_ αναγνωρίζουν ένα άτομο. Οι ηθικές προκλήσεις μπορεί να σχετίζονται με _ιδιωτικότητα δεδομένων_, _ιδιοκτησία δεδομένων_ και συναφή θέματα όπως _ενημερωμένη συναίνεση_ και _δικαιώματα πνευματικής ιδιοκτησίας_ για τους χρήστες.

Στον σχεδιασμό αλγορίθμων, οι ενέργειες θα περιλαμβάνουν τη συλλογή και την επιμέλεια **συνόλων δεδομένων**, και στη συνέχεια τη χρήση τους για την εκπαίδευση και την ανάπτυξη **μοντέλων δεδομένων** που προβλέπουν αποτελέσματα ή αυτοματοποιούν αποφάσεις σε πραγματικά πλαίσια. Οι ηθικές προκλήσεις μπορεί να προκύψουν από _προκατάληψη συνόλου δεδομένων_, _προβλήματα ποιότητας δεδομένων_, _αδικία_ και _παραπλάνηση_ στους αλγορίθμους - συμπεριλαμβανομένων ορισμένων ζητημάτων που είναι συστημικής φύσης.

Και στις δύο περιπτώσεις, οι ηθικές προκλήσεις επισημαίνουν περιοχές όπου οι ενέργειές μας μπορεί να έρχονται σε σύγκρουση με τις κοινές αξίες μας. Για να ανιχνεύσουμε, να μετριάσουμε, να ελαχιστοποιήσουμε ή να εξαλείψουμε αυτές τις ανησυχίες - πρέπει να θέσουμε ηθικά ερωτήματα "ναι/όχι" σχετικά με τις ενέργειές μας και στη συνέχεια να λάβουμε διορθωτικά μέτρα όπως απαιτείται. Ας δούμε μερικές ηθικές προκλήσεις και τα ηθικά ερωτήματα που εγείρουν:


#### 2.1 Ιδιοκτησία Δεδομένων

Η συλλογή δεδομένων συχνά περιλαμβάνει προσωπικά δεδομένα που μπορούν να αναγνωρίσουν τα υποκείμενα των δεδομένων. [Η ιδιοκτησία δεδομένων](https://permission.io/blog/data-ownership) αφορά τον _έλεγχο_ και τα [_δικαιώματα χρηστών_](https://permission.io/blog/data-ownership) σχετικά με τη δημιουργία, επεξεργασία και διάδοση δεδομένων. 

Τα ηθικά ερωτήματα που πρέπει να θέσουμε είναι: 
 * Ποιος κατέχει τα δεδομένα; (χρήστης ή οργανισμός)
 * Ποια δικαιώματα έχουν τα υποκείμενα των δεδομένων; (π.χ. πρόσβαση, διαγραφή, φορητότητα)
 * Ποια δικαιώματα έχουν οι οργανισμοί; (π.χ. διόρθωση κακόβουλων κριτικών χρηστών)

#### 2.2 Ενημερωμένη Συναίνεση

[Η ενημερωμένη συναίνεση](https://legaldictionary.net/informed-consent/) ορίζει την πράξη των χρηστών να συμφωνούν σε μια ενέργεια (όπως η συλλογή δεδομένων) με _πλήρη κατανόηση_ των σχετικών γεγονότων, συμπεριλαμβανομένου του σκοπού, των πιθανών κινδύνων και των εναλλακτικών. 

Ερωτήματα προς διερεύνηση εδώ είναι:
 * Έδωσε ο χρήστης (υποκείμενο δεδομένων) άδεια για τη συλλογή και χρήση δεδομένων;
 * Κατάλαβε ο χρήστης τον σκοπό για τον οποίο συλλέχθηκαν τα δεδομένα;
 * Κατάλαβε ο χρήστης τους πιθανούς κινδύνους από τη συμμετοχή του;

#### 2.3 Πνευματική Ιδιοκτησία

[Η πνευματική ιδιοκτησία](https://en.wikipedia.org/wiki/Intellectual_property) αναφέρεται σε ά
* Καταγράφεται η πληροφορία _ακριβώς_ ώστε να αντικατοπτρίζει την πραγματικότητα;

#### 2.8 Δικαιοσύνη Αλγορίθμων

Η [Δικαιοσύνη Αλγορίθμων](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) εξετάζει αν ο σχεδιασμός του αλγορίθμου εισάγει συστηματικά διακρίσεις εναντίον συγκεκριμένων υποομάδων υποκειμένων δεδομένων, οδηγώντας σε [πιθανές βλάβες](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) στην _κατανομή_ (όπου πόροι αρνούνται ή παρακρατούνται από αυτήν την ομάδα) και στην _ποιότητα υπηρεσιών_ (όπου η ακρίβεια της τεχνητής νοημοσύνης είναι χαμηλότερη για ορισμένες υποομάδες σε σχέση με άλλες).

Ερωτήσεις που πρέπει να εξεταστούν εδώ είναι:
* Αξιολογήσαμε την ακρίβεια του μοντέλου για διαφορετικές υποομάδες και συνθήκες;
* Εξετάσαμε το σύστημα για πιθανές βλάβες (π.χ., στερεότυπα);
* Μπορούμε να αναθεωρήσουμε τα δεδομένα ή να επανεκπαιδεύσουμε τα μοντέλα για να μειώσουμε τις εντοπισμένες βλάβες;

Εξερευνήστε πόρους όπως οι [λίστες ελέγχου δικαιοσύνης AI](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) για να μάθετε περισσότερα.

#### 2.9 Παραπλάνηση

Η [Παραπλάνηση Δεδομένων](https://www.sciencedirect.com/topics/computer-science/misrepresentation) αφορά το ερώτημα αν επικοινωνούμε τα συμπεράσματα από ειλικρινώς αναφερόμενα δεδομένα με τρόπο που παραπλανά για να υποστηρίξουμε μια επιθυμητή αφήγηση.

Ερωτήσεις που πρέπει να εξεταστούν εδώ είναι:
* Αναφέρουμε ελλιπή ή ανακριβή δεδομένα;
* Οπτικοποιούμε τα δεδομένα με τρόπο που οδηγεί σε παραπλανητικά συμπεράσματα;
* Χρησιμοποιούμε επιλεκτικές στατιστικές τεχνικές για να χειραγωγήσουμε τα αποτελέσματα;
* Υπάρχουν εναλλακτικές εξηγήσεις που μπορεί να προσφέρουν διαφορετικό συμπέρασμα;

#### 2.10 Ελεύθερη Επιλογή
Η [Ψευδαίσθηση της Ελεύθερης Επιλογής](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) συμβαίνει όταν οι "αρχιτεκτονικές επιλογής" του συστήματος χρησιμοποιούν αλγόριθμους λήψης αποφάσεων για να ωθήσουν τους ανθρώπους να πάρουν ένα προτιμώμενο αποτέλεσμα, ενώ φαίνεται ότι τους δίνουν επιλογές και έλεγχο. Αυτά τα [σκοτεινά μοτίβα](https://www.darkpatterns.org/) μπορούν να προκαλέσουν κοινωνική και οικονομική βλάβη στους χρήστες. Επειδή οι αποφάσεις των χρηστών επηρεάζουν τα προφίλ συμπεριφοράς, αυτές οι ενέργειες ενδεχομένως να οδηγήσουν σε μελλοντικές επιλογές που μπορούν να ενισχύσουν ή να επεκτείνουν τον αντίκτυπο αυτών των βλαβών.

Ερωτήσεις που πρέπει να εξεταστούν εδώ είναι:
* Κατάλαβε ο χρήστης τις συνέπειες της επιλογής που έκανε;
* Ήταν ο χρήστης ενήμερος για (εναλλακτικές) επιλογές και τα πλεονεκτήματα & μειονεκτήματα της κάθε μίας;
* Μπορεί ο χρήστης να αντιστρέψει μια αυτοματοποιημένη ή επηρεασμένη επιλογή αργότερα;

### 3. Μελέτες Περίπτωσης

Για να τοποθετήσουμε αυτές τις ηθικές προκλήσεις σε πραγματικά πλαίσια, είναι χρήσιμο να εξετάσουμε μελέτες περιπτώσεων που αναδεικνύουν τις πιθανές βλάβες και συνέπειες για τα άτομα και την κοινωνία, όταν παραβλέπονται τέτοιες ηθικές παραβιάσεις.

Ακολουθούν μερικά παραδείγματα:

| Ηθική Πρόκληση | Μελέτη Περίπτωσης | 
|--- |--- |
| **Ενημερωμένη Συναίνεση** | 1972 - [Μελέτη Σύφιλης Tuskegee](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Αφροαμερικανοί άνδρες που συμμετείχαν στη μελέτη υποσχέθηκαν δωρεάν ιατρική φροντίδα _αλλά εξαπατήθηκαν_ από ερευνητές που δεν ενημέρωσαν τους συμμετέχοντες για τη διάγνωσή τους ή για τη διαθεσιμότητα θεραπείας. Πολλοί συμμετέχοντες πέθαναν και οι σύντροφοι ή τα παιδιά τους επηρεάστηκαν. Η μελέτη διήρκεσε 40 χρόνια. | 
| **Ιδιωτικότητα Δεδομένων** | 2007 - Ο [διαγωνισμός δεδομένων του Netflix](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) παρείχε στους ερευνητές _10 εκατομμύρια ανωνυμοποιημένες βαθμολογίες ταινιών από 50.000 πελάτες_ για να βοηθήσουν στη βελτίωση των αλγορίθμων συστάσεων. Ωστόσο, οι ερευνητές κατάφεραν να συσχετίσουν ανωνυμοποιημένα δεδομένα με προσωπικά αναγνωρίσιμα δεδομένα σε _εξωτερικά σύνολα δεδομένων_ (π.χ., σχόλια IMDb), ουσιαστικά "απο-ανωνυμοποιώντας" ορισμένους συνδρομητές του Netflix.|
| **Προκατάληψη στη Συλλογή Δεδομένων** | 2013 - Η πόλη της Βοστώνης [ανέπτυξε το Street Bump](https://www.boston.gov/transportation/street-bump), μια εφαρμογή που επέτρεπε στους πολίτες να αναφέρουν λακκούβες, παρέχοντας στην πόλη καλύτερα δεδομένα για τους δρόμους ώστε να εντοπίζει και να διορθώνει προβλήματα. Ωστόσο, [οι άνθρωποι σε χαμηλότερες εισοδηματικές ομάδες είχαν λιγότερη πρόσβαση σε αυτοκίνητα και τηλέφωνα](https://hbr.org/2013/04/the-hidden-biases-in-big-data), καθιστώντας τα προβλήματα των δρόμων τους αόρατα στην εφαρμογή. Οι προγραμματιστές συνεργάστηκαν με ακαδημαϊκούς για να αντιμετωπίσουν ζητήματα _ισότιμης πρόσβασης και ψηφιακών διαφορών_ για δικαιοσύνη. |
| **Δικαιοσύνη Αλγορίθμων** | 2018 - Η MIT [Gender Shades Study](http://gendershades.org/overview.html) αξιολόγησε την ακρίβεια των προϊόντων τεχνητής νοημοσύνης για την ταξινόμηση φύλου, αποκαλύπτοντας κενά στην ακρίβεια για τις γυναίκες και τα άτομα με χρώμα. Μια [κάρτα Apple του 2019](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) φάνηκε να προσφέρει λιγότερη πίστωση στις γυναίκες από ό,τι στους άνδρες. Και οι δύο περιπτώσεις ανέδειξαν ζητήματα προκατάληψης αλγορίθμων που οδηγούν σε κοινωνικοοικονομικές βλάβες.|
| **Παραπλάνηση Δεδομένων** | 2020 - Το [Τμήμα Δημόσιας Υγείας της Γεωργίας δημοσίευσε γραφήματα για τα κρούσματα COVID-19](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) που φαινόταν να παραπλανούν τους πολίτες σχετικά με τις τάσεις των επιβεβαιωμένων κρουσμάτων με μη χρονολογική σειρά στον άξονα x. Αυτό δείχνει παραπλάνηση μέσω τεχνικών οπτικοποίησης. |
| **Ψευδαίσθηση της Ελεύθερης Επιλογής** | 2020 - Η εκπαιδευτική εφαρμογή [ABCmouse πλήρωσε 10 εκατομμύρια δολάρια για να διευθετήσει μια καταγγελία της FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) όπου οι γονείς παγιδεύτηκαν να πληρώνουν για συνδρομές που δεν μπορούσαν να ακυρώσουν. Αυτό δείχνει σκοτεινά μοτίβα στις αρχιτεκτονικές επιλογής, όπου οι χρήστες ωθήθηκαν σε πιθανώς επιβλαβείς επιλογές. |
| **Ιδιωτικότητα Δεδομένων & Δικαιώματα Χρηστών** | 2021 - Η [παραβίαση δεδομένων του Facebook](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) αποκάλυψε δεδομένα από 530 εκατομμύρια χρήστες, οδηγώντας σε διακανονισμό 5 δισεκατομμυρίων δολαρίων με την FTC. Ωστόσο, αρνήθηκε να ειδοποιήσει τους χρήστες για την παραβίαση, παραβιάζοντας τα δικαιώματα των χρηστών σχετικά με τη διαφάνεια και την πρόσβαση στα δεδομένα. |

Θέλετε να εξερευνήσετε περισσότερες μελέτες περιπτώσεων; Δείτε αυτούς τους πόρους:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - ηθικά διλήμματα σε διάφορους κλάδους.
* [Μάθημα Ηθικής στην Επιστήμη Δεδομένων](https://www.coursera.org/learn/data-science-ethics#syllabus) - μελέτες περιπτώσεων ορόσημο.
* [Όπου τα πράγματα πήγαν στραβά](https://deon.drivendata.org/examples/) - λίστα ελέγχου deon με παραδείγματα.

> 🚨 Σκεφτείτε τις μελέτες περιπτώσεων που έχετε δει - έχετε βιώσει ή επηρεαστεί από μια παρόμοια ηθική πρόκληση στη ζωή σας; Μπορείτε να σκεφτείτε τουλάχιστον μία άλλη μελέτη περίπτωσης που να απεικονίζει μία από τις ηθικές προκλήσεις που συζητήσαμε σε αυτήν την ενότητα;

## Εφαρμοσμένη Ηθική

Μιλήσαμε για έννοιες ηθικής, προκλήσεις και μελέτες περιπτώσεων σε πραγματικά πλαίσια. Αλλά πώς μπορούμε να ξεκινήσουμε να _εφαρμόζουμε_ ηθικές αρχές και πρακτικές στα έργα μας; Και πώς μπορούμε να _λειτουργικοποιήσουμε_ αυτές τις πρακτικές για καλύτερη διακυβέρνηση; Ας εξερευνήσουμε μερικές πραγματικές λύσεις:

### 1. Επαγγελματικοί Κώδικες

Οι Επαγγελματικοί Κώδικες προσφέρουν μια επιλογή για οργανισμούς να "ενθαρρύνουν" τα μέλη τους να υποστηρίξουν τις ηθικές αρχές και τη δήλωση αποστολής τους. Οι κώδικες είναι _ηθικές κατευθυντήριες γραμμές_ για επαγγελματική συμπεριφορά, βοηθώντας τους εργαζόμενους ή τα μέλη να λαμβάνουν αποφάσεις που ευθυγραμμίζονται με τις αρχές του οργανισμού τους. Είναι αποτελεσματικοί μόνο όταν τα μέλη συμμορφώνονται εθελοντικά. Ωστόσο, πολλοί οργανισμοί προσφέρουν πρόσθετες ανταμοιβές και κυρώσεις για να ενθαρρύνουν τη συμμόρφωση των μελών.

Παραδείγματα περιλαμβάνουν:

* [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Κώδικας Ηθικής
* [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Κώδικας Συμπεριφοράς (δημιουργήθηκε το 2013)
* [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (από το 1993)

> 🚨 Ανήκετε σε κάποιο επαγγελματικό οργανισμό μηχανικών ή επιστήμης δεδομένων; Εξερευνήστε την ιστοσελίδα τους για να δείτε αν ορίζουν έναν επαγγελματικό κώδικα ηθικής. Τι λέει αυτό για τις ηθικές τους αρχές; Πώς "ενθαρρύνουν" τα μέλη να ακολουθήσουν τον κώδικα;

### 2. Λίστες Ελέγχου Ηθικής

Ενώ οι επαγγελματικοί κώδικες ορίζουν την απαιτούμενη _ηθική συμπεριφορά_ από τους επαγγελματίες, [έχουν γνωστούς περιορισμούς](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) στην επιβολή, ιδιαίτερα σε μεγάλα έργα. Αντίθετα, πολλοί ειδικοί στην Επιστήμη Δεδομένων [υποστηρίζουν τις λίστες ελέγχου](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), που μπορούν **να συνδέσουν τις αρχές με τις πρακτικές** με πιο καθοριστικό και εφαρμόσιμο τρόπο.

Οι λίστες ελέγχου μετατρέπουν τις ερωτήσεις σε "ναι/όχι" εργασίες που μπορούν να λειτουργικοποιηθούν, επιτρέποντας την παρακολούθησή τους ως μέρος των τυπικών ροών εργασίας κυκλοφορίας προϊόντων.

Παραδείγματα περιλαμβάνουν:
* [Deon](https://deon.drivendata.org/) - μια γενικής χρήσης λίστα ελέγχου ηθικής δεδομένων που δημιουργήθηκε από [συστάσεις της βιομηχανίας](https://deon.drivendata.org/#checklist-citations) με εργαλείο γραμμής εντολών για εύκολη ενσωμάτωση.
* [Privacy Audit Checklist](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - παρέχει γενικές οδηγίες για πρακτικές χειρισμού πληροφοριών από νομικές και κοινωνικές προοπτικές.
* [AI Fairness Checklist](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - δημιουργήθηκε από επαγγελματίες της τεχνητής νοημοσύνης για να υποστηρίξει την υιοθέτηση και ενσωμάτωση ελέγχων δικαιοσύνης στους κύκλους ανάπτυξης της τεχνητής νοημοσύνης.
* [22 ερωτήσεις για την ηθική στα δεδομένα και την τεχνητή νοημοσύνη](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - πιο ανοιχτό πλαίσιο, δομημένο για αρχική εξερεύνηση ηθικών ζητημάτων στο σχεδιασμό, την υλοποίηση και τα οργανωτικά πλαίσια.

### 3. Κανονισμοί Ηθικής

Η ηθική αφορά τον καθορισμό κοινών αξιών και την εθελοντική τήρηση του σωστού. **Συμμόρφωση** αφορά την _τήρηση του νόμου_ όπου και αν ορίζεται. **Διακυβέρνηση** καλύπτει γενικά όλους τους τρόπους με τους οποίους οι οργανισμοί λειτουργούν για να επιβάλλουν ηθικές αρχές και να συμμορφώνονται με καθορισμένους νόμους.

Σήμερα, η διακυβέρνηση λαμβάνει δύο μορφές εντός των οργανισμών. Πρώτον, αφορά τον καθορισμό **ηθικών αρχών AI** και την καθιέρωση πρακτικών για την λειτουργικοποίηση της υιοθέτησης σε όλα τα έργα που σχετίζονται με την τεχνητή νοημοσύνη στον οργανισμό. Δεύτερον, αφορά τη συμμόρφωση με όλους τους κυβερνητικά καθορισμένους **κανονισμούς προστασίας δεδομένων** για τις περιοχές στις οποίες δραστηριοποιείται.

Παραδείγματα κανονισμών προστασίας και ιδιωτικότητας δεδομένων:

* `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - ρυθμίζει τη συλλογή, χρήση και αποκάλυψη προσωπικών πληροφοριών από την _ομοσπονδιακή κυβέρνηση_.
* `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - προστατεύει προσωπικά δεδομένα υγείας.
* `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule)
* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - μάθημα για τη Δικαιοσύνη, από τη Microsoft.  
* [Principles of Responsible AI](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - δωρεάν εκπαιδευτική διαδρομή από το Microsoft Learn.  
* [Ethics and Data Science](https://resources.oreilly.com/examples/0636920203964) - ηλεκτρονικό βιβλίο από την O'Reilly (M. Loukides, H. Mason κ.ά.)  
* [Data Science Ethics](https://www.coursera.org/learn/data-science-ethics#syllabus) - διαδικτυακό μάθημα από το Πανεπιστήμιο του Μίσιγκαν.  
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - μελέτες περιπτώσεων από το Πανεπιστήμιο του Τέξας.  

# Εργασία  

[Γράψτε μια Μελέτη Περίπτωσης για την Ηθική των Δεδομένων](assignment.md)  

---

**Αποποίηση ευθύνης**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία αυτόματης μετάφρασης [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που καταβάλλουμε προσπάθειες για ακρίβεια, παρακαλούμε να έχετε υπόψη ότι οι αυτόματες μεταφράσεις ενδέχεται να περιέχουν λάθη ή ανακρίβειες. Το πρωτότυπο έγγραφο στη μητρική του γλώσσα θα πρέπει να θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή εσφαλμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.